---
layout: post
title: Transformer: Ngươi Không phải là anh hùng, người là quái vật nhiều đầu.
published: false
---
# Giới Thiệu
Trong blog này, mình sẽ trình bày chi tiết cách mô hình Transformer hoạt động, cũng như là cách cài đặt mô hình chi tiết cho những bạn mới có kiến thức cơ bản về deep learning như CNN hoặc LSTM cũng có thể hiểu được. 
Về cơ bản mô hình Transformer chính là nền tảng của rất nhiều mô hình khác mà nổi tiếng nhất là BERT (Bidirectional Encoder Representations from Transformers)

# Tổng Quan Mô Hình
# Encoder
## Embedding Layer
## Positional Encoding
## Self Attention Layer
## Multi Head Attention
# Decoder
## Masked Multi Head Attention
# Loss function
# Implemetation
