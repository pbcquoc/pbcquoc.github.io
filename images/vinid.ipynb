{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu\n",
    "Trong notebook này, mình sẽ trình bày cách giải quyết đề tài tuyển dụng của VinID. Mô hình CNN được sử dụng để phân loại 10 số viết tay trong bộ MNIST. Trong notebook này,bao gồm các phần sau:\n",
    "\n",
    "* **1. Giới thiệu**[](http://)\n",
    "* **2. Tiền xử lý dữ liệu**\n",
    "    * 2.1 Load dữ liệu\n",
    "    * 2.2 Kiểm tra missing value\n",
    "    * 2.3 Chuẩn hóa    \n",
    "    * 2.5 Label encoding\n",
    "    * 2.6 Xây dựng tập train/test\n",
    "* **3. Data augmentation**    \n",
    "* **4. Xây dựng mô hình**\n",
    "    * 4.1 Xây dựng mô hình\n",
    "* **5. Tunning parameter**    \n",
    "    * 5.1 Khai báo không gian tìm kiếm siêu tham số\n",
    "    * 5.2 Grid search\n",
    "* **6. So sánh các optimizer và loss function**    \n",
    "    * 6.1 So sánh optimizer\n",
    "    * 6.2 So sánh loss function\n",
    "* **7. Đánh giá mô hình**\n",
    "    * 7.1 Confusion matrix\n",
    "* **8. Dự đoán**\n",
    "    * 8.1 Predict and Submit results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cài đặt thư viện hyperas để hỗ trỡ quá trình tunning siêu tham số. Hyperas cung cấp các api rất tiện lợi cho quá trình theo huấn luyện và theo dõi độ chính xác của model tại mỗi bộ tham số. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperas in /root/anaconda3/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: entrypoints in /root/anaconda3/lib/python3.6/site-packages (from hyperas) (0.2.3)\n",
      "Requirement already satisfied: keras in /root/anaconda3/lib/python3.6/site-packages (from hyperas) (2.2.4)\n",
      "Requirement already satisfied: hyperopt in /root/anaconda3/lib/python3.6/site-packages (from hyperas) (0.1.2)\n",
      "Requirement already satisfied: nbformat in /root/anaconda3/lib/python3.6/site-packages (from hyperas) (4.4.0)\n",
      "Requirement already satisfied: jupyter in /root/anaconda3/lib/python3.6/site-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied: nbconvert in /root/anaconda3/lib/python3.6/site-packages (from hyperas) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /root/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (1.3.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /root/.local/lib/python3.6/site-packages (from keras->hyperas) (1.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /root/.local/lib/python3.6/site-packages (from keras->hyperas) (1.0.5)\n",
      "Requirement already satisfied: pyyaml in /root/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (3.12)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /root/.local/lib/python3.6/site-packages (from keras->hyperas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /root/.local/lib/python3.6/site-packages (from keras->hyperas) (1.12.0)\n",
      "Requirement already satisfied: h5py in /root/anaconda3/lib/python3.6/site-packages (from keras->hyperas) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /root/anaconda3/lib/python3.6/site-packages (from hyperopt->hyperas) (4.32.2)\n",
      "Requirement already satisfied: pymongo in /root/anaconda3/lib/python3.6/site-packages (from hyperopt->hyperas) (3.9.0)\n",
      "Requirement already satisfied: future in /root/.local/lib/python3.6/site-packages (from hyperopt->hyperas) (0.17.1)\n",
      "Requirement already satisfied: networkx in /root/anaconda3/lib/python3.6/site-packages (from hyperopt->hyperas) (2.1)\n",
      "Requirement already satisfied: ipython_genutils in /root/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /root/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (4.3.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /root/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (2.6.0)\n",
      "Requirement already satisfied: jupyter_core in /root/anaconda3/lib/python3.6/site-packages (from nbformat->hyperas) (4.4.0)\n",
      "Requirement already satisfied: notebook in /root/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (5.5.0)\n",
      "Requirement already satisfied: qtconsole in /root/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (4.3.1)\n",
      "Requirement already satisfied: jupyter-console in /root/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (5.2.0)\n",
      "Requirement already satisfied: ipykernel in /root/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (4.8.2)\n",
      "Requirement already satisfied: ipywidgets in /root/anaconda3/lib/python3.6/site-packages (from jupyter->hyperas) (7.2.1)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /root/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (0.8.3)\n",
      "Requirement already satisfied: jinja2 in /root/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (2.10)\n",
      "Requirement already satisfied: pygments in /root/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (2.2.0)\n",
      "Requirement already satisfied: bleach in /root/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /root/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (1.4.2)\n",
      "Requirement already satisfied: testpath in /root/anaconda3/lib/python3.6/site-packages (from nbconvert->hyperas) (0.3.1)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /root/anaconda3/lib/python3.6/site-packages (from networkx->hyperopt->hyperas) (4.3.0)\n",
      "Requirement already satisfied: Send2Trash in /root/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /root/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (17.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /root/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /root/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (5.2.3)\n",
      "Requirement already satisfied: tornado>=4 in /root/anaconda3/lib/python3.6/site-packages (from notebook->jupyter->hyperas) (5.0.2)\n",
      "Requirement already satisfied: ipython in /root/anaconda3/lib/python3.6/site-packages (from jupyter-console->jupyter->hyperas) (6.4.0)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.0 in /root/anaconda3/lib/python3.6/site-packages (from jupyter-console->jupyter->hyperas) (1.0.15)\n",
      "Requirement already satisfied: widgetsnbextension~=3.2.0 in /root/anaconda3/lib/python3.6/site-packages (from ipywidgets->jupyter->hyperas) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /root/anaconda3/lib/python3.6/site-packages (from jinja2->nbconvert->hyperas) (1.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /root/anaconda3/lib/python3.6/site-packages (from bleach->nbconvert->hyperas) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /root/anaconda3/lib/python3.6/site-packages (from jupyter-client>=5.2.0->notebook->jupyter->hyperas) (2.7.3)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /root/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (4.5.0)\n",
      "Requirement already satisfied: pickleshare in /root/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.4)\n",
      "Requirement already satisfied: backcall in /root/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /root/.local/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (41.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /root/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.12.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /root/anaconda3/lib/python3.6/site-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
      "Requirement already satisfied: wcwidth in /root/anaconda3/lib/python3.6/site-packages (from prompt_toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
      "Requirement already satisfied: webencodings in /root/anaconda3/lib/python3.6/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->hyperas) (0.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-console->jupyter->hyperas) (0.5.2)\n",
      "Requirement already satisfied: parso>=0.2.0 in /root/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython->jupyter-console->jupyter->hyperas) (0.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Basic compuational libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.layers import Dense, Dropout, Conv2D, GlobalAveragePooling2D, Flatten, GlobalMaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "# Import hyperopt for tunning hyper params\n",
    "from hyperopt import hp, tpe, fmin\n",
    "from hyperopt import space_eval\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tiền xử lý\n",
    "Đọc bộ dữ liệu MNIST, chúng ta chia bộ dữ liệu thành tập train/valid/test. Đồng thời chuẩn hóa dữ liệu về khoảng [0-1] để giúp tăng tốc quá trình hội tụ. Tập valid của chúng ta sẽ gồm 20% tập train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    # Load the data\n",
    "    train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n",
    "    test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "    Y_train = train[\"label\"]\n",
    "    \n",
    "    # Drop 'label' column\n",
    "    X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "    \n",
    "    # Normalize the data\n",
    "    X_train = X_train / 255.0\n",
    "    test = test / 255.0\n",
    "    \n",
    "    # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "    X_train = X_train.values.reshape(-1,28,28,1)\n",
    "    test = test.values.reshape(-1,28,28,1)\n",
    "    \n",
    "    # Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "    Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "    \n",
    "    return X_train, Y_train, test\n",
    "\n",
    "X, Y, X_test = data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra phân bố của nhãn\n",
    "Chúng ta thấy rằng số lượng mẫu dữ liệu cho mỗi nhãn tương đương nhau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(np.argmax(Y, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử nhìn qua một số mẫu trong tập huấn luyện. Chúng ta thấy rằng hầu hết các ảnh đều rõ nét và tương đối dễ dàng để nhận dạng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X[i][:,:,0], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(np.argmax(Y[i]));\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Định nghĩa số epochs cần huấn luyện và bachsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "Kĩ thuật data augmentation được sử dụng để phát sinh thêm những mẫu dữ liệu mới bằng cách áp dụng các kĩ thuật xử lý ảnh trên bức ảnh. Các phép biến đổi nhỏ này phải đảm bảo không làm thay đổi nhãn của bức ảnh. \n",
    "\n",
    "Một số kĩ thuật phổ biến của data augmentation như là:\n",
    "* Rotation: Xoay một góc nhỏ\n",
    "* Translation: Tính tiến\n",
    "* Brightness, Staturation: Thay đổi độ sáng, tương phản \n",
    "* Zoom: zoom to/nhỏ bức ảnh\n",
    "* Elastic Distortion: biến dạng bức ảnh\n",
    "* Flip: lật trái/phải/trên/dưới.\n",
    "\n",
    "Ở dưới đây, chúng ta sẽ chọn xoay 1 góc trong 0-10 độ. Zoom ảnh 0.1 lần, tịnh tiến 0.1 lần mỗi chiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "train_aug = ImageDataGenerator(        \n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        )\n",
    "\n",
    "test_aug = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Xây dưng mô hình CNN\n",
    "CNN bao gồm tập hợp các lớp cơ bản bao gồm: convolution layer + nonlinear layer, pooling layer, fully connected layer. Các lớp này liên kết với nhau theo một thứ tự nhất định. Thông thường, một ảnh sẽ được lan truyền qua tầng convolution layer + nonlinear layer đầu tiên, sau đó các giá trị tính toán được sẽ lan truyền qua pooling layer, bộ ba convolution layer + nonlinear layer + pooling layer có thể được lặp lại nhiều lần trong network. Và sau đó được lan truyền qua tầng fully connected layer và softmax để tính sác xuất ảnh đó chứa vật thế gì.\n",
    "\n",
    "![](https://pbcquoc.github.io/images/cnn_model.png)\n",
    "### Định nghĩa mô hình\n",
    "Chúng ta sử dụng Keras Sequential API để định nghĩa mô hình. Các layer được thêm vào rất dễ dàng và tương đối linh động. \n",
    "Đầu tiên chúng ta sử dụng layer Conv2D trên ảnh đầu vào. Conv2D bao gồm một tập các filters cần phải học. Mỗi filters sẽ trược qua toàn bộ bức ảnh để detect các đặt trưng trên bức ảnh đó. \n",
    "\n",
    "Pooling layer là tầng quan trọng và thường đứng sau tầng Conv. Tầng này có chức năng giảm chiều của feature maps trước đó. Đối với max-pooling, tầng này chỉ đơn giản chọn giá trị lớn nhất trong vùng có kích thước pooling_size x pooling_size (thường là 2x2). Tầng pooling này được sử dụng để giảm chi phí tính toán và giảm được overfit của mô hình. \n",
    "\n",
    "Đồng thời, Dropout cũng được sử dụng để hạn chế overfit. Dropout sẽ bỏ đi ngẫu nhiên các neuron bằng cách nhân với mask zeros, do đó, giúp mô hình học được những đặc trưng hữu ích. Dropout trong hầu hết các trường hợp đều giúp tăng độ chính xác và hạn chết overfit của mô hình. \n",
    "\n",
    "Ở tầng cuối cùng, chúng ta flatten feature matrix thành một vector, sau đó sử dụng các tầng fully connected layers để phân loại ảnh thành các lớp cho trước.\n",
    "\n",
    "Để giúp mô hình hội tụ gần với gobal minima chúng ta sử dụng annealing learning rate. Learning sẽ được điều chỉnh nhỏ dần sau mỗi lần cập nhật nếu như sau một số bước nhất định mà loss của mô hình không giảm nữa. Để giảm thời gian tính toán, chúng ta có thể sử dụng learning ban đầu lớn, sau đó giảm dần để mô hình hội tụ nhanh hơn.\n",
    "\n",
    "Ngoài ra, chúng ta sử dụng early stopping để hạn chế hiện tượng overfit của mô hình. early stopping sẽ dừng quá trình huấn luyện nếu như loss trên tập validation tăng dần trong khi trên tập lại giảm. \n",
    "\n",
    "### Sử dụng hyperas để tunning siêu tham số\n",
    "Trong quá trình định nghĩa mô hình, chúng ta sẽ lồng vào đó các đoạn mã để hỗ trợ quá trình search siêu tham số đã được định nghĩa ở trên. Chúng ta sẽ cần search các tham số như filter_size, pooling_size, dropout rate, dense size. Đồng thời chúng ta cũng thử việc điều chỉnh cả optimizer của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "def train_model(train_generator, valid_generator, params):    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = params['conv1'], kernel_size = params['kernel_size_1'], padding = 'Same', \n",
    "                     activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = params['conv2'], kernel_size = params['kernel_size_2'], padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size = params['pooling_size_1']))\n",
    "    model.add(Dropout(params['dropout1']))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = params['conv3'], kernel_size = params['kernel_size_3'], padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = params['conv4'], kernel_size = params['kernel_size_4'], padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size = params['pooling_size_1'], strides=(2,2)))\n",
    "    model.add(Dropout(params['dropout2']))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(params['dense1'], activation = \"relu\"))\n",
    "    model.add(Dropout(params['dropout3']))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    \n",
    "    if params['opt'] == 'rmsprop':\n",
    "        opt = RMSprop()\n",
    "    elif params['opt'] == 'sgd':\n",
    "        opt = SGD()\n",
    "    elif params['opt'] == 'nadam':\n",
    "        opt = Nadam()\n",
    "    else:\n",
    "        opt = Adam()\n",
    "    \n",
    "    model.compile(loss=params['loss'], optimizer=opt, metrics=['acc'])\n",
    "        \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, mode='auto', cooldown=2, min_lr=1e-7)\n",
    "    early = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    callbacks_list = [reduce_lr, early]    \n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                  validation_data=valid_generator,\n",
    "                                  steps_per_epoch=len(train_generator),\n",
    "                                  validation_steps=len(valid_generator),\n",
    "                                  callbacks=callbacks_list, epochs = epochs,\n",
    "                                  verbose=2)\n",
    "    \n",
    "    score, acc = model.evaluate_generator(valid_generator, steps=len(valid_generator), verbose=0)\n",
    "    \n",
    "    return acc, model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyper-params tunning\n",
    "Chúng ta sử dụng Hyperas để tunning các tham số. Hyperas sẽ phát sinh bộ tham số dựa trên khai báo ở trên. Sau đó huấn luyện mô hình và đánh giá trên tập validation. Bộ tham số có độ chính xác cao nhất trên tập validation sẽ được ghi nhận lại. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Khai báo không gian tìm kiếm siêu tham số\n",
    "Có rất nhiều siêu tham số cần được tunning như: kiến trúc mạng, số filter, kích thước mỗi filters, kích thước pooling, các cách khởi tạo, hàm kích hoạt, tỉ lệ dropout,... Trong phần này, chúng ta sẽ tập trung vào các tham số  như kích thước filter, số filters, pooling size.\n",
    "\n",
    "Đầu tiên, chúng ta cần khai báo các siêu tham để hyperas có thể tìm kiếm trong tập đấy. Ở mỗi tầng conv, chúng ta sẽ tunning kích thước filter, filter size. Ở tầng pooling, kích thước pooling size sẽ được tunning. Đồng thời, tỉ lệ dropout ở tầng Dropout cũng được tunning. Số filters ở tầng conv thường từ 16 -> 1024, kích thước filter hay thường dùng nhất trong là 3 với 5. Còn tỉ lệ dropout nằm trong đoạn 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the space of hyperparameters that we will search\n",
    "space = {\n",
    "    'opt':hp.choice('opt', ['adam', 'sgd', 'rmsprop']),\n",
    "    \n",
    "    'conv1':hp.choice('conv1', [16, 32, 64, 128]),\n",
    "    'conv2':hp.choice('conv2', [16, 32, 64, 128]),\n",
    "    'kernel_size_1': hp.choice('kernel_size_1', [3, 5]),\n",
    "    'kernel_size_2': hp.choice('kernel_size_2', [3, 5]),\n",
    "    'dropout1': hp.choice('dropout1', [0, 0.25, 0.5]),\n",
    "    'pooling_size_1': hp.choice('pooling_size_1', [2, 3]),\n",
    "    \n",
    "    'conv3':hp.choice('conv3', [32, 64, 128, 256, 512]),\n",
    "    'conv4':hp.choice('conv4', [32, 64, 128, 256, 512]),\n",
    "    'kernel_size_3': hp.choice('kernel_size_3', [3, 5]),\n",
    "    'kernel_size_4': hp.choice('kernel_size_4', [3, 5]),\n",
    "    'dropout2':hp.choice('dropout2', [0, 0.25, 0.5]),\n",
    "    'pooling_size_2': hp.choice('pooling_size_2', [2, 3]),\n",
    "    \n",
    "    'dense1':hp.choice('dense1', [128, 256, 512, 1024]),\n",
    "    'dropout3':hp.choice('dropout3', [0, 0.25, 0.5]),\n",
    "    \n",
    "    'loss': hp.choice('loss', ['categorical_crossentropy', 'kullback_leibler_divergence']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Optimze để tìm bộ tham số tốt nhất\n",
    "Hyperas sẽ phát sinh các bộ tham số giữ trên không gian tìm kiếm định nghĩa trước của chúng ta. Sau đó thư viện sẽ hỗ trợ quá trình tìm kiếm các tham số này đơn giản bằng một số API có sẵn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=random_seed)\n",
    "# only apply data augmentation with train data\n",
    "train_gen = train_aug.flow(X_train, Y_train, batch_size=batch_size)\n",
    "valid_gen = test_aug.flow(X_val, Y_val, batch_size=batch_size)\n",
    "\n",
    "def optimize(params):\n",
    "    acc, model, history = train_model(train_gen, valid_gen, params)\n",
    "    \n",
    "    return -acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chạy quá trình search tham số. Bộ siêu tham số tốt nhất sẽ được ghi nhận lại để chúng ta sử dụng trong mô hình cuối cùng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "\n",
      "W0914 09:43:05.983868 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0914 09:43:06.065519 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0914 09:43:06.075301 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0914 09:43:06.123427 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0914 09:43:06.125205 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0914 09:43:10.018944 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0914 09:43:10.144633 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0914 09:43:10.155966 140240089409280 deprecation.py:506] From /root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0914 09:43:10.834075 140240089409280 deprecation_wrapper.py:119] From /root/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0914 09:43:10.981822 140240089409280 deprecation.py:323] From /root/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30                                          \n",
      " - 19s - loss: 0.5554 - acc: 0.8958 - val_loss: 0.3073 - val_acc: 0.9707\n",
      "\n",
      "Epoch 2/30                                          \n",
      " - 12s - loss: 0.1966 - acc: 0.9566 - val_loss: 0.1294 - val_acc: 0.9815\n",
      "\n",
      "Epoch 3/30                                          \n",
      " - 13s - loss: 0.1257 - acc: 0.9689 - val_loss: 0.1337 - val_acc: 0.9817\n",
      "\n",
      "Epoch 4/30                                          \n",
      " - 12s - loss: 0.1069 - acc: 0.9740 - val_loss: 0.0717 - val_acc: 0.9871\n",
      "\n",
      "Epoch 5/30                                          \n",
      " - 13s - loss: 0.1014 - acc: 0.9768 - val_loss: 0.0616 - val_acc: 0.9875\n",
      "\n",
      "Epoch 6/30                                          \n",
      " - 12s - loss: 0.0942 - acc: 0.9792 - val_loss: 0.0549 - val_acc: 0.9881\n",
      "\n",
      "Epoch 7/30                                          \n",
      " - 13s - loss: 0.0926 - acc: 0.9790 - val_loss: 0.0696 - val_acc: 0.9896\n",
      "\n",
      "Epoch 8/30                                          \n",
      " - 13s - loss: 0.0939 - acc: 0.9791 - val_loss: 0.0530 - val_acc: 0.9915\n",
      "\n",
      "Epoch 9/30                                          \n",
      " - 13s - loss: 0.0891 - acc: 0.9810 - val_loss: 0.0581 - val_acc: 0.9917\n",
      "\n",
      "Epoch 10/30                                         \n",
      " - 12s - loss: 0.0996 - acc: 0.9806 - val_loss: 0.0514 - val_acc: 0.9920\n",
      "\n",
      "Epoch 11/30                                         \n",
      " - 13s - loss: 0.0953 - acc: 0.9818 - val_loss: 0.0505 - val_acc: 0.9923\n",
      "\n",
      "Epoch 12/30                                         \n",
      " - 13s - loss: 0.0998 - acc: 0.9815 - val_loss: 0.0642 - val_acc: 0.9913\n",
      "\n",
      "Epoch 13/30                                         \n",
      " - 13s - loss: 0.0931 - acc: 0.9825 - val_loss: 0.0482 - val_acc: 0.9926\n",
      "\n",
      "Epoch 14/30                                         \n",
      " - 13s - loss: 0.0910 - acc: 0.9826 - val_loss: 0.0467 - val_acc: 0.9930\n",
      "\n",
      "Epoch 15/30                                         \n",
      " - 13s - loss: 0.0881 - acc: 0.9832 - val_loss: 0.0739 - val_acc: 0.9920\n",
      "\n",
      "Epoch 16/30                                         \n",
      " - 13s - loss: 0.0870 - acc: 0.9836 - val_loss: 0.0677 - val_acc: 0.9899\n",
      "\n",
      "Epoch 17/30                                         \n",
      " - 13s - loss: 0.0607 - acc: 0.9890 - val_loss: 0.0434 - val_acc: 0.9943\n",
      "\n",
      "Epoch 18/30                                         \n",
      " - 13s - loss: 0.0498 - acc: 0.9907 - val_loss: 0.0434 - val_acc: 0.9946\n",
      "\n",
      "Epoch 19/30                                         \n",
      " - 13s - loss: 0.0503 - acc: 0.9908 - val_loss: 0.0501 - val_acc: 0.9937\n",
      "\n",
      "Epoch 20/30                                         \n",
      " - 13s - loss: 0.0438 - acc: 0.9912 - val_loss: 0.0391 - val_acc: 0.9952\n",
      "\n",
      "Epoch 21/30                                         \n",
      " - 12s - loss: 0.0429 - acc: 0.9918 - val_loss: 0.0370 - val_acc: 0.9954\n",
      "\n",
      "Epoch 22/30                                         \n",
      " - 13s - loss: 0.0418 - acc: 0.9922 - val_loss: 0.0394 - val_acc: 0.9950\n",
      "\n",
      "Epoch 23/30                                         \n",
      " - 13s - loss: 0.0435 - acc: 0.9910 - val_loss: 0.0393 - val_acc: 0.9944\n",
      "\n",
      "Epoch 24/30                                         \n",
      " - 13s - loss: 0.0398 - acc: 0.9920 - val_loss: 0.0372 - val_acc: 0.9949\n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 17s - loss: 0.9664 - acc: 0.9156 - val_loss: 1.0357 - val_acc: 0.9275         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 13s - loss: 0.9532 - acc: 0.9346 - val_loss: 0.4416 - val_acc: 0.9712         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 13s - loss: 0.9019 - acc: 0.9403 - val_loss: 0.8849 - val_acc: 0.9435         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 13s - loss: 0.8870 - acc: 0.9428 - val_loss: 0.6445 - val_acc: 0.9587         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 13s - loss: 0.5074 - acc: 0.9675 - val_loss: 0.3391 - val_acc: 0.9785         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 13s - loss: 0.4676 - acc: 0.9701 - val_loss: 0.3290 - val_acc: 0.9786         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 13s - loss: 0.4251 - acc: 0.9728 - val_loss: 0.3726 - val_acc: 0.9763         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 13s - loss: 0.4235 - acc: 0.9729 - val_loss: 0.3774 - val_acc: 0.9758         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 13s - loss: 0.3975 - acc: 0.9743 - val_loss: 0.2364 - val_acc: 0.9848         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 13s - loss: 0.3164 - acc: 0.9796 - val_loss: 0.2160 - val_acc: 0.9863         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 12s - loss: 0.2887 - acc: 0.9811 - val_loss: 0.2184 - val_acc: 0.9857         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 13s - loss: 0.2726 - acc: 0.9821 - val_loss: 0.1987 - val_acc: 0.9870         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 13s - loss: 0.2596 - acc: 0.9831 - val_loss: 0.2118 - val_acc: 0.9862         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 13s - loss: 0.2464 - acc: 0.9840 - val_loss: 0.2148 - val_acc: 0.9863         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 13s - loss: 0.2507 - acc: 0.9839 - val_loss: 0.1660 - val_acc: 0.9893         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 13s - loss: 0.2186 - acc: 0.9856 - val_loss: 0.1904 - val_acc: 0.9880         \n",
      "\n",
      "Epoch 17/30                                                                      \n",
      " - 13s - loss: 0.2297 - acc: 0.9850 - val_loss: 0.1671 - val_acc: 0.9895         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 13s - loss: 0.2243 - acc: 0.9854 - val_loss: 0.1535 - val_acc: 0.9899         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 13s - loss: 0.2341 - acc: 0.9850 - val_loss: 0.1759 - val_acc: 0.9885         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 13s - loss: 0.2328 - acc: 0.9850 - val_loss: 0.1490 - val_acc: 0.9902         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 13s - loss: 0.2095 - acc: 0.9863 - val_loss: 0.1746 - val_acc: 0.9886         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 13s - loss: 0.2244 - acc: 0.9855 - val_loss: 0.1477 - val_acc: 0.9904         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 13s - loss: 0.2187 - acc: 0.9859 - val_loss: 0.1455 - val_acc: 0.9904         \n",
      "\n",
      "Epoch 24/30                                                                      \n",
      " - 13s - loss: 0.1993 - acc: 0.9871 - val_loss: 0.1623 - val_acc: 0.9896         \n",
      "\n",
      "Epoch 25/30                                                                      \n",
      " - 13s - loss: 0.2076 - acc: 0.9865 - val_loss: 0.1603 - val_acc: 0.9893         \n",
      "\n",
      "Epoch 26/30                                                                      \n",
      " - 13s - loss: 0.2081 - acc: 0.9866 - val_loss: 0.1567 - val_acc: 0.9900         \n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 16s - loss: 0.4960 - acc: 0.8443 - val_loss: 0.0618 - val_acc: 0.9818         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 13s - loss: 0.1609 - acc: 0.9529 - val_loss: 0.0576 - val_acc: 0.9845         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 13s - loss: 0.1358 - acc: 0.9620 - val_loss: 0.0406 - val_acc: 0.9893         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 13s - loss: 0.1236 - acc: 0.9657 - val_loss: 0.0579 - val_acc: 0.9869         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 13s - loss: 0.1175 - acc: 0.9705 - val_loss: 0.0731 - val_acc: 0.9875         \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30                                                                       \n",
      " - 13s - loss: 0.0870 - acc: 0.9771 - val_loss: 0.0348 - val_acc: 0.9919         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 13s - loss: 0.0813 - acc: 0.9798 - val_loss: 0.0335 - val_acc: 0.9927         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 13s - loss: 0.0744 - acc: 0.9815 - val_loss: 0.0335 - val_acc: 0.9923         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 13s - loss: 0.0745 - acc: 0.9807 - val_loss: 0.0292 - val_acc: 0.9930         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 13s - loss: 0.0695 - acc: 0.9824 - val_loss: 0.0333 - val_acc: 0.9920         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 13s - loss: 0.0708 - acc: 0.9822 - val_loss: 0.0388 - val_acc: 0.9919         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 13s - loss: 0.0655 - acc: 0.9843 - val_loss: 0.0257 - val_acc: 0.9938         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 13s - loss: 0.0644 - acc: 0.9843 - val_loss: 0.0278 - val_acc: 0.9936         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 13s - loss: 0.0645 - acc: 0.9845 - val_loss: 0.0263 - val_acc: 0.9942         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 13s - loss: 0.0578 - acc: 0.9854 - val_loss: 0.0307 - val_acc: 0.9930         \n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 17s - loss: 0.6574 - acc: 0.9177 - val_loss: 0.4988 - val_acc: 0.9615         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 13s - loss: 0.5163 - acc: 0.9549 - val_loss: 0.4268 - val_acc: 0.9658         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 13s - loss: 0.4795 - acc: 0.9609 - val_loss: 0.4681 - val_acc: 0.9636         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 13s - loss: 0.4307 - acc: 0.9666 - val_loss: 0.3215 - val_acc: 0.9758         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 13s - loss: 0.4220 - acc: 0.9670 - val_loss: 0.3196 - val_acc: 0.9764         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 13s - loss: 0.3804 - acc: 0.9719 - val_loss: 0.4115 - val_acc: 0.9706         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 13s - loss: 0.3977 - acc: 0.9716 - val_loss: 0.2873 - val_acc: 0.9792         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 13s - loss: 0.4015 - acc: 0.9712 - val_loss: 0.3924 - val_acc: 0.9729         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 13s - loss: 0.4319 - acc: 0.9701 - val_loss: 0.2615 - val_acc: 0.9820         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 13s - loss: 0.4116 - acc: 0.9716 - val_loss: 0.5734 - val_acc: 0.9612         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 13s - loss: 0.4008 - acc: 0.9729 - val_loss: 0.2799 - val_acc: 0.9815         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 13s - loss: 0.2759 - acc: 0.9809 - val_loss: 0.1867 - val_acc: 0.9855         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 13s - loss: 0.2192 - acc: 0.9846 - val_loss: 0.1530 - val_acc: 0.9898         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 13s - loss: 0.1964 - acc: 0.9864 - val_loss: 0.1338 - val_acc: 0.9905         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 14s - loss: 0.2035 - acc: 0.9860 - val_loss: 0.1199 - val_acc: 0.9917         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 13s - loss: 0.1799 - acc: 0.9877 - val_loss: 0.1060 - val_acc: 0.9927         \n",
      "\n",
      "Epoch 17/30                                                                      \n",
      " - 13s - loss: 0.1713 - acc: 0.9882 - val_loss: 0.1342 - val_acc: 0.9908         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 13s - loss: 0.1708 - acc: 0.9881 - val_loss: 0.1145 - val_acc: 0.9918         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 13s - loss: 0.1475 - acc: 0.9896 - val_loss: 0.1034 - val_acc: 0.9927         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 13s - loss: 0.1479 - acc: 0.9896 - val_loss: 0.0757 - val_acc: 0.9943         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 13s - loss: 0.1301 - acc: 0.9908 - val_loss: 0.1102 - val_acc: 0.9926         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 14s - loss: 0.1316 - acc: 0.9911 - val_loss: 0.0869 - val_acc: 0.9936         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 13s - loss: 0.1329 - acc: 0.9905 - val_loss: 0.0835 - val_acc: 0.9943         \n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 16s - loss: 1.0239 - acc: 0.6619 - val_loss: 0.1741 - val_acc: 0.9469         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 13s - loss: 0.3178 - acc: 0.9034 - val_loss: 0.1258 - val_acc: 0.9625         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 13s - loss: 0.2087 - acc: 0.9358 - val_loss: 0.0757 - val_acc: 0.9760         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 13s - loss: 0.1657 - acc: 0.9510 - val_loss: 0.0638 - val_acc: 0.9807         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 13s - loss: 0.1426 - acc: 0.9560 - val_loss: 0.0464 - val_acc: 0.9846         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 13s - loss: 0.1204 - acc: 0.9629 - val_loss: 0.0570 - val_acc: 0.9827         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 13s - loss: 0.1091 - acc: 0.9672 - val_loss: 0.0400 - val_acc: 0.9875         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 13s - loss: 0.0976 - acc: 0.9707 - val_loss: 0.0722 - val_acc: 0.9795         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 13s - loss: 0.0908 - acc: 0.9719 - val_loss: 0.0343 - val_acc: 0.9893         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 13s - loss: 0.0882 - acc: 0.9729 - val_loss: 0.0390 - val_acc: 0.9892         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 13s - loss: 0.0828 - acc: 0.9738 - val_loss: 0.0303 - val_acc: 0.9899         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 13s - loss: 0.0747 - acc: 0.9774 - val_loss: 0.0358 - val_acc: 0.9885         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 13s - loss: 0.0715 - acc: 0.9781 - val_loss: 0.0246 - val_acc: 0.9927         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 13s - loss: 0.0714 - acc: 0.9785 - val_loss: 0.0246 - val_acc: 0.9930         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 13s - loss: 0.0692 - acc: 0.9789 - val_loss: 0.0283 - val_acc: 0.9902         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 13s - loss: 0.0624 - acc: 0.9810 - val_loss: 0.0243 - val_acc: 0.9929         \n",
      "\n",
      "Epoch 17/30                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 13s - loss: 0.0549 - acc: 0.9827 - val_loss: 0.0229 - val_acc: 0.9923         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 13s - loss: 0.0588 - acc: 0.9823 - val_loss: 0.0220 - val_acc: 0.9924         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 14s - loss: 0.0565 - acc: 0.9834 - val_loss: 0.0212 - val_acc: 0.9932         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 13s - loss: 0.0563 - acc: 0.9834 - val_loss: 0.0254 - val_acc: 0.9917         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 13s - loss: 0.0544 - acc: 0.9833 - val_loss: 0.0199 - val_acc: 0.9939         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 13s - loss: 0.0542 - acc: 0.9838 - val_loss: 0.0233 - val_acc: 0.9921         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 13s - loss: 0.0541 - acc: 0.9843 - val_loss: 0.0231 - val_acc: 0.9918         \n",
      "\n",
      "Epoch 24/30                                                                      \n",
      " - 13s - loss: 0.0509 - acc: 0.9843 - val_loss: 0.0206 - val_acc: 0.9935         \n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 21s - loss: 1.6756 - acc: 0.8689 - val_loss: 0.6940 - val_acc: 0.9527         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 16s - loss: 0.9866 - acc: 0.9319 - val_loss: 0.9049 - val_acc: 0.9394         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 16s - loss: 0.8665 - acc: 0.9422 - val_loss: 0.5904 - val_acc: 0.9614         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 16s - loss: 0.7071 - acc: 0.9529 - val_loss: 0.5167 - val_acc: 0.9655         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 16s - loss: 0.6586 - acc: 0.9566 - val_loss: 0.4366 - val_acc: 0.9713         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 16s - loss: 0.6200 - acc: 0.9591 - val_loss: 0.7137 - val_acc: 0.9533         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 16s - loss: 0.6694 - acc: 0.9563 - val_loss: 0.6443 - val_acc: 0.9577         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 16s - loss: 0.4908 - acc: 0.9680 - val_loss: 0.2523 - val_acc: 0.9833         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 16s - loss: 0.3721 - acc: 0.9758 - val_loss: 0.2367 - val_acc: 0.9845         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 16s - loss: 0.3498 - acc: 0.9773 - val_loss: 0.1804 - val_acc: 0.9886         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 16s - loss: 0.3272 - acc: 0.9785 - val_loss: 0.2229 - val_acc: 0.9852         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 16s - loss: 0.2959 - acc: 0.9803 - val_loss: 0.1800 - val_acc: 0.9883         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 16s - loss: 0.2873 - acc: 0.9805 - val_loss: 0.1722 - val_acc: 0.9888         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 16s - loss: 0.2762 - acc: 0.9816 - val_loss: 0.1621 - val_acc: 0.9894         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 17s - loss: 0.2464 - acc: 0.9833 - val_loss: 0.1692 - val_acc: 0.9889         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 16s - loss: 0.2348 - acc: 0.9846 - val_loss: 0.1621 - val_acc: 0.9893         \n",
      "\n",
      "Epoch 17/30                                                                      \n",
      " - 17s - loss: 0.2236 - acc: 0.9852 - val_loss: 0.1422 - val_acc: 0.9899         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 16s - loss: 0.2178 - acc: 0.9859 - val_loss: 0.1475 - val_acc: 0.9902         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 16s - loss: 0.2072 - acc: 0.9863 - val_loss: 0.1584 - val_acc: 0.9893         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 16s - loss: 0.2196 - acc: 0.9855 - val_loss: 0.1343 - val_acc: 0.9915         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 16s - loss: 0.2013 - acc: 0.9865 - val_loss: 0.1432 - val_acc: 0.9905         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 16s - loss: 0.2084 - acc: 0.9862 - val_loss: 0.1349 - val_acc: 0.9914         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 16s - loss: 0.1891 - acc: 0.9876 - val_loss: 0.1285 - val_acc: 0.9919         \n",
      "\n",
      "Epoch 24/30                                                                      \n",
      " - 16s - loss: 0.1852 - acc: 0.9876 - val_loss: 0.1296 - val_acc: 0.9914         \n",
      "\n",
      "Epoch 25/30                                                                      \n",
      " - 16s - loss: 0.1986 - acc: 0.9869 - val_loss: 0.1462 - val_acc: 0.9904         \n",
      "\n",
      "Epoch 26/30                                                                      \n",
      " - 16s - loss: 0.1874 - acc: 0.9875 - val_loss: 0.1469 - val_acc: 0.9902         \n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 18s - loss: 0.4874 - acc: 0.8507 - val_loss: 0.0734 - val_acc: 0.9785         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 14s - loss: 0.1627 - acc: 0.9520 - val_loss: 0.0551 - val_acc: 0.9848         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 13s - loss: 0.1213 - acc: 0.9635 - val_loss: 0.0511 - val_acc: 0.9852         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 13s - loss: 0.1058 - acc: 0.9686 - val_loss: 0.0297 - val_acc: 0.9915         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 13s - loss: 0.0947 - acc: 0.9731 - val_loss: 0.0390 - val_acc: 0.9886         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 13s - loss: 0.0860 - acc: 0.9751 - val_loss: 0.0375 - val_acc: 0.9899         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 14s - loss: 0.0648 - acc: 0.9811 - val_loss: 0.0277 - val_acc: 0.9926         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 13s - loss: 0.0540 - acc: 0.9843 - val_loss: 0.0250 - val_acc: 0.9925         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 13s - loss: 0.0470 - acc: 0.9855 - val_loss: 0.0227 - val_acc: 0.9936         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 14s - loss: 0.0455 - acc: 0.9862 - val_loss: 0.0196 - val_acc: 0.9945         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 13s - loss: 0.0438 - acc: 0.9861 - val_loss: 0.0210 - val_acc: 0.9940         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 13s - loss: 0.0485 - acc: 0.9857 - val_loss: 0.0204 - val_acc: 0.9943         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 13s - loss: 0.0386 - acc: 0.9881 - val_loss: 0.0179 - val_acc: 0.9950         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 13s - loss: 0.0382 - acc: 0.9888 - val_loss: 0.0175 - val_acc: 0.9949         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 13s - loss: 0.0364 - acc: 0.9882 - val_loss: 0.0174 - val_acc: 0.9948         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 14s - loss: 0.0341 - acc: 0.9901 - val_loss: 0.0169 - val_acc: 0.9949         \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30                                                                      \n",
      " - 13s - loss: 0.0316 - acc: 0.9904 - val_loss: 0.0167 - val_acc: 0.9950         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 13s - loss: 0.0334 - acc: 0.9894 - val_loss: 0.0177 - val_acc: 0.9946         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 13s - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0156 - val_acc: 0.9956         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 13s - loss: 0.0322 - acc: 0.9901 - val_loss: 0.0156 - val_acc: 0.9955         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 14s - loss: 0.0317 - acc: 0.9900 - val_loss: 0.0161 - val_acc: 0.9951         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 13s - loss: 0.0296 - acc: 0.9907 - val_loss: 0.0158 - val_acc: 0.9952         \n",
      "\n",
      "Epoch 1/30                                                                       \n",
      " - 18s - loss: 0.3462 - acc: 0.9129 - val_loss: 0.1458 - val_acc: 0.9729\n",
      "\n",
      "Epoch 2/30                                                          \n",
      " - 13s - loss: 0.1845 - acc: 0.9618 - val_loss: 0.0830 - val_acc: 0.9860\n",
      "\n",
      "Epoch 3/30                                                          \n",
      " - 13s - loss: 0.1356 - acc: 0.9715 - val_loss: 0.1129 - val_acc: 0.9831\n",
      "\n",
      "Epoch 4/30                                                          \n",
      " - 13s - loss: 0.1069 - acc: 0.9760 - val_loss: 0.0834 - val_acc: 0.9871\n",
      "\n",
      "Epoch 5/30                                                          \n",
      " - 13s - loss: 0.0581 - acc: 0.9861 - val_loss: 0.0468 - val_acc: 0.9913\n",
      "\n",
      "Epoch 6/30                                                          \n",
      " - 14s - loss: 0.0424 - acc: 0.9898 - val_loss: 0.0324 - val_acc: 0.9935\n",
      "\n",
      "Epoch 7/30                                                          \n",
      " - 13s - loss: 0.0442 - acc: 0.9894 - val_loss: 0.0333 - val_acc: 0.9924\n",
      "\n",
      "Epoch 8/30                                                          \n",
      " - 13s - loss: 0.0409 - acc: 0.9897 - val_loss: 0.0352 - val_acc: 0.9931\n",
      "\n",
      "Epoch 9/30                                                          \n",
      " - 13s - loss: 0.0290 - acc: 0.9924 - val_loss: 0.0237 - val_acc: 0.9957\n",
      "\n",
      "Epoch 10/30                                                         \n",
      " - 13s - loss: 0.0288 - acc: 0.9921 - val_loss: 0.0321 - val_acc: 0.9939\n",
      "\n",
      "Epoch 11/30                                                         \n",
      " - 13s - loss: 0.0274 - acc: 0.9929 - val_loss: 0.0220 - val_acc: 0.9950\n",
      "\n",
      "Epoch 12/30                                                         \n",
      " - 13s - loss: 0.0283 - acc: 0.9926 - val_loss: 0.0276 - val_acc: 0.9939\n",
      "\n",
      "Epoch 13/30                                                         \n",
      " - 14s - loss: 0.0256 - acc: 0.9936 - val_loss: 0.0314 - val_acc: 0.9938\n",
      "\n",
      "Epoch 14/30                                                         \n",
      " - 13s - loss: 0.0232 - acc: 0.9933 - val_loss: 0.0233 - val_acc: 0.9950\n",
      "\n",
      "Epoch 1/30                                                          \n",
      " - 18s - loss: 0.3839 - acc: 0.8764 - val_loss: 0.0678 - val_acc: 0.9785\n",
      "\n",
      "Epoch 2/30                                                          \n",
      " - 14s - loss: 0.1337 - acc: 0.9584 - val_loss: 0.0516 - val_acc: 0.9854\n",
      "\n",
      "Epoch 3/30                                                          \n",
      " - 14s - loss: 0.0955 - acc: 0.9709 - val_loss: 0.0440 - val_acc: 0.9860\n",
      "\n",
      "Epoch 4/30                                                          \n",
      " - 14s - loss: 0.0857 - acc: 0.9727 - val_loss: 0.0462 - val_acc: 0.9871\n",
      "\n",
      "Epoch 5/30                                                          \n",
      " - 13s - loss: 0.0698 - acc: 0.9782 - val_loss: 0.0304 - val_acc: 0.9906\n",
      "\n",
      "Epoch 6/30                                                          \n",
      " - 13s - loss: 0.0649 - acc: 0.9798 - val_loss: 0.0359 - val_acc: 0.9883\n",
      "\n",
      "Epoch 7/30                                                          \n",
      " - 13s - loss: 0.0567 - acc: 0.9825 - val_loss: 0.0320 - val_acc: 0.9907\n",
      "\n",
      "Epoch 8/30                                                          \n",
      " - 13s - loss: 0.0552 - acc: 0.9828 - val_loss: 0.0288 - val_acc: 0.9917\n",
      "\n",
      "Epoch 9/30                                                          \n",
      " - 13s - loss: 0.0521 - acc: 0.9838 - val_loss: 0.0326 - val_acc: 0.9902\n",
      "\n",
      "Epoch 10/30                                                         \n",
      " - 14s - loss: 0.0494 - acc: 0.9841 - val_loss: 0.0233 - val_acc: 0.9918\n",
      "\n",
      "Epoch 11/30                                                         \n",
      " - 14s - loss: 0.0481 - acc: 0.9846 - val_loss: 0.0287 - val_acc: 0.9906\n",
      "\n",
      "Epoch 12/30                                                         \n",
      " - 13s - loss: 0.0479 - acc: 0.9842 - val_loss: 0.0230 - val_acc: 0.9927\n",
      "\n",
      "Epoch 13/30                                                         \n",
      " - 14s - loss: 0.0464 - acc: 0.9851 - val_loss: 0.0315 - val_acc: 0.9906\n",
      "\n",
      "Epoch 14/30                                                         \n",
      " - 13s - loss: 0.0437 - acc: 0.9864 - val_loss: 0.0236 - val_acc: 0.9930\n",
      "\n",
      "Epoch 15/30                                                         \n",
      " - 13s - loss: 0.0456 - acc: 0.9852 - val_loss: 0.0273 - val_acc: 0.9910\n",
      "\n",
      "Epoch 1/30                                                          \n",
      " - 19s - loss: 0.6171 - acc: 0.7981 - val_loss: 0.1144 - val_acc: 0.9661\n",
      "\n",
      "Epoch 2/30                                                          \n",
      " - 13s - loss: 0.2044 - acc: 0.9350 - val_loss: 0.0610 - val_acc: 0.9804\n",
      "\n",
      "Epoch 3/30                                                          \n",
      " - 14s - loss: 0.1512 - acc: 0.9518 - val_loss: 0.0584 - val_acc: 0.9808\n",
      "\n",
      "Epoch 4/30                                                          \n",
      " - 13s - loss: 0.1247 - acc: 0.9606 - val_loss: 0.0534 - val_acc: 0.9819\n",
      "\n",
      "Epoch 5/30                                                          \n",
      " - 13s - loss: 0.1093 - acc: 0.9651 - val_loss: 0.0426 - val_acc: 0.9857\n",
      "\n",
      "Epoch 6/30                                                          \n",
      " - 13s - loss: 0.0970 - acc: 0.9692 - val_loss: 0.0425 - val_acc: 0.9870\n",
      "\n",
      "Epoch 7/30                                                          \n",
      " - 13s - loss: 0.0880 - acc: 0.9725 - val_loss: 0.0396 - val_acc: 0.9879\n",
      "\n",
      "Epoch 8/30                                                          \n",
      " - 13s - loss: 0.0840 - acc: 0.9735 - val_loss: 0.0314 - val_acc: 0.9896\n",
      "\n",
      "Epoch 9/30                                                          \n",
      " - 14s - loss: 0.0759 - acc: 0.9761 - val_loss: 0.0391 - val_acc: 0.9874\n",
      "\n",
      "Epoch 10/30                                                         \n",
      " - 14s - loss: 0.0720 - acc: 0.9776 - val_loss: 0.0279 - val_acc: 0.9901\n",
      "\n",
      "Epoch 11/30                                                         \n",
      " - 13s - loss: 0.0696 - acc: 0.9781 - val_loss: 0.0369 - val_acc: 0.9905\n",
      "\n",
      "Epoch 12/30                                                         \n",
      " - 13s - loss: 0.0696 - acc: 0.9785 - val_loss: 0.0271 - val_acc: 0.9918\n",
      "\n",
      "Epoch 13/30                                                         \n",
      " - 13s - loss: 0.0616 - acc: 0.9807 - val_loss: 0.0255 - val_acc: 0.9923\n",
      "\n",
      "Epoch 14/30                                                         \n",
      " - 13s - loss: 0.0615 - acc: 0.9802 - val_loss: 0.0263 - val_acc: 0.9915\n",
      "\n",
      "Epoch 15/30                                                         \n",
      " - 13s - loss: 0.0568 - acc: 0.9817 - val_loss: 0.0287 - val_acc: 0.9917\n",
      "\n",
      "Epoch 16/30                                                         \n",
      " - 13s - loss: 0.0584 - acc: 0.9819 - val_loss: 0.0257 - val_acc: 0.9920\n",
      "\n",
      "Epoch 1/30                                                           \n",
      " - 20s - loss: 0.4689 - acc: 0.8664 - val_loss: 0.1439 - val_acc: 0.9642\n",
      "\n",
      "Epoch 2/30                                                           \n",
      " - 14s - loss: 0.1875 - acc: 0.9494 - val_loss: 0.0653 - val_acc: 0.9775\n",
      "\n",
      "Epoch 3/30                                                           \n",
      " - 13s - loss: 0.1474 - acc: 0.9587 - val_loss: 0.0494 - val_acc: 0.9864\n",
      "\n",
      "Epoch 4/30                                                           \n",
      " - 14s - loss: 0.1163 - acc: 0.9664 - val_loss: 0.0449 - val_acc: 0.9868\n",
      "\n",
      "Epoch 5/30                                                           \n",
      " - 14s - loss: 0.1085 - acc: 0.9690 - val_loss: 0.0532 - val_acc: 0.9832\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30                                                           \n",
      " - 14s - loss: 0.0968 - acc: 0.9724 - val_loss: 0.0390 - val_acc: 0.9882\n",
      "\n",
      "Epoch 7/30                                                           \n",
      " - 14s - loss: 0.0925 - acc: 0.9725 - val_loss: 0.0324 - val_acc: 0.9894\n",
      "\n",
      "Epoch 8/30                                                           \n",
      " - 13s - loss: 0.0977 - acc: 0.9727 - val_loss: 0.0340 - val_acc: 0.9888\n",
      "\n",
      "Epoch 9/30                                                           \n",
      " - 14s - loss: 0.0794 - acc: 0.9767 - val_loss: 0.0294 - val_acc: 0.9911\n",
      "\n",
      "Epoch 10/30                                                          \n",
      " - 14s - loss: 0.0838 - acc: 0.9761 - val_loss: 0.0540 - val_acc: 0.9869\n",
      "\n",
      "Epoch 11/30                                                          \n",
      " - 13s - loss: 0.0861 - acc: 0.9764 - val_loss: 0.0399 - val_acc: 0.9877\n",
      "\n",
      "Epoch 12/30                                                          \n",
      " - 14s - loss: 0.0607 - acc: 0.9826 - val_loss: 0.0260 - val_acc: 0.9929\n",
      "\n",
      "Epoch 13/30                                                          \n",
      " - 14s - loss: 0.0481 - acc: 0.9857 - val_loss: 0.0257 - val_acc: 0.9930\n",
      "\n",
      "Epoch 14/30                                                          \n",
      " - 14s - loss: 0.0441 - acc: 0.9870 - val_loss: 0.0216 - val_acc: 0.9935\n",
      "\n",
      "Epoch 15/30                                                          \n",
      " - 13s - loss: 0.0450 - acc: 0.9864 - val_loss: 0.0249 - val_acc: 0.9933\n",
      "\n",
      "Epoch 16/30                                                          \n",
      " - 14s - loss: 0.0427 - acc: 0.9875 - val_loss: 0.0283 - val_acc: 0.9921\n",
      "\n",
      "Epoch 17/30                                                          \n",
      " - 14s - loss: 0.0367 - acc: 0.9886 - val_loss: 0.0209 - val_acc: 0.9939\n",
      "\n",
      "Epoch 18/30                                                          \n",
      " - 14s - loss: 0.0334 - acc: 0.9902 - val_loss: 0.0223 - val_acc: 0.9937\n",
      "\n",
      "Epoch 19/30                                                          \n",
      " - 14s - loss: 0.0329 - acc: 0.9901 - val_loss: 0.0224 - val_acc: 0.9948\n",
      "\n",
      "Epoch 20/30                                                          \n",
      " - 14s - loss: 0.0328 - acc: 0.9903 - val_loss: 0.0203 - val_acc: 0.9942\n",
      "\n",
      "Epoch 21/30                                                          \n",
      " - 14s - loss: 0.0333 - acc: 0.9900 - val_loss: 0.0223 - val_acc: 0.9943\n",
      "\n",
      "Epoch 22/30                                                          \n",
      " - 14s - loss: 0.0297 - acc: 0.9911 - val_loss: 0.0177 - val_acc: 0.9946\n",
      "\n",
      "Epoch 23/30                                                          \n",
      " - 14s - loss: 0.0312 - acc: 0.9912 - val_loss: 0.0224 - val_acc: 0.9944\n",
      "\n",
      "Epoch 24/30                                                          \n",
      " - 13s - loss: 0.0291 - acc: 0.9914 - val_loss: 0.0213 - val_acc: 0.9943\n",
      "\n",
      "Epoch 25/30                                                          \n",
      " - 14s - loss: 0.0279 - acc: 0.9909 - val_loss: 0.0183 - val_acc: 0.9948\n",
      "\n",
      "Epoch 1/30                                                           \n",
      " - 21s - loss: 0.2754 - acc: 0.9363 - val_loss: 0.2048 - val_acc: 0.9676\n",
      "\n",
      "Epoch 2/30                                                           \n",
      " - 14s - loss: 0.1504 - acc: 0.9709 - val_loss: 0.0826 - val_acc: 0.9850\n",
      "\n",
      "Epoch 3/30                                                           \n",
      " - 14s - loss: 0.1017 - acc: 0.9784 - val_loss: 0.0567 - val_acc: 0.9879\n",
      "\n",
      "Epoch 4/30                                                           \n",
      " - 14s - loss: 0.0885 - acc: 0.9801 - val_loss: 0.0714 - val_acc: 0.9887\n",
      "\n",
      "Epoch 5/30                                                           \n",
      " - 14s - loss: 0.0720 - acc: 0.9837 - val_loss: 0.0469 - val_acc: 0.9913\n",
      "\n",
      "Epoch 6/30                                                           \n",
      " - 14s - loss: 0.0533 - acc: 0.9864 - val_loss: 0.0590 - val_acc: 0.9904\n",
      "\n",
      "Epoch 7/30                                                           \n",
      " - 14s - loss: 0.0631 - acc: 0.9846 - val_loss: 0.0561 - val_acc: 0.9894\n",
      "\n",
      "Epoch 8/30                                                           \n",
      " - 14s - loss: 0.0353 - acc: 0.9910 - val_loss: 0.0250 - val_acc: 0.9939\n",
      "\n",
      "Epoch 9/30                                                           \n",
      " - 14s - loss: 0.0225 - acc: 0.9934 - val_loss: 0.0235 - val_acc: 0.9948\n",
      "\n",
      "Epoch 10/30                                                          \n",
      " - 14s - loss: 0.0220 - acc: 0.9938 - val_loss: 0.0243 - val_acc: 0.9936\n",
      "\n",
      "Epoch 11/30                                                          \n",
      " - 14s - loss: 0.0184 - acc: 0.9943 - val_loss: 0.0210 - val_acc: 0.9946\n",
      "\n",
      "Epoch 12/30                                                          \n",
      " - 14s - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0205 - val_acc: 0.9950\n",
      "\n",
      "Epoch 13/30                                                          \n",
      " - 14s - loss: 0.0192 - acc: 0.9942 - val_loss: 0.0242 - val_acc: 0.9935\n",
      "\n",
      "Epoch 14/30                                                          \n",
      " - 14s - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0245 - val_acc: 0.9945\n",
      "\n",
      "Epoch 15/30                                                          \n",
      " - 14s - loss: 0.0137 - acc: 0.9960 - val_loss: 0.0218 - val_acc: 0.9954\n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 22s - loss: 0.5127 - acc: 0.8815 - val_loss: 0.3727 - val_acc: 0.9604          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 15s - loss: 0.2329 - acc: 0.9503 - val_loss: 0.1801 - val_acc: 0.9793          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 14s - loss: 0.1848 - acc: 0.9592 - val_loss: 0.1309 - val_acc: 0.9751          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 14s - loss: 0.1597 - acc: 0.9665 - val_loss: 0.1286 - val_acc: 0.9854          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 14s - loss: 0.1513 - acc: 0.9687 - val_loss: 0.1181 - val_acc: 0.9815          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 14s - loss: 0.1572 - acc: 0.9696 - val_loss: 0.0928 - val_acc: 0.9892          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 14s - loss: 0.1491 - acc: 0.9701 - val_loss: 0.1040 - val_acc: 0.9886          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 14s - loss: 0.1456 - acc: 0.9723 - val_loss: 0.0903 - val_acc: 0.9904          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 14s - loss: 0.1502 - acc: 0.9740 - val_loss: 0.0797 - val_acc: 0.9887          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 14s - loss: 0.1533 - acc: 0.9745 - val_loss: 0.0630 - val_acc: 0.9923          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 14s - loss: 0.1473 - acc: 0.9753 - val_loss: 0.1024 - val_acc: 0.9867          \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.1444 - acc: 0.9773 - val_loss: 0.0659 - val_acc: 0.9910            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 15s - loss: 0.1214 - acc: 0.9816 - val_loss: 0.0496 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 14s - loss: 0.1000 - acc: 0.9836 - val_loss: 0.0544 - val_acc: 0.9937            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 14s - loss: 0.0914 - acc: 0.9850 - val_loss: 0.0555 - val_acc: 0.9942            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 14s - loss: 0.0852 - acc: 0.9862 - val_loss: 0.0532 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 23s - loss: 0.2821 - acc: 0.9110 - val_loss: 0.0573 - val_acc: 0.9829            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1029 - acc: 0.9681 - val_loss: 0.0449 - val_acc: 0.9864            \n",
      "\n",
      "Epoch 3/30                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 15s - loss: 0.0820 - acc: 0.9738 - val_loss: 0.0434 - val_acc: 0.9875            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.0646 - acc: 0.9794 - val_loss: 0.0297 - val_acc: 0.9911            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0583 - acc: 0.9808 - val_loss: 0.0317 - val_acc: 0.9895            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0523 - acc: 0.9835 - val_loss: 0.0316 - val_acc: 0.9892            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0454 - acc: 0.9856 - val_loss: 0.0255 - val_acc: 0.9915            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0411 - acc: 0.9875 - val_loss: 0.0258 - val_acc: 0.9923            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0403 - acc: 0.9874 - val_loss: 0.0236 - val_acc: 0.9919            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0389 - acc: 0.9885 - val_loss: 0.0235 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0398 - acc: 0.9875 - val_loss: 0.0253 - val_acc: 0.9917            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 15s - loss: 0.0369 - acc: 0.9885 - val_loss: 0.0241 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 15s - loss: 0.0343 - acc: 0.9890 - val_loss: 0.0221 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 15s - loss: 0.0374 - acc: 0.9882 - val_loss: 0.0223 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 15s - loss: 0.0373 - acc: 0.9885 - val_loss: 0.0216 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 15s - loss: 0.0343 - acc: 0.9896 - val_loss: 0.0230 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 15s - loss: 0.0354 - acc: 0.9885 - val_loss: 0.0234 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 15s - loss: 0.0331 - acc: 0.9893 - val_loss: 0.0208 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 19/30                                                                         \n",
      " - 15s - loss: 0.0372 - acc: 0.9885 - val_loss: 0.0216 - val_acc: 0.9930            \n",
      "\n",
      "Epoch 20/30                                                                         \n",
      " - 15s - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0246 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 21/30                                                                         \n",
      " - 15s - loss: 0.0339 - acc: 0.9897 - val_loss: 0.0187 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 22/30                                                                         \n",
      " - 15s - loss: 0.0334 - acc: 0.9889 - val_loss: 0.0232 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 23/30                                                                         \n",
      " - 15s - loss: 0.0348 - acc: 0.9891 - val_loss: 0.0198 - val_acc: 0.9936            \n",
      "\n",
      "Epoch 24/30                                                                         \n",
      " - 15s - loss: 0.0333 - acc: 0.9894 - val_loss: 0.0234 - val_acc: 0.9925            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 27s - loss: 0.5423 - acc: 0.8826 - val_loss: 0.3249 - val_acc: 0.9565            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 18s - loss: 0.2459 - acc: 0.9502 - val_loss: 0.1190 - val_acc: 0.9810            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 18s - loss: 0.1682 - acc: 0.9612 - val_loss: 0.0814 - val_acc: 0.9854            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 18s - loss: 0.1362 - acc: 0.9669 - val_loss: 0.0607 - val_acc: 0.9879            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 18s - loss: 0.1351 - acc: 0.9674 - val_loss: 0.0900 - val_acc: 0.9830            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 18s - loss: 0.1263 - acc: 0.9684 - val_loss: 0.1372 - val_acc: 0.9761            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 18s - loss: 0.0803 - acc: 0.9800 - val_loss: 0.0233 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 18s - loss: 0.0620 - acc: 0.9839 - val_loss: 0.0246 - val_acc: 0.9949            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 18s - loss: 0.0544 - acc: 0.9857 - val_loss: 0.0291 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 18s - loss: 0.0541 - acc: 0.9865 - val_loss: 0.0289 - val_acc: 0.9931            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 23s - loss: 0.3664 - acc: 0.9165 - val_loss: 0.2863 - val_acc: 0.9715            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 14s - loss: 0.1919 - acc: 0.9632 - val_loss: 0.1237 - val_acc: 0.9845            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 14s - loss: 0.1414 - acc: 0.9721 - val_loss: 0.1344 - val_acc: 0.9815            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 14s - loss: 0.1246 - acc: 0.9755 - val_loss: 0.0732 - val_acc: 0.9894            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 14s - loss: 0.1027 - acc: 0.9784 - val_loss: 0.2016 - val_acc: 0.9810            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.1106 - acc: 0.9785 - val_loss: 0.0675 - val_acc: 0.9888            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 14s - loss: 0.1039 - acc: 0.9795 - val_loss: 0.0651 - val_acc: 0.9910            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 14s - loss: 0.0937 - acc: 0.9821 - val_loss: 0.0638 - val_acc: 0.9911            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 14s - loss: 0.0894 - acc: 0.9838 - val_loss: 0.1246 - val_acc: 0.9861            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 14s - loss: 0.0872 - acc: 0.9834 - val_loss: 0.0754 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 14s - loss: 0.0593 - acc: 0.9880 - val_loss: 0.0526 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.0509 - acc: 0.9902 - val_loss: 0.0538 - val_acc: 0.9937            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 13s - loss: 0.0484 - acc: 0.9904 - val_loss: 0.0543 - val_acc: 0.9945            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 14s - loss: 0.0418 - acc: 0.9915 - val_loss: 0.0444 - val_acc: 0.9956            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 14s - loss: 0.0347 - acc: 0.9926 - val_loss: 0.0417 - val_acc: 0.9954            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 14s - loss: 0.0357 - acc: 0.9925 - val_loss: 0.0501 - val_acc: 0.9949            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30                                                                         \n",
      " - 14s - loss: 0.0323 - acc: 0.9934 - val_loss: 0.0360 - val_acc: 0.9964            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 14s - loss: 0.0322 - acc: 0.9933 - val_loss: 0.0428 - val_acc: 0.9956            \n",
      "\n",
      "Epoch 19/30                                                                         \n",
      " - 14s - loss: 0.0341 - acc: 0.9940 - val_loss: 0.0427 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 20/30                                                                         \n",
      " - 14s - loss: 0.0329 - acc: 0.9933 - val_loss: 0.0440 - val_acc: 0.9950            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 23s - loss: 0.7654 - acc: 0.7562 - val_loss: 0.1295 - val_acc: 0.9629            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 14s - loss: 0.2781 - acc: 0.9148 - val_loss: 0.0799 - val_acc: 0.9763            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 14s - loss: 0.1998 - acc: 0.9381 - val_loss: 0.0516 - val_acc: 0.9840            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 14s - loss: 0.1668 - acc: 0.9499 - val_loss: 0.0578 - val_acc: 0.9817            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 14s - loss: 0.1403 - acc: 0.9565 - val_loss: 0.0448 - val_acc: 0.9863            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.1217 - acc: 0.9631 - val_loss: 0.0367 - val_acc: 0.9879            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 14s - loss: 0.1095 - acc: 0.9655 - val_loss: 0.0386 - val_acc: 0.9869            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 14s - loss: 0.1114 - acc: 0.9677 - val_loss: 0.0338 - val_acc: 0.9890            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 14s - loss: 0.1009 - acc: 0.9693 - val_loss: 0.0353 - val_acc: 0.9894            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 14s - loss: 0.0920 - acc: 0.9721 - val_loss: 0.0337 - val_acc: 0.9894            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 14s - loss: 0.0882 - acc: 0.9727 - val_loss: 0.0312 - val_acc: 0.9914            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.0813 - acc: 0.9754 - val_loss: 0.0303 - val_acc: 0.9907            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 14s - loss: 0.0836 - acc: 0.9750 - val_loss: 0.0273 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 14s - loss: 0.0807 - acc: 0.9765 - val_loss: 0.0306 - val_acc: 0.9914            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 14s - loss: 0.0722 - acc: 0.9780 - val_loss: 0.0309 - val_acc: 0.9913            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 14s - loss: 0.0743 - acc: 0.9776 - val_loss: 0.0241 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 14s - loss: 0.0655 - acc: 0.9806 - val_loss: 0.0246 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 14s - loss: 0.0690 - acc: 0.9792 - val_loss: 0.0235 - val_acc: 0.9936            \n",
      "\n",
      "Epoch 19/30                                                                         \n",
      " - 14s - loss: 0.0667 - acc: 0.9797 - val_loss: 0.0243 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 20/30                                                                         \n",
      " - 14s - loss: 0.0677 - acc: 0.9796 - val_loss: 0.0275 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 21/30                                                                         \n",
      " - 14s - loss: 0.0658 - acc: 0.9801 - val_loss: 0.0198 - val_acc: 0.9942            \n",
      "\n",
      "Epoch 22/30                                                                         \n",
      " - 14s - loss: 0.0663 - acc: 0.9799 - val_loss: 0.0246 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 23/30                                                                         \n",
      " - 14s - loss: 0.0644 - acc: 0.9807 - val_loss: 0.0273 - val_acc: 0.9923            \n",
      "\n",
      "Epoch 24/30                                                                         \n",
      " - 14s - loss: 0.0650 - acc: 0.9798 - val_loss: 0.0184 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 25/30                                                                         \n",
      " - 14s - loss: 0.0635 - acc: 0.9806 - val_loss: 0.0275 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 26/30                                                                         \n",
      " - 14s - loss: 0.0636 - acc: 0.9811 - val_loss: 0.0245 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 27/30                                                                         \n",
      " - 14s - loss: 0.0599 - acc: 0.9817 - val_loss: 0.0225 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 24s - loss: 0.3980 - acc: 0.8750 - val_loss: 0.0950 - val_acc: 0.9718            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 14s - loss: 0.1621 - acc: 0.9497 - val_loss: 0.0514 - val_acc: 0.9833            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 14s - loss: 0.1247 - acc: 0.9618 - val_loss: 0.0448 - val_acc: 0.9846            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 14s - loss: 0.1068 - acc: 0.9671 - val_loss: 0.0344 - val_acc: 0.9882            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 14s - loss: 0.0898 - acc: 0.9729 - val_loss: 0.0422 - val_acc: 0.9873            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.0751 - acc: 0.9761 - val_loss: 0.0293 - val_acc: 0.9908            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 14s - loss: 0.0708 - acc: 0.9783 - val_loss: 0.0334 - val_acc: 0.9904            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 14s - loss: 0.0696 - acc: 0.9784 - val_loss: 0.0306 - val_acc: 0.9900            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0629 - acc: 0.9807 - val_loss: 0.0280 - val_acc: 0.9912            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 14s - loss: 0.0558 - acc: 0.9829 - val_loss: 0.0236 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 14s - loss: 0.0570 - acc: 0.9826 - val_loss: 0.0267 - val_acc: 0.9915            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.0530 - acc: 0.9837 - val_loss: 0.0240 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 14s - loss: 0.0493 - acc: 0.9849 - val_loss: 0.0239 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 24s - loss: 0.4408 - acc: 0.8600 - val_loss: 0.1750 - val_acc: 0.9555            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 14s - loss: 0.1783 - acc: 0.9471 - val_loss: 0.1170 - val_acc: 0.9671            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 14s - loss: 0.1328 - acc: 0.9591 - val_loss: 0.0642 - val_acc: 0.9825            \n",
      "\n",
      "Epoch 4/30                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 15s - loss: 0.1175 - acc: 0.9656 - val_loss: 0.0693 - val_acc: 0.9798            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 14s - loss: 0.1004 - acc: 0.9695 - val_loss: 0.0393 - val_acc: 0.9877            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.0913 - acc: 0.9726 - val_loss: 0.0270 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0869 - acc: 0.9737 - val_loss: 0.0312 - val_acc: 0.9901            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 14s - loss: 0.0786 - acc: 0.9759 - val_loss: 0.0509 - val_acc: 0.9844            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 14s - loss: 0.0578 - acc: 0.9821 - val_loss: 0.0218 - val_acc: 0.9937            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0507 - acc: 0.9845 - val_loss: 0.0238 - val_acc: 0.9940            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 14s - loss: 0.0442 - acc: 0.9874 - val_loss: 0.0232 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.0421 - acc: 0.9865 - val_loss: 0.0218 - val_acc: 0.9946            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 30s - loss: 0.3098 - acc: 0.9004 - val_loss: 0.0635 - val_acc: 0.9801            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 18s - loss: 0.1144 - acc: 0.9632 - val_loss: 0.0357 - val_acc: 0.9886            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 18s - loss: 0.0877 - acc: 0.9725 - val_loss: 0.0325 - val_acc: 0.9912            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 18s - loss: 0.0766 - acc: 0.9758 - val_loss: 0.0341 - val_acc: 0.9894            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 17s - loss: 0.0676 - acc: 0.9795 - val_loss: 0.0315 - val_acc: 0.9904            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 18s - loss: 0.0609 - acc: 0.9808 - val_loss: 0.0254 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 18s - loss: 0.0547 - acc: 0.9824 - val_loss: 0.0238 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 18s - loss: 0.0498 - acc: 0.9842 - val_loss: 0.0219 - val_acc: 0.9931            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 18s - loss: 0.0446 - acc: 0.9863 - val_loss: 0.0227 - val_acc: 0.9936            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 18s - loss: 0.0452 - acc: 0.9856 - val_loss: 0.0219 - val_acc: 0.9930            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 18s - loss: 0.0389 - acc: 0.9882 - val_loss: 0.0172 - val_acc: 0.9938            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 18s - loss: 0.0389 - acc: 0.9875 - val_loss: 0.0190 - val_acc: 0.9942            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 18s - loss: 0.0353 - acc: 0.9887 - val_loss: 0.0137 - val_acc: 0.9950            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 18s - loss: 0.0371 - acc: 0.9882 - val_loss: 0.0192 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 18s - loss: 0.0346 - acc: 0.9883 - val_loss: 0.0134 - val_acc: 0.9956            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 17s - loss: 0.0375 - acc: 0.9878 - val_loss: 0.0182 - val_acc: 0.9946            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 17s - loss: 0.0325 - acc: 0.9892 - val_loss: 0.0163 - val_acc: 0.9950            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 17s - loss: 0.0324 - acc: 0.9893 - val_loss: 0.0128 - val_acc: 0.9955            \n",
      "\n",
      "Epoch 19/30                                                                         \n",
      " - 18s - loss: 0.0327 - acc: 0.9901 - val_loss: 0.0175 - val_acc: 0.9948            \n",
      "\n",
      "Epoch 20/30                                                                         \n",
      " - 18s - loss: 0.0318 - acc: 0.9901 - val_loss: 0.0142 - val_acc: 0.9957            \n",
      "\n",
      "Epoch 21/30                                                                         \n",
      " - 17s - loss: 0.0306 - acc: 0.9897 - val_loss: 0.0159 - val_acc: 0.9954            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 27s - loss: 0.5833 - acc: 0.9192 - val_loss: 0.2125 - val_acc: 0.9798            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.3753 - acc: 0.9613 - val_loss: 0.2395 - val_acc: 0.9799            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.3165 - acc: 0.9688 - val_loss: 0.1753 - val_acc: 0.9867            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 16s - loss: 0.2935 - acc: 0.9721 - val_loss: 0.1860 - val_acc: 0.9831            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.3030 - acc: 0.9725 - val_loss: 0.3114 - val_acc: 0.9771            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.1678 - acc: 0.9840 - val_loss: 0.0845 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.1404 - acc: 0.9866 - val_loss: 0.0913 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 16s - loss: 0.1245 - acc: 0.9863 - val_loss: 0.0976 - val_acc: 0.9907            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 16s - loss: 0.0855 - acc: 0.9893 - val_loss: 0.0605 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0825 - acc: 0.9898 - val_loss: 0.0573 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0729 - acc: 0.9907 - val_loss: 0.0485 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 15s - loss: 0.0691 - acc: 0.9906 - val_loss: 0.0452 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 15s - loss: 0.0644 - acc: 0.9914 - val_loss: 0.0360 - val_acc: 0.9957            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 15s - loss: 0.0658 - acc: 0.9912 - val_loss: 0.0559 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 15s - loss: 0.0572 - acc: 0.9924 - val_loss: 0.0390 - val_acc: 0.9948            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 15s - loss: 0.0488 - acc: 0.9924 - val_loss: 0.0381 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 26s - loss: 0.2547 - acc: 0.9170 - val_loss: 0.0509 - val_acc: 0.9840            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1018 - acc: 0.9680 - val_loss: 0.0492 - val_acc: 0.9854            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.0717 - acc: 0.9766 - val_loss: 0.0340 - val_acc: 0.9894            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.0644 - acc: 0.9796 - val_loss: 0.0295 - val_acc: 0.9912            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0508 - acc: 0.9833 - val_loss: 0.0249 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.0523 - acc: 0.9834 - val_loss: 0.0188 - val_acc: 0.9937            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 14s - loss: 0.0470 - acc: 0.9853 - val_loss: 0.0235 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 14s - loss: 0.0413 - acc: 0.9866 - val_loss: 0.0316 - val_acc: 0.9914            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0368 - acc: 0.9882 - val_loss: 0.0146 - val_acc: 0.9955            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 14s - loss: 0.0344 - acc: 0.9896 - val_loss: 0.0225 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0320 - acc: 0.9898 - val_loss: 0.0226 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.0316 - acc: 0.9902 - val_loss: 0.0199 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 28s - loss: 0.1723 - acc: 0.9469 - val_loss: 0.0918 - val_acc: 0.9721            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 14s - loss: 0.0690 - acc: 0.9771 - val_loss: 0.0359 - val_acc: 0.9886            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 14s - loss: 0.0530 - acc: 0.9827 - val_loss: 0.0342 - val_acc: 0.9892            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 14s - loss: 0.0442 - acc: 0.9860 - val_loss: 0.0211 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0411 - acc: 0.9873 - val_loss: 0.0277 - val_acc: 0.9902            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.0342 - acc: 0.9897 - val_loss: 0.0252 - val_acc: 0.9911            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0279 - acc: 0.9907 - val_loss: 0.0175 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0196 - val_acc: 0.9940            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 14s - loss: 0.0232 - acc: 0.9925 - val_loss: 0.0207 - val_acc: 0.9940            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 14s - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0205 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 27s - loss: 0.2539 - acc: 0.9189 - val_loss: 0.0575 - val_acc: 0.9827            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1015 - acc: 0.9676 - val_loss: 0.0413 - val_acc: 0.9871            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 14s - loss: 0.0792 - acc: 0.9749 - val_loss: 0.0306 - val_acc: 0.9914            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 14s - loss: 0.0676 - acc: 0.9783 - val_loss: 0.0350 - val_acc: 0.9905            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0535 - acc: 0.9830 - val_loss: 0.0236 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 14s - loss: 0.0477 - acc: 0.9847 - val_loss: 0.0280 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 14s - loss: 0.0470 - acc: 0.9852 - val_loss: 0.0212 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 14s - loss: 0.0419 - acc: 0.9869 - val_loss: 0.0222 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 14s - loss: 0.0390 - acc: 0.9870 - val_loss: 0.0247 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0360 - acc: 0.9885 - val_loss: 0.0207 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 14s - loss: 0.0327 - acc: 0.9897 - val_loss: 0.0197 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 14s - loss: 0.0318 - acc: 0.9901 - val_loss: 0.0190 - val_acc: 0.9940            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 14s - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0212 - val_acc: 0.9942            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 14s - loss: 0.0310 - acc: 0.9910 - val_loss: 0.0180 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 14s - loss: 0.0274 - acc: 0.9909 - val_loss: 0.0190 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 14s - loss: 0.0297 - acc: 0.9902 - val_loss: 0.0173 - val_acc: 0.9940            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 15s - loss: 0.0283 - acc: 0.9905 - val_loss: 0.0190 - val_acc: 0.9940            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 15s - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0166 - val_acc: 0.9949            \n",
      "\n",
      "Epoch 19/30                                                                         \n",
      " - 15s - loss: 0.0275 - acc: 0.9908 - val_loss: 0.0168 - val_acc: 0.9950            \n",
      "\n",
      "Epoch 20/30                                                                         \n",
      " - 15s - loss: 0.0269 - acc: 0.9919 - val_loss: 0.0158 - val_acc: 0.9954            \n",
      "\n",
      "Epoch 21/30                                                                         \n",
      " - 15s - loss: 0.0259 - acc: 0.9917 - val_loss: 0.0181 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 22/30                                                                         \n",
      " - 15s - loss: 0.0275 - acc: 0.9913 - val_loss: 0.0151 - val_acc: 0.9956            \n",
      "\n",
      "Epoch 23/30                                                                         \n",
      " - 15s - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0212 - val_acc: 0.9931            \n",
      "\n",
      "Epoch 24/30                                                                         \n",
      " - 15s - loss: 0.0257 - acc: 0.9922 - val_loss: 0.0167 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 25/30                                                                         \n",
      " - 15s - loss: 0.0243 - acc: 0.9915 - val_loss: 0.0186 - val_acc: 0.9944            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 27s - loss: 0.2612 - acc: 0.9184 - val_loss: 0.0539 - val_acc: 0.9833            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 14s - loss: 0.1021 - acc: 0.9677 - val_loss: 0.0409 - val_acc: 0.9879            \n",
      "\n",
      "Epoch 3/30                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 14s - loss: 0.0720 - acc: 0.9781 - val_loss: 0.0278 - val_acc: 0.9902            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 14s - loss: 0.0647 - acc: 0.9785 - val_loss: 0.0295 - val_acc: 0.9920            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0559 - acc: 0.9820 - val_loss: 0.0308 - val_acc: 0.9904            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0500 - acc: 0.9844 - val_loss: 0.0211 - val_acc: 0.9937            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0453 - acc: 0.9854 - val_loss: 0.0219 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0433 - acc: 0.9857 - val_loss: 0.0225 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0417 - acc: 0.9864 - val_loss: 0.0217 - val_acc: 0.9931            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 31s - loss: 0.2414 - acc: 0.9236 - val_loss: 0.0545 - val_acc: 0.9825            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 17s - loss: 0.0993 - acc: 0.9687 - val_loss: 0.0492 - val_acc: 0.9857            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 17s - loss: 0.0761 - acc: 0.9757 - val_loss: 0.0295 - val_acc: 0.9910            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 17s - loss: 0.0605 - acc: 0.9812 - val_loss: 0.0292 - val_acc: 0.9917            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 17s - loss: 0.0532 - acc: 0.9825 - val_loss: 0.0253 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 17s - loss: 0.0452 - acc: 0.9859 - val_loss: 0.0246 - val_acc: 0.9919            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 17s - loss: 0.0452 - acc: 0.9854 - val_loss: 0.0266 - val_acc: 0.9923            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 18s - loss: 0.0399 - acc: 0.9871 - val_loss: 0.0199 - val_acc: 0.9936            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 17s - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0228 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 17s - loss: 0.0362 - acc: 0.9885 - val_loss: 0.0231 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 17s - loss: 0.0343 - acc: 0.9894 - val_loss: 0.0175 - val_acc: 0.9942            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 17s - loss: 0.0312 - acc: 0.9906 - val_loss: 0.0188 - val_acc: 0.9946            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 17s - loss: 0.0314 - acc: 0.9900 - val_loss: 0.0204 - val_acc: 0.9944            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 17s - loss: 0.0269 - acc: 0.9913 - val_loss: 0.0196 - val_acc: 0.9938            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 28s - loss: 0.1715 - acc: 0.9469 - val_loss: 0.0524 - val_acc: 0.9857            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.0670 - acc: 0.9789 - val_loss: 0.0355 - val_acc: 0.9886            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.0565 - acc: 0.9823 - val_loss: 0.0417 - val_acc: 0.9876            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.0458 - acc: 0.9862 - val_loss: 0.0297 - val_acc: 0.9912            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0362 - acc: 0.9889 - val_loss: 0.0251 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0315 - acc: 0.9902 - val_loss: 0.0254 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0318 - acc: 0.9903 - val_loss: 0.0232 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0280 - acc: 0.9905 - val_loss: 0.0223 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 14s - loss: 0.0270 - acc: 0.9916 - val_loss: 0.0210 - val_acc: 0.9933            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0235 - acc: 0.9927 - val_loss: 0.0245 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0224 - acc: 0.9931 - val_loss: 0.0188 - val_acc: 0.9956            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 15s - loss: 0.0211 - acc: 0.9932 - val_loss: 0.0216 - val_acc: 0.9931            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 15s - loss: 0.0202 - acc: 0.9935 - val_loss: 0.0229 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 15s - loss: 0.0177 - acc: 0.9944 - val_loss: 0.0146 - val_acc: 0.9957            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 15s - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0235 - val_acc: 0.9939            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 15s - loss: 0.0149 - acc: 0.9954 - val_loss: 0.0141 - val_acc: 0.9955            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 15s - loss: 0.0165 - acc: 0.9951 - val_loss: 0.0184 - val_acc: 0.9945            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 15s - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0176 - val_acc: 0.9952            \n",
      "\n",
      "Epoch 19/30                                                                         \n",
      " - 15s - loss: 0.0151 - acc: 0.9956 - val_loss: 0.0175 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 29s - loss: 0.2600 - acc: 0.9187 - val_loss: 0.0584 - val_acc: 0.9812            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1012 - acc: 0.9680 - val_loss: 0.0529 - val_acc: 0.9851            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.0765 - acc: 0.9761 - val_loss: 0.0409 - val_acc: 0.9901            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.0656 - acc: 0.9799 - val_loss: 0.0251 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0569 - acc: 0.9821 - val_loss: 0.0341 - val_acc: 0.9904            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0520 - acc: 0.9841 - val_loss: 0.0209 - val_acc: 0.9937            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 16s - loss: 0.0456 - acc: 0.9854 - val_loss: 0.0276 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0459 - acc: 0.9855 - val_loss: 0.0247 - val_acc: 0.9925            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0383 - acc: 0.9876 - val_loss: 0.0219 - val_acc: 0.9930            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 29s - loss: 0.5410 - acc: 0.8257 - val_loss: 0.0846 - val_acc: 0.9732            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1835 - acc: 0.9438 - val_loss: 0.0549 - val_acc: 0.9832            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.1286 - acc: 0.9605 - val_loss: 0.0496 - val_acc: 0.9850            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.1089 - acc: 0.9670 - val_loss: 0.0376 - val_acc: 0.9880            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0955 - acc: 0.9707 - val_loss: 0.0380 - val_acc: 0.9874            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0814 - acc: 0.9741 - val_loss: 0.0307 - val_acc: 0.9893            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 16s - loss: 0.0809 - acc: 0.9749 - val_loss: 0.0490 - val_acc: 0.9855            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0723 - acc: 0.9768 - val_loss: 0.0297 - val_acc: 0.9896            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0669 - acc: 0.9783 - val_loss: 0.0276 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0611 - acc: 0.9806 - val_loss: 0.0310 - val_acc: 0.9889            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0603 - acc: 0.9812 - val_loss: 0.0387 - val_acc: 0.9900            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 15s - loss: 0.0513 - acc: 0.9838 - val_loss: 0.0245 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 15s - loss: 0.0521 - acc: 0.9844 - val_loss: 0.0201 - val_acc: 0.9935            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 15s - loss: 0.0533 - acc: 0.9838 - val_loss: 0.0261 - val_acc: 0.9925            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 15s - loss: 0.0453 - acc: 0.9858 - val_loss: 0.0223 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 15s - loss: 0.0484 - acc: 0.9851 - val_loss: 0.0218 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 29s - loss: 0.4198 - acc: 0.8675 - val_loss: 0.0541 - val_acc: 0.9825            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1570 - acc: 0.9512 - val_loss: 0.0437 - val_acc: 0.9858            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.1191 - acc: 0.9624 - val_loss: 0.0337 - val_acc: 0.9890            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.0992 - acc: 0.9684 - val_loss: 0.0347 - val_acc: 0.9889            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0865 - acc: 0.9735 - val_loss: 0.0412 - val_acc: 0.9879            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0780 - acc: 0.9763 - val_loss: 0.0242 - val_acc: 0.9923            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0688 - acc: 0.9781 - val_loss: 0.0266 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0733 - acc: 0.9769 - val_loss: 0.0247 - val_acc: 0.9925            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0648 - acc: 0.9794 - val_loss: 0.0235 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 16s - loss: 0.0675 - acc: 0.9789 - val_loss: 0.0257 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0642 - acc: 0.9795 - val_loss: 0.0243 - val_acc: 0.9930            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 15s - loss: 0.0666 - acc: 0.9792 - val_loss: 0.0257 - val_acc: 0.9924            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 29s - loss: 0.2276 - acc: 0.9388 - val_loss: 0.0552 - val_acc: 0.9852            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.0762 - acc: 0.9790 - val_loss: 0.0507 - val_acc: 0.9836            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.0549 - acc: 0.9841 - val_loss: 0.0339 - val_acc: 0.9898            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.0483 - acc: 0.9865 - val_loss: 0.0323 - val_acc: 0.9894            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 16s - loss: 0.0413 - acc: 0.9882 - val_loss: 0.0358 - val_acc: 0.9896            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0362 - acc: 0.9888 - val_loss: 0.0319 - val_acc: 0.9902            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0340 - acc: 0.9898 - val_loss: 0.0289 - val_acc: 0.9913            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0314 - acc: 0.9907 - val_loss: 0.0252 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0283 - acc: 0.9919 - val_loss: 0.0235 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0285 - acc: 0.9908 - val_loss: 0.0225 - val_acc: 0.9930            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0264 - acc: 0.9923 - val_loss: 0.0183 - val_acc: 0.9948            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 15s - loss: 0.0235 - acc: 0.9927 - val_loss: 0.0218 - val_acc: 0.9932            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 15s - loss: 0.0221 - acc: 0.9932 - val_loss: 0.0203 - val_acc: 0.9930            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 16s - loss: 0.0188 - acc: 0.9947 - val_loss: 0.0170 - val_acc: 0.9944            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 15s - loss: 0.0162 - acc: 0.9954 - val_loss: 0.0175 - val_acc: 0.9946            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 15s - loss: 0.0165 - acc: 0.9953 - val_loss: 0.0174 - val_acc: 0.9946            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 15s - loss: 0.0150 - acc: 0.9956 - val_loss: 0.0166 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 15s - loss: 0.0139 - acc: 0.9963 - val_loss: 0.0159 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 19/30                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 0.0150 - acc: 0.9957 - val_loss: 0.0169 - val_acc: 0.9949            \n",
      "\n",
      "Epoch 20/30                                                                         \n",
      " - 15s - loss: 0.0153 - acc: 0.9959 - val_loss: 0.0166 - val_acc: 0.9951            \n",
      "\n",
      "Epoch 21/30                                                                         \n",
      " - 15s - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0165 - val_acc: 0.9950            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 30s - loss: 0.4987 - acc: 0.8427 - val_loss: 0.1087 - val_acc: 0.9671            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 15s - loss: 0.1680 - acc: 0.9492 - val_loss: 0.0691 - val_acc: 0.9795            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.1223 - acc: 0.9624 - val_loss: 0.0353 - val_acc: 0.9888            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.1006 - acc: 0.9689 - val_loss: 0.0487 - val_acc: 0.9848            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0887 - acc: 0.9727 - val_loss: 0.0361 - val_acc: 0.9892            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0773 - acc: 0.9755 - val_loss: 0.0344 - val_acc: 0.9898            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0250 - val_acc: 0.9921            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0721 - acc: 0.9776 - val_loss: 0.0332 - val_acc: 0.9898            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 15s - loss: 0.0685 - acc: 0.9786 - val_loss: 0.0296 - val_acc: 0.9905            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0676 - acc: 0.9786 - val_loss: 0.0286 - val_acc: 0.9906            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 35s - loss: 0.3322 - acc: 0.9121 - val_loss: 0.1658 - val_acc: 0.9780            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 18s - loss: 0.1908 - acc: 0.9568 - val_loss: 0.1393 - val_acc: 0.9829            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 18s - loss: 0.1404 - acc: 0.9679 - val_loss: 0.1026 - val_acc: 0.9850            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 19s - loss: 0.1349 - acc: 0.9701 - val_loss: 0.1686 - val_acc: 0.9743            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 18s - loss: 0.1292 - acc: 0.9723 - val_loss: 0.0548 - val_acc: 0.9899            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 18s - loss: 0.1349 - acc: 0.9721 - val_loss: 0.0624 - val_acc: 0.9906            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 19s - loss: 0.1141 - acc: 0.9757 - val_loss: 0.0719 - val_acc: 0.9886            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 19s - loss: 0.0845 - acc: 0.9818 - val_loss: 0.0561 - val_acc: 0.9912            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 31s - loss: 0.4166 - acc: 0.8683 - val_loss: 0.0654 - val_acc: 0.9773            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 16s - loss: 0.1473 - acc: 0.9548 - val_loss: 0.0670 - val_acc: 0.9776            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.1055 - acc: 0.9675 - val_loss: 0.0515 - val_acc: 0.9836            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 16s - loss: 0.0903 - acc: 0.9727 - val_loss: 0.0366 - val_acc: 0.9875            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.0756 - acc: 0.9767 - val_loss: 0.0440 - val_acc: 0.9864            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.0701 - acc: 0.9784 - val_loss: 0.0389 - val_acc: 0.9871            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 16s - loss: 0.0595 - acc: 0.9813 - val_loss: 0.0276 - val_acc: 0.9914            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0591 - acc: 0.9818 - val_loss: 0.0249 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 16s - loss: 0.0532 - acc: 0.9833 - val_loss: 0.0252 - val_acc: 0.9904            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0537 - acc: 0.9829 - val_loss: 0.0304 - val_acc: 0.9910            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 15s - loss: 0.0500 - acc: 0.9841 - val_loss: 0.0249 - val_acc: 0.9912            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 32s - loss: 0.4039 - acc: 0.8804 - val_loss: 0.0770 - val_acc: 0.9777          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 15s - loss: 0.1363 - acc: 0.9582 - val_loss: 0.0777 - val_acc: 0.9730          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 15s - loss: 0.0984 - acc: 0.9692 - val_loss: 0.0796 - val_acc: 0.9790          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 15s - loss: 0.0857 - acc: 0.9746 - val_loss: 0.0329 - val_acc: 0.9898          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 16s - loss: 0.0776 - acc: 0.9769 - val_loss: 0.0379 - val_acc: 0.9886          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 15s - loss: 0.0727 - acc: 0.9785 - val_loss: 0.0391 - val_acc: 0.9885          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 16s - loss: 0.0719 - acc: 0.9790 - val_loss: 0.0335 - val_acc: 0.9895          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 32s - loss: 0.3816 - acc: 0.9165 - val_loss: 0.3787 - val_acc: 0.9611          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 16s - loss: 0.1981 - acc: 0.9608 - val_loss: 0.1979 - val_acc: 0.9800          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 16s - loss: 0.1507 - acc: 0.9689 - val_loss: 0.1114 - val_acc: 0.9861          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 15s - loss: 0.1342 - acc: 0.9738 - val_loss: 0.1051 - val_acc: 0.9807          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 16s - loss: 0.1183 - acc: 0.9765 - val_loss: 0.0787 - val_acc: 0.9856          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.1176 - acc: 0.9783 - val_loss: 0.1074 - val_acc: 0.9871          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 16s - loss: 0.1066 - acc: 0.9790 - val_loss: 0.0739 - val_acc: 0.9918          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0992 - acc: 0.9804 - val_loss: 0.0884 - val_acc: 0.9904          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 15s - loss: 0.1008 - acc: 0.9819 - val_loss: 0.0958 - val_acc: 0.9868          \n",
      "\n",
      "Epoch 10/30                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 0.0691 - acc: 0.9865 - val_loss: 0.0395 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 16s - loss: 0.0565 - acc: 0.9891 - val_loss: 0.0358 - val_acc: 0.9951          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 16s - loss: 0.0511 - acc: 0.9895 - val_loss: 0.0427 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 16s - loss: 0.0561 - acc: 0.9897 - val_loss: 0.0484 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 16s - loss: 0.0473 - acc: 0.9910 - val_loss: 0.0385 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 43s - loss: 0.2885 - acc: 0.9180 - val_loss: 0.0806 - val_acc: 0.9770          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 23s - loss: 0.1190 - acc: 0.9667 - val_loss: 0.0585 - val_acc: 0.9831          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 24s - loss: 0.0853 - acc: 0.9759 - val_loss: 0.0487 - val_acc: 0.9881          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 23s - loss: 0.0723 - acc: 0.9795 - val_loss: 0.0491 - val_acc: 0.9868          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 23s - loss: 0.0649 - acc: 0.9807 - val_loss: 0.0384 - val_acc: 0.9907          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 23s - loss: 0.0579 - acc: 0.9832 - val_loss: 0.0334 - val_acc: 0.9918          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 23s - loss: 0.0536 - acc: 0.9842 - val_loss: 0.0423 - val_acc: 0.9895          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 23s - loss: 0.0445 - acc: 0.9871 - val_loss: 0.0300 - val_acc: 0.9935          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 23s - loss: 0.0443 - acc: 0.9869 - val_loss: 0.0312 - val_acc: 0.9929          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 23s - loss: 0.0402 - acc: 0.9876 - val_loss: 0.0301 - val_acc: 0.9924          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 24s - loss: 0.0341 - acc: 0.9895 - val_loss: 0.0222 - val_acc: 0.9933          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 23s - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0240 - val_acc: 0.9932          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 23s - loss: 0.0311 - acc: 0.9911 - val_loss: 0.0250 - val_acc: 0.9935          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 23s - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0222 - val_acc: 0.9935          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 23s - loss: 0.0277 - acc: 0.9917 - val_loss: 0.0213 - val_acc: 0.9938          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 24s - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0214 - val_acc: 0.9939          \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 24s - loss: 0.0248 - acc: 0.9926 - val_loss: 0.0217 - val_acc: 0.9940          \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 24s - loss: 0.0253 - acc: 0.9921 - val_loss: 0.0210 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 24s - loss: 0.0239 - acc: 0.9929 - val_loss: 0.0205 - val_acc: 0.9943          \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 23s - loss: 0.0240 - acc: 0.9923 - val_loss: 0.0204 - val_acc: 0.9943          \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 24s - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0204 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 24s - loss: 0.0236 - acc: 0.9924 - val_loss: 0.0205 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 23s - loss: 0.0269 - acc: 0.9926 - val_loss: 0.0204 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 24s - loss: 0.0265 - acc: 0.9915 - val_loss: 0.0205 - val_acc: 0.9946          \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 23s - loss: 0.0253 - acc: 0.9925 - val_loss: 0.0205 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 26/30                                                                       \n",
      " - 24s - loss: 0.0248 - acc: 0.9925 - val_loss: 0.0205 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 33s - loss: 0.8574 - acc: 0.7248 - val_loss: 0.1646 - val_acc: 0.9519            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 16s - loss: 0.3019 - acc: 0.9083 - val_loss: 0.1017 - val_acc: 0.9711            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 15s - loss: 0.2140 - acc: 0.9342 - val_loss: 0.1034 - val_acc: 0.9669            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 15s - loss: 0.1736 - acc: 0.9469 - val_loss: 0.0713 - val_acc: 0.9779            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 15s - loss: 0.1433 - acc: 0.9551 - val_loss: 0.0490 - val_acc: 0.9840            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 15s - loss: 0.1321 - acc: 0.9592 - val_loss: 0.0528 - val_acc: 0.9836            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 15s - loss: 0.1178 - acc: 0.9632 - val_loss: 0.0466 - val_acc: 0.9855            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 16s - loss: 0.1069 - acc: 0.9661 - val_loss: 0.0466 - val_acc: 0.9851            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 16s - loss: 0.1033 - acc: 0.9682 - val_loss: 0.0492 - val_acc: 0.9857            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 16s - loss: 0.0983 - acc: 0.9684 - val_loss: 0.0346 - val_acc: 0.9898            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 16s - loss: 0.0927 - acc: 0.9702 - val_loss: 0.0362 - val_acc: 0.9880            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 16s - loss: 0.0929 - acc: 0.9705 - val_loss: 0.0383 - val_acc: 0.9879            \n",
      "\n",
      "Epoch 13/30                                                                         \n",
      " - 16s - loss: 0.0887 - acc: 0.9723 - val_loss: 0.0339 - val_acc: 0.9886            \n",
      "\n",
      "Epoch 14/30                                                                         \n",
      " - 16s - loss: 0.0917 - acc: 0.9710 - val_loss: 0.0369 - val_acc: 0.9870            \n",
      "\n",
      "Epoch 15/30                                                                         \n",
      " - 15s - loss: 0.0918 - acc: 0.9718 - val_loss: 0.0328 - val_acc: 0.9907            \n",
      "\n",
      "Epoch 16/30                                                                         \n",
      " - 16s - loss: 0.0877 - acc: 0.9726 - val_loss: 0.0351 - val_acc: 0.9893            \n",
      "\n",
      "Epoch 17/30                                                                         \n",
      " - 15s - loss: 0.0872 - acc: 0.9728 - val_loss: 0.0370 - val_acc: 0.9880            \n",
      "\n",
      "Epoch 18/30                                                                         \n",
      " - 15s - loss: 0.0857 - acc: 0.9730 - val_loss: 0.0339 - val_acc: 0.9881            \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30                                                                          \n",
      " - 34s - loss: 0.3253 - acc: 0.9127 - val_loss: 0.1139 - val_acc: 0.9807            \n",
      "\n",
      "Epoch 2/30                                                                          \n",
      " - 16s - loss: 0.1609 - acc: 0.9636 - val_loss: 0.1716 - val_acc: 0.9705            \n",
      "\n",
      "Epoch 3/30                                                                          \n",
      " - 16s - loss: 0.1301 - acc: 0.9702 - val_loss: 0.1231 - val_acc: 0.9846            \n",
      "\n",
      "Epoch 4/30                                                                          \n",
      " - 16s - loss: 0.0756 - acc: 0.9826 - val_loss: 0.0505 - val_acc: 0.9926            \n",
      "\n",
      "Epoch 5/30                                                                          \n",
      " - 16s - loss: 0.0640 - acc: 0.9851 - val_loss: 0.0426 - val_acc: 0.9929            \n",
      "\n",
      "Epoch 6/30                                                                          \n",
      " - 16s - loss: 0.0590 - acc: 0.9860 - val_loss: 0.0519 - val_acc: 0.9918            \n",
      "\n",
      "Epoch 7/30                                                                          \n",
      " - 16s - loss: 0.0569 - acc: 0.9868 - val_loss: 0.0425 - val_acc: 0.9923            \n",
      "\n",
      "Epoch 8/30                                                                          \n",
      " - 15s - loss: 0.0524 - acc: 0.9878 - val_loss: 0.0678 - val_acc: 0.9919            \n",
      "\n",
      "Epoch 9/30                                                                          \n",
      " - 16s - loss: 0.0520 - acc: 0.9862 - val_loss: 0.0399 - val_acc: 0.9946            \n",
      "\n",
      "Epoch 10/30                                                                         \n",
      " - 15s - loss: 0.0484 - acc: 0.9881 - val_loss: 0.0539 - val_acc: 0.9927            \n",
      "\n",
      "Epoch 11/30                                                                         \n",
      " - 16s - loss: 0.0552 - acc: 0.9874 - val_loss: 0.1110 - val_acc: 0.9887            \n",
      "\n",
      "Epoch 12/30                                                                         \n",
      " - 16s - loss: 0.0394 - acc: 0.9910 - val_loss: 0.0405 - val_acc: 0.9943            \n",
      "\n",
      "Epoch 1/30                                                                          \n",
      " - 42s - loss: 0.4217 - acc: 0.8791 - val_loss: 0.0716 - val_acc: 0.9781          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 23s - loss: 0.1711 - acc: 0.9516 - val_loss: 0.0684 - val_acc: 0.9813          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 22s - loss: 0.1250 - acc: 0.9640 - val_loss: 0.0454 - val_acc: 0.9890          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 23s - loss: 0.0998 - acc: 0.9713 - val_loss: 0.0379 - val_acc: 0.9896          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 23s - loss: 0.0919 - acc: 0.9740 - val_loss: 0.0381 - val_acc: 0.9895          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 22s - loss: 0.0796 - acc: 0.9764 - val_loss: 0.0550 - val_acc: 0.9868          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 23s - loss: 0.0651 - acc: 0.9806 - val_loss: 0.0218 - val_acc: 0.9927          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 23s - loss: 0.0604 - acc: 0.9813 - val_loss: 0.0271 - val_acc: 0.9925          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 23s - loss: 0.0575 - acc: 0.9834 - val_loss: 0.0210 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 23s - loss: 0.0527 - acc: 0.9841 - val_loss: 0.0249 - val_acc: 0.9926          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 23s - loss: 0.0547 - acc: 0.9838 - val_loss: 0.0197 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 23s - loss: 0.0532 - acc: 0.9845 - val_loss: 0.0218 - val_acc: 0.9931          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 23s - loss: 0.0510 - acc: 0.9850 - val_loss: 0.0221 - val_acc: 0.9933          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 23s - loss: 0.0495 - acc: 0.9854 - val_loss: 0.0172 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 22s - loss: 0.0440 - acc: 0.9864 - val_loss: 0.0259 - val_acc: 0.9931          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 22s - loss: 0.0443 - acc: 0.9867 - val_loss: 0.0204 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 23s - loss: 0.0444 - acc: 0.9861 - val_loss: 0.0193 - val_acc: 0.9939          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 36s - loss: 0.2182 - acc: 0.9395 - val_loss: 0.1395 - val_acc: 0.9727          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 16s - loss: 0.1010 - acc: 0.9735 - val_loss: 0.0986 - val_acc: 0.9783          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 16s - loss: 0.0796 - acc: 0.9790 - val_loss: 0.0588 - val_acc: 0.9870          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 16s - loss: 0.0678 - acc: 0.9816 - val_loss: 0.0455 - val_acc: 0.9890          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 16s - loss: 0.0579 - acc: 0.9847 - val_loss: 0.0470 - val_acc: 0.9877          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0535 - acc: 0.9848 - val_loss: 0.0567 - val_acc: 0.9885          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 16s - loss: 0.0287 - acc: 0.9919 - val_loss: 0.0252 - val_acc: 0.9933          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0293 - val_acc: 0.9921          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 16s - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0225 - val_acc: 0.9939          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 15s - loss: 0.0172 - acc: 0.9946 - val_loss: 0.0263 - val_acc: 0.9931          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 15s - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0269 - val_acc: 0.9936          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 16s - loss: 0.0154 - acc: 0.9954 - val_loss: 0.0224 - val_acc: 0.9936          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 15s - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0211 - val_acc: 0.9951          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 15s - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0181 - val_acc: 0.9948          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 16s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0215 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 15s - loss: 0.0107 - acc: 0.9968 - val_loss: 0.0237 - val_acc: 0.9935          \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 16s - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0194 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 37s - loss: 0.2018 - acc: 0.9386 - val_loss: 0.0844 - val_acc: 0.9777          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 16s - loss: 0.0913 - acc: 0.9749 - val_loss: 0.0747 - val_acc: 0.9832          \n",
      "\n",
      "Epoch 3/30                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 0.0716 - acc: 0.9798 - val_loss: 0.0752 - val_acc: 0.9838          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 16s - loss: 0.0651 - acc: 0.9826 - val_loss: 0.0730 - val_acc: 0.9824          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 16s - loss: 0.0517 - acc: 0.9859 - val_loss: 0.0763 - val_acc: 0.9854          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0506 - acc: 0.9851 - val_loss: 0.0316 - val_acc: 0.9921          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 16s - loss: 0.0440 - acc: 0.9865 - val_loss: 0.0342 - val_acc: 0.9931          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0436 - acc: 0.9879 - val_loss: 0.0499 - val_acc: 0.9898          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 16s - loss: 0.0228 - acc: 0.9930 - val_loss: 0.0273 - val_acc: 0.9933          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0246 - val_acc: 0.9939          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 15s - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0216 - val_acc: 0.9943          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 16s - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0220 - val_acc: 0.9943          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 16s - loss: 0.0144 - acc: 0.9955 - val_loss: 0.0172 - val_acc: 0.9956          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 15s - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0246 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 16s - loss: 0.0143 - acc: 0.9954 - val_loss: 0.0202 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 16s - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0174 - val_acc: 0.9965          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 36s - loss: 0.3440 - acc: 0.9105 - val_loss: 0.4647 - val_acc: 0.9112          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 16s - loss: 0.1564 - acc: 0.9628 - val_loss: 0.1167 - val_acc: 0.9768          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 16s - loss: 0.1286 - acc: 0.9695 - val_loss: 0.0946 - val_acc: 0.9802          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 15s - loss: 0.0929 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9848          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 15s - loss: 0.0773 - acc: 0.9798 - val_loss: 0.0497 - val_acc: 0.9870          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 15s - loss: 0.0614 - acc: 0.9829 - val_loss: 0.0611 - val_acc: 0.9844          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 15s - loss: 0.0613 - acc: 0.9824 - val_loss: 0.0538 - val_acc: 0.9862          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0354 - acc: 0.9898 - val_loss: 0.0391 - val_acc: 0.9902          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 16s - loss: 0.0311 - acc: 0.9905 - val_loss: 0.0272 - val_acc: 0.9924          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0286 - acc: 0.9916 - val_loss: 0.0263 - val_acc: 0.9927          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 16s - loss: 0.0251 - acc: 0.9916 - val_loss: 0.0282 - val_acc: 0.9927          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 16s - loss: 0.0248 - acc: 0.9929 - val_loss: 0.0327 - val_acc: 0.9914          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 16s - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0211 - val_acc: 0.9940          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 16s - loss: 0.0170 - acc: 0.9945 - val_loss: 0.0231 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 16s - loss: 0.0149 - acc: 0.9956 - val_loss: 0.0218 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 16s - loss: 0.0146 - acc: 0.9956 - val_loss: 0.0213 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 37s - loss: 0.1987 - acc: 0.9405 - val_loss: 0.0916 - val_acc: 0.9760          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 17s - loss: 0.0918 - acc: 0.9741 - val_loss: 0.0592 - val_acc: 0.9842          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 16s - loss: 0.0702 - acc: 0.9799 - val_loss: 0.0626 - val_acc: 0.9842          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 16s - loss: 0.0628 - acc: 0.9821 - val_loss: 0.0604 - val_acc: 0.9877          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 17s - loss: 0.0332 - acc: 0.9906 - val_loss: 0.0287 - val_acc: 0.9917          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 17s - loss: 0.0255 - acc: 0.9923 - val_loss: 0.0240 - val_acc: 0.9933          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 16s - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0218 - val_acc: 0.9935          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0231 - val_acc: 0.9931          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 16s - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0178 - val_acc: 0.9951          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0234 - acc: 0.9927 - val_loss: 0.0226 - val_acc: 0.9948          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 17s - loss: 0.0198 - acc: 0.9943 - val_loss: 0.0215 - val_acc: 0.9930          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 16s - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0203 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 38s - loss: 0.2393 - acc: 0.9237 - val_loss: 0.0820 - val_acc: 0.9819          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 16s - loss: 0.1017 - acc: 0.9710 - val_loss: 0.0807 - val_acc: 0.9823          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 17s - loss: 0.0840 - acc: 0.9772 - val_loss: 0.0525 - val_acc: 0.9881          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 16s - loss: 0.0659 - acc: 0.9811 - val_loss: 0.0464 - val_acc: 0.9873          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 17s - loss: 0.0676 - acc: 0.9811 - val_loss: 0.0353 - val_acc: 0.9907          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0555 - acc: 0.9842 - val_loss: 0.0233 - val_acc: 0.9931          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 16s - loss: 0.0519 - acc: 0.9843 - val_loss: 0.0322 - val_acc: 0.9917          \n",
      "\n",
      "Epoch 8/30                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 0.0477 - acc: 0.9861 - val_loss: 0.0421 - val_acc: 0.9889          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 17s - loss: 0.0280 - acc: 0.9916 - val_loss: 0.0231 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0217 - acc: 0.9936 - val_loss: 0.0180 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 16s - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0267 - val_acc: 0.9932          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 16s - loss: 0.0185 - acc: 0.9938 - val_loss: 0.0175 - val_acc: 0.9946          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 16s - loss: 0.0199 - acc: 0.9943 - val_loss: 0.0219 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 16s - loss: 0.0207 - acc: 0.9930 - val_loss: 0.0243 - val_acc: 0.9939          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 15s - loss: 0.0154 - acc: 0.9959 - val_loss: 0.0240 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 38s - loss: 0.3076 - acc: 0.9264 - val_loss: 0.2360 - val_acc: 0.9562          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 17s - loss: 0.1637 - acc: 0.9674 - val_loss: 0.1731 - val_acc: 0.9718          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 17s - loss: 0.1179 - acc: 0.9746 - val_loss: 0.0739 - val_acc: 0.9862          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 16s - loss: 0.0817 - acc: 0.9808 - val_loss: 0.0571 - val_acc: 0.9871          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 17s - loss: 0.0611 - acc: 0.9843 - val_loss: 0.0501 - val_acc: 0.9892          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0638 - acc: 0.9838 - val_loss: 0.0423 - val_acc: 0.9915          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 17s - loss: 0.0566 - acc: 0.9853 - val_loss: 0.0532 - val_acc: 0.9874          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0516 - acc: 0.9860 - val_loss: 0.0610 - val_acc: 0.9835          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 16s - loss: 0.0295 - acc: 0.9913 - val_loss: 0.0217 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0208 - acc: 0.9939 - val_loss: 0.0279 - val_acc: 0.9933          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 17s - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0295 - val_acc: 0.9929          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 17s - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0237 - val_acc: 0.9946          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 38s - loss: 0.1528 - acc: 0.9523 - val_loss: 0.0718 - val_acc: 0.9798          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 17s - loss: 0.0783 - acc: 0.9770 - val_loss: 0.1404 - val_acc: 0.9625          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 16s - loss: 0.0572 - acc: 0.9821 - val_loss: 0.0444 - val_acc: 0.9885          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 16s - loss: 0.0511 - acc: 0.9845 - val_loss: 0.0783 - val_acc: 0.9819          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 17s - loss: 0.0486 - acc: 0.9858 - val_loss: 0.0327 - val_acc: 0.9906          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0443 - acc: 0.9870 - val_loss: 0.0463 - val_acc: 0.9881          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 17s - loss: 0.0375 - acc: 0.9888 - val_loss: 0.0380 - val_acc: 0.9913          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 17s - loss: 0.0223 - acc: 0.9933 - val_loss: 0.0181 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 16s - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0216 - val_acc: 0.9946          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0203 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 16s - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0155 - val_acc: 0.9958          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 17s - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0182 - val_acc: 0.9963          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 16s - loss: 0.0099 - acc: 0.9971 - val_loss: 0.0135 - val_acc: 0.9961          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 16s - loss: 0.0096 - acc: 0.9976 - val_loss: 0.0199 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 16s - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0183 - val_acc: 0.9956          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 16s - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0140 - val_acc: 0.9957          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 39s - loss: 0.3061 - acc: 0.9002 - val_loss: 0.0601 - val_acc: 0.9814          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 17s - loss: 0.1151 - acc: 0.9649 - val_loss: 0.1378 - val_acc: 0.9632          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 17s - loss: 0.0940 - acc: 0.9704 - val_loss: 0.0445 - val_acc: 0.9855          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 17s - loss: 0.0835 - acc: 0.9745 - val_loss: 0.0398 - val_acc: 0.9886          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 16s - loss: 0.0738 - acc: 0.9776 - val_loss: 0.0346 - val_acc: 0.9904          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0686 - acc: 0.9790 - val_loss: 0.0288 - val_acc: 0.9908          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 17s - loss: 0.0665 - acc: 0.9799 - val_loss: 0.0305 - val_acc: 0.9919          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 16s - loss: 0.0599 - acc: 0.9820 - val_loss: 0.0310 - val_acc: 0.9918          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 17s - loss: 0.0444 - acc: 0.9871 - val_loss: 0.0204 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0370 - acc: 0.9885 - val_loss: 0.0171 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 16s - loss: 0.0323 - acc: 0.9899 - val_loss: 0.0181 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 17s - loss: 0.0312 - acc: 0.9906 - val_loss: 0.0221 - val_acc: 0.9927          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 17s - loss: 0.0324 - acc: 0.9901 - val_loss: 0.0166 - val_acc: 0.9948          \n",
      "\n",
      "Epoch 14/30                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 16s - loss: 0.0268 - acc: 0.9916 - val_loss: 0.0160 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 16s - loss: 0.0264 - acc: 0.9919 - val_loss: 0.0179 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 16s - loss: 0.0229 - acc: 0.9923 - val_loss: 0.0178 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 17s - loss: 0.0245 - acc: 0.9929 - val_loss: 0.0151 - val_acc: 0.9952          \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 17s - loss: 0.0237 - acc: 0.9921 - val_loss: 0.0146 - val_acc: 0.9948          \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 17s - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0157 - val_acc: 0.9951          \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 18s - loss: 0.0217 - acc: 0.9937 - val_loss: 0.0159 - val_acc: 0.9946          \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 17s - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0162 - val_acc: 0.9944          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 40s - loss: 0.2175 - acc: 0.9377 - val_loss: 0.1437 - val_acc: 0.9685          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 18s - loss: 0.1121 - acc: 0.9708 - val_loss: 0.1757 - val_acc: 0.9469          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 16s - loss: 0.0851 - acc: 0.9763 - val_loss: 0.1054 - val_acc: 0.9760          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 17s - loss: 0.0679 - acc: 0.9810 - val_loss: 0.0502 - val_acc: 0.9879          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 17s - loss: 0.0605 - acc: 0.9834 - val_loss: 0.0735 - val_acc: 0.9821          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 18s - loss: 0.0534 - acc: 0.9850 - val_loss: 0.0455 - val_acc: 0.9892          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 17s - loss: 0.0467 - acc: 0.9865 - val_loss: 0.0520 - val_acc: 0.9864          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 17s - loss: 0.0438 - acc: 0.9871 - val_loss: 0.0477 - val_acc: 0.9864          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 18s - loss: 0.0246 - acc: 0.9930 - val_loss: 0.0227 - val_acc: 0.9948          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 17s - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0225 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 17s - loss: 0.0183 - acc: 0.9943 - val_loss: 0.0257 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 17s - loss: 0.0184 - acc: 0.9943 - val_loss: 0.0254 - val_acc: 0.9936          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 17s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0204 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 18s - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0203 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 18s - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0206 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 18s - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0200 - val_acc: 0.9948          \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 17s - loss: 0.0084 - acc: 0.9970 - val_loss: 0.0199 - val_acc: 0.9946          \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 17s - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0194 - val_acc: 0.9954          \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 17s - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0193 - val_acc: 0.9957          \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 16s - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0202 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 16s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0209 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 17s - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0208 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 1/30                                                                        \n",
      " - 41s - loss: 0.1596 - acc: 0.9493 - val_loss: 0.0771 - val_acc: 0.9799          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 17s - loss: 0.0727 - acc: 0.9786 - val_loss: 0.0966 - val_acc: 0.9786          \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 17s - loss: 0.0607 - acc: 0.9819 - val_loss: 0.0732 - val_acc: 0.9810          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 17s - loss: 0.0499 - acc: 0.9849 - val_loss: 0.0421 - val_acc: 0.9876          \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 17s - loss: 0.0465 - acc: 0.9862 - val_loss: 0.0570 - val_acc: 0.9860          \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 16s - loss: 0.0430 - acc: 0.9868 - val_loss: 0.0492 - val_acc: 0.9876          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 17s - loss: 0.0224 - acc: 0.9933 - val_loss: 0.0226 - val_acc: 0.9942          \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 17s - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0245 - val_acc: 0.9936          \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 17s - loss: 0.0169 - acc: 0.9953 - val_loss: 0.0185 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 16s - loss: 0.0152 - acc: 0.9956 - val_loss: 0.0251 - val_acc: 0.9937          \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 17s - loss: 0.0142 - acc: 0.9958 - val_loss: 0.0183 - val_acc: 0.9950          \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 18s - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0211 - val_acc: 0.9943          \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 18s - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0220 - val_acc: 0.9945          \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 16s - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0175 - val_acc: 0.9960          \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 17s - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0173 - val_acc: 0.9961          \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 17s - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0191 - val_acc: 0.9949          \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 17s - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0167 - val_acc: 0.9958          \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 17s - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0179 - val_acc: 0.9956          \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 17s - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0170 - val_acc: 0.9943          \n",
      "\n",
      "Epoch 20/30                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 17s - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0156 - val_acc: 0.9952          \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 16s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0139 - val_acc: 0.9960          \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 17s - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0135 - val_acc: 0.9955          \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 18s - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0144 - val_acc: 0.9954          \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 18s - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0162 - val_acc: 0.9951          \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 17s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0135 - val_acc: 0.9962          \n",
      "\n",
      "100%|██████████| 50/50 [3:55:42<00:00, 378.77s/it, best loss: -0.9966666666666667]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(fn = optimize, space = space, \n",
    "            algo = tpe.suggest, max_evals = 50) # change to 50 to search more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper params: \n",
      " {'conv1': 128, 'conv2': 128, 'conv3': 32, 'conv4': 32, 'dense1': 512, 'dropout1': 0, 'dropout2': 0, 'dropout3': 0, 'kernel_size_1': 5, 'kernel_size_2': 3, 'kernel_size_3': 3, 'kernel_size_4': 5, 'loss': 'kullback_leibler_divergence', 'opt': 'adam', 'pooling_size_1': 3, 'pooling_size_2': 2}\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "print('best hyper params: \\n', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huấn luyện lại mô hình với bộ tham số tốt nhất ở trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 43s - loss: 0.1557 - acc: 0.9516 - val_loss: 0.0764 - val_acc: 0.9782\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.0708 - acc: 0.9782 - val_loss: 0.0628 - val_acc: 0.9832\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0596 - acc: 0.9826 - val_loss: 0.0463 - val_acc: 0.9870\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.0505 - acc: 0.9849 - val_loss: 0.0571 - val_acc: 0.9842\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.0459 - acc: 0.9856 - val_loss: 0.0496 - val_acc: 0.9873\n",
      "Epoch 6/30\n",
      " - 17s - loss: 0.0247 - acc: 0.9927 - val_loss: 0.0215 - val_acc: 0.9943\n",
      "Epoch 7/30\n",
      " - 17s - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0195 - val_acc: 0.9942\n",
      "Epoch 8/30\n",
      " - 17s - loss: 0.0161 - acc: 0.9953 - val_loss: 0.0248 - val_acc: 0.9943\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0170 - acc: 0.9946 - val_loss: 0.0221 - val_acc: 0.9946\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0168 - val_acc: 0.9958\n",
      "Epoch 11/30\n",
      " - 17s - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0195 - val_acc: 0.9951\n",
      "Epoch 12/30\n",
      " - 17s - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0165 - val_acc: 0.9958\n",
      "Epoch 13/30\n",
      " - 17s - loss: 0.0114 - acc: 0.9960 - val_loss: 0.0211 - val_acc: 0.9943\n",
      "Epoch 14/30\n",
      " - 17s - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0191 - val_acc: 0.9945\n",
      "Epoch 15/30\n",
      " - 17s - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0165 - val_acc: 0.9954\n",
      "validation accuracy: 0.9936904761904762\n"
     ]
    }
   ],
   "source": [
    "acc, model, history = train_model(train_gen, valid_gen, best_params)\n",
    "print(\"validation accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả trên tập validation khá cao với acc > 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. So sánh optimizers và loss\n",
    "## 6.1 So sánh các optimzers\n",
    "\n",
    "Mục tiêu của quá trình huấn luyện mô hình ML là giảm độ lỗi của hàm loss function được tính bằng sự khác biệt của giá trị mô hình dự đoán và giá trị thực tế. Để đạt được mục đích này chúng ta thường sử dụng gradient descent. Gradient descent sẽ cập nhật trọng số của mô hình ngược với chiều gradient để giảm độ lỗi của loss function. \n",
    "![image.png](https://miro.medium.com/max/414/1*6a9Gx2UlB1ksh92TabyGPQ.png)\n",
    "\n",
    "Chúng ta sử thường sử dụng 3 optimzer phổ biến sau là adam, sgd, rmsprop để cập nhật trọng số của mô hình. \n",
    "Stochastic Gradient Descent là một biến thể của Gradient Descent, yêu cầu chúng ta phải shuffle dự liệu trước khi huấn luyện. Trong khi đó RMSProp và Adam là 2 optimizer hướng đến việc điều chỉnh learning rate tự động theo quá trình học.\n",
    "\n",
    "RMSprop (Root mean square propagation) được giới thiệu bởi Geoffrey Hinton. RMSProp giải quyết vấn đề giảm dần learning rate của Adagrad bằng cách chuẩn hóa learning với gradient gần với thời điểm cập nhật mà thôi. Để làm được điều này tác giả chia learning rate cho tổng bình phương gradient giảm dần. \n",
    "![](https://miro.medium.com/max/786/1*adEDAdjulZUJisfzurVuWw.png)\n",
    "\n",
    "Adam là optimizer phổ biến nhất tại thời điểm hiện tại. Adam cũng tính learning riêng biệt cho từng tham số, tương tự như RMSProp và Adagrad. Adam chuẩn hóa learning của mỗi tham số bằng first và second order moment của gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with optimizer: rmsprop\n",
      "Epoch 1/30\n",
      " - 42s - loss: 0.1667 - acc: 0.9488 - val_loss: 0.1342 - val_acc: 0.9690\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.0814 - acc: 0.9774 - val_loss: 0.0725 - val_acc: 0.9790\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0648 - acc: 0.9825 - val_loss: 0.0563 - val_acc: 0.9851\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.0563 - acc: 0.9844 - val_loss: 0.0644 - val_acc: 0.9887\n",
      "Epoch 5/30\n",
      " - 16s - loss: 0.0484 - acc: 0.9871 - val_loss: 0.0777 - val_acc: 0.9849\n",
      "Epoch 6/30\n",
      " - 18s - loss: 0.0305 - acc: 0.9923 - val_loss: 0.0277 - val_acc: 0.9951\n",
      "Epoch 7/30\n",
      " - 18s - loss: 0.0225 - acc: 0.9941 - val_loss: 0.0271 - val_acc: 0.9939\n",
      "Epoch 8/30\n",
      " - 17s - loss: 0.0184 - acc: 0.9947 - val_loss: 0.0242 - val_acc: 0.9958\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0200 - acc: 0.9948 - val_loss: 0.0264 - val_acc: 0.9951\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0158 - acc: 0.9956 - val_loss: 0.0263 - val_acc: 0.9955\n",
      "Epoch 11/30\n",
      " - 17s - loss: 0.0149 - acc: 0.9960 - val_loss: 0.0279 - val_acc: 0.9943\n",
      "Train with optimizer: sgd\n",
      "Epoch 1/30\n",
      " - 42s - loss: 0.2978 - acc: 0.9222 - val_loss: 0.0897 - val_acc: 0.9752\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.1012 - acc: 0.9732 - val_loss: 0.0592 - val_acc: 0.9830\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0730 - acc: 0.9799 - val_loss: 0.0516 - val_acc: 0.9840\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.0620 - acc: 0.9826 - val_loss: 0.0544 - val_acc: 0.9843\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.0546 - acc: 0.9846 - val_loss: 0.0456 - val_acc: 0.9865\n",
      "Epoch 6/30\n",
      " - 18s - loss: 0.0496 - acc: 0.9852 - val_loss: 0.0383 - val_acc: 0.9893\n",
      "Epoch 7/30\n",
      " - 17s - loss: 0.0441 - acc: 0.9869 - val_loss: 0.0514 - val_acc: 0.9852\n",
      "Epoch 8/30\n",
      " - 18s - loss: 0.0408 - acc: 0.9876 - val_loss: 0.0281 - val_acc: 0.9914\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0385 - acc: 0.9888 - val_loss: 0.0301 - val_acc: 0.9919\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0381 - acc: 0.9892 - val_loss: 0.0300 - val_acc: 0.9923\n",
      "Epoch 11/30\n",
      " - 18s - loss: 0.0328 - acc: 0.9906 - val_loss: 0.0287 - val_acc: 0.9924\n",
      "Train with optimizer: adam\n",
      "Epoch 1/30\n",
      " - 44s - loss: 0.1576 - acc: 0.9501 - val_loss: 0.0492 - val_acc: 0.9856\n",
      "Epoch 2/30\n",
      " - 18s - loss: 0.0708 - acc: 0.9783 - val_loss: 0.0663 - val_acc: 0.9802\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0595 - acc: 0.9824 - val_loss: 0.0983 - val_acc: 0.9723\n",
      "Epoch 4/30\n",
      " - 16s - loss: 0.0311 - acc: 0.9902 - val_loss: 0.0226 - val_acc: 0.9924\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.0239 - acc: 0.9923 - val_loss: 0.0229 - val_acc: 0.9942\n",
      "Epoch 6/30\n",
      " - 16s - loss: 0.0218 - acc: 0.9933 - val_loss: 0.0198 - val_acc: 0.9951\n",
      "Epoch 7/30\n",
      " - 17s - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0159 - val_acc: 0.9957\n",
      "Epoch 8/30\n",
      " - 18s - loss: 0.0213 - acc: 0.9932 - val_loss: 0.0224 - val_acc: 0.9937\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0189 - acc: 0.9940 - val_loss: 0.0206 - val_acc: 0.9937\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0138 - acc: 0.9958 - val_loss: 0.0133 - val_acc: 0.9952\n",
      "Epoch 11/30\n",
      " - 18s - loss: 0.0132 - acc: 0.9965 - val_loss: 0.0144 - val_acc: 0.9956\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.0113 - acc: 0.9967 - val_loss: 0.0161 - val_acc: 0.9957\n",
      "Epoch 13/30\n",
      " - 16s - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0170 - val_acc: 0.9951\n"
     ]
    }
   ],
   "source": [
    "optimizers = ['rmsprop', 'sgd', 'adam']\n",
    "hists = []\n",
    "params = best_params\n",
    "for optimizer in optimizers:\n",
    "    params['opt'] = optimizer\n",
    "    print(\"Train with optimizer: {}\".format(optimizer))\n",
    "    _, _, history = train_model(train_gen, valid_gen, params)\n",
    "    hists.append((optimizer, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot quá trình huấn luyện mô hình với 3 lọai optimizers khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, history in hists:\n",
    "    plt.plot(history.history['val_acc'], label=name)\n",
    "\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chúng ta thấy rằng trong các loại optimzer trên. SGD hội tụ lâu nhất và độ chính xác cũng thấp nhất so với các optimizers còn lại. Trong khi đó, Adam hội tụ nhanh nhất, và có độ chính xác cao nhất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 So sánh các loss function \n",
    "Trong bài toán phân loại nhiều lớp. Chúng ta thường sử dụng 2 loại loss function sau:\n",
    "* Cross entropy\n",
    "* Kullback Leibler Divergence Loss\n",
    "\n",
    "Cross entropy được sử dụng phổ biến nhất trong bài toán của chúng ta. Cross entropy loss có nền tảng toán học của maximun likelihood được tính bằng tổng của sự khác biệt giữ giá trị dự đoán và giá trị thực tế của dữ liệu. Cross entropy error tốt nhất khi có giá trị bằng 0.\n",
    "\n",
    "KL loss (Kullback Leibler Divergence Loss) thể hiện sự khác biệt giữ 2 phân bố xác suất. KL loss bằng 0, chứng tỏ 2 phân bố này hoàn toàn giống nhau. \n",
    "\n",
    "Cross entropy cho bằng toán phân loại nhiều lớn tương đối giống với KL Loss về mặt toán học, nên có thể xem 2 độ lỗi này là một trong bài toán của chúng ta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with loss function : categorical_crossentropy\n",
      "Epoch 1/30\n",
      " - 44s - loss: 0.1543 - acc: 0.9505 - val_loss: 0.0602 - val_acc: 0.9825\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.0734 - acc: 0.9780 - val_loss: 0.0768 - val_acc: 0.9806\n",
      "Epoch 3/30\n",
      " - 18s - loss: 0.0606 - acc: 0.9826 - val_loss: 0.0422 - val_acc: 0.9885\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.0506 - acc: 0.9845 - val_loss: 0.0298 - val_acc: 0.9913\n",
      "Epoch 5/30\n",
      " - 18s - loss: 0.0460 - acc: 0.9861 - val_loss: 0.0365 - val_acc: 0.9915\n",
      "Epoch 6/30\n",
      " - 17s - loss: 0.0401 - acc: 0.9883 - val_loss: 0.0471 - val_acc: 0.9885\n",
      "Epoch 7/30\n",
      " - 17s - loss: 0.0239 - acc: 0.9929 - val_loss: 0.0205 - val_acc: 0.9946\n",
      "Epoch 8/30\n",
      " - 18s - loss: 0.0187 - acc: 0.9948 - val_loss: 0.0222 - val_acc: 0.9950\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0215 - val_acc: 0.9939\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0159 - val_acc: 0.9954\n",
      "Epoch 11/30\n",
      " - 18s - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0163 - val_acc: 0.9950\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0157 - val_acc: 0.9957\n",
      "Epoch 13/30\n",
      " - 18s - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0156 - val_acc: 0.9961\n",
      "Epoch 14/30\n",
      " - 18s - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0160 - val_acc: 0.9952\n",
      "Epoch 15/30\n",
      " - 18s - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0158 - val_acc: 0.9955\n",
      "Epoch 16/30\n",
      " - 17s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "Train with loss function : kullback_leibler_divergence\n",
      "Epoch 1/30\n",
      " - 46s - loss: 0.1590 - acc: 0.9510 - val_loss: 0.0868 - val_acc: 0.9736\n",
      "Epoch 2/30\n",
      " - 18s - loss: 0.0743 - acc: 0.9772 - val_loss: 0.0935 - val_acc: 0.9723\n",
      "Epoch 3/30\n",
      " - 18s - loss: 0.0581 - acc: 0.9829 - val_loss: 0.0340 - val_acc: 0.9906\n",
      "Epoch 4/30\n",
      " - 18s - loss: 0.0480 - acc: 0.9854 - val_loss: 0.0650 - val_acc: 0.9839\n",
      "Epoch 5/30\n",
      " - 18s - loss: 0.0446 - acc: 0.9874 - val_loss: 0.0482 - val_acc: 0.9867\n",
      "Epoch 6/30\n",
      " - 17s - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0165 - val_acc: 0.9964\n",
      "Epoch 7/30\n",
      " - 18s - loss: 0.0193 - acc: 0.9938 - val_loss: 0.0253 - val_acc: 0.9937\n",
      "Epoch 8/30\n",
      " - 17s - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0180 - val_acc: 0.9943\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0135 - acc: 0.9955 - val_loss: 0.0182 - val_acc: 0.9952\n"
     ]
    }
   ],
   "source": [
    "loss_functions = ['categorical_crossentropy', 'kullback_leibler_divergence']\n",
    "hists = []\n",
    "params = best_params\n",
    "for loss_funct in loss_functions:\n",
    "    params['loss'] = loss_funct\n",
    "    print(\"Train with loss function : {}\".format(loss_funct))\n",
    "    _, _, history = train_model(train_gen, valid_gen, params)\n",
    "    hists.append((loss_funct, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot quá trình huấn luyện mô hình với 2 loại loss function khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, history in hists:\n",
    "    plt.plot(history.history['val_acc'], label=name)\n",
    "\n",
    "plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta thấy rằng không có sự khác biệt rõ rằng về tốc độ hội tụ giữ 2 hàm loss function là cross-entropy và KL loss trong bài toán của chúng ta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Đánh giá mô hình. \n",
    "Chúng ta sẽ xem xét một số lỗi của mô hình dự huấn luyện được. Một số lỗi dễ dàng được phát hiện bằng confusion matrix thể hiện xác xuất/số ảnh bị phân loại nhầm thành lớp khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAEmCAYAAADr3bIaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXeYFFXWh9+eHoYcBEGySPAQBclKkGRCFESyIiJGzOinq7tr2FXXLLgq6i4qKoKIASPqYgKRLAgKB5EgQ845zTDfH1UDA06omamiu4bz8tRDd9Wtc09X9Zy+dcP5RdLS0jAMwzCyJyHWDhiGYYQBC5aGYRgesGBpGIbhAQuWhmEYHrBgaRiG4QELloZhGB6wYHkCISJFReRjEdkuIu/mw87lIvKln77FChFpJyIaaz+M+Cdi8yzjDxEZAAwD6gI7gXnAI6o6NZ92BwK3AGerakq+HY1zRCQNqKOqS2PtixF+rGUZZ4jIMGA48ChwClAdeBHo7oP5U4ElJ0Kg9IKIJMbaByM8WMsyjhCR0sBqYLCqZvqYLCKFgceBPu6u8cA9qrpfRDoAbwHPAvcAqcB9qvqaiDwE3AtEgP3AbUA1oLaqXuHargEsBwqpaoqIXAXcD5QHNgF/U9Ux7v5rVLWte97ZwAjgdGAJcJuqTnOPfQtMAToBZwA/AgNUdVMmny3d/+eAu1z/bwQO4PyAnAw8paqPuuVbuvXWA/YC7wHDVPWAiHwPtAP2AGnAEGC9a//fwB3AV8Ao4C1VrSoitYBZQBdVnSsilYGfgV6q+m1m98M4cbCWZXxxFlAE+CCbMn8FWgNNgMZAS+BvGY5XBEoDVXACxAsicpKqPoDTWn1HVUuo6qjsHBGR4jhB60JVLQmcjdMdcGy5ssCnbtlywDPApyJSLkOxAcBgoAKQhBMIs6IizjWoghOo/wNcATTDCX73i0hNt2wqTtA7GefadQaGAqhqe7dMY/fzvpPBflmcVvZ1GStW1d9xfmTGiEgx4DXgdQuUBliwjDfKAZtyeEy+HPiHqm5Q1Y3AQ8DADMcPuscPqupnwC5A8ujPIaChiBRV1bWq+ksmZS4CflPVN1U1RVXHAouBizOUeU1Vl6jqXpyWcJNs6jyI0z97EBiHEwhHqOpOt/5fcFqoqOocVZ3u1rsCeBk4x8NnekBV97v+HIWq/gf4DZgBVML5cTIMC5Zxxmbg5Bz60ioDKzO8X+nuO2zjmGC7ByiRW0dUdTfQF7gBWCsin4pIXQ/+pPtUJcP7dbnwZ7Oqprqv04PZ+gzH96afLyKni8gnIrJORHbgtJxPzsY2wEZV3ZdDmf8ADYF/q+r+HMoaJwgWLOOLH4F9QI9syqzBeYRMp7q7Ly/sBopleF8x40FV/UJVz8VpYS3GCSI5+ZPu0+o8+pQbRuL4VUdVSwH34fTJZke2nfQiUgKnf3QU8KDbzWAY2GhgHKGq20Xkfpx+xhTgS5zH0i5AR1W9GxgL/E1EZuH84d+PM2iRF+YB94hIdWA7zgAQACJyCtAKmIzTmtuF00d4LJ8B/3anO40HLgPqA5/k0afcUBLYAexyW703AhszHF8P1ARyM3VoBDBHVa8RkVeAlzgymGacwFjLMs5Q1Wdw5lj+DecPfxVwM/ChW+RhYDbOKO0CYK67Ly91fQW849qaw9EBLgG4E6fluAWnL3BoJjY2A93cspuBu4FumY12B8BdOINHO3Fave8cc/xBYLSIbBORHAOeiHQHLsDpegDnPjQVkct989gILTZ1yDAMwwPWsjQMw/CABUvDMAwPWLA0DMPwQNyMhrvL+FoAa8l81NUwjNgQxZk+NsvPeafutKxSuThlh6pu8av+3BI3wRInUE6JtROGYWRJOyBfma/SEZGyqSRujpKrnC5bRaR2rAJmPAXLtQAba11OalJufmy8MXdEL99tGsaJwPp16xh85eXg/o36RKkoKawv3JyUSJEcCyem7eOU/bNPwmmJnvDBMhUgNakUqUllfDdepUpV320axgmG791jKQnFSE0omnPBQ7EfXomnYGkYxolGBIjktEKVnBexHgcsWBqGETsiCc7mpVyMib0HWXDTRfWZ9XR3Zj7Vnddua0/hQlFG3dKOucMvZeZT3XnxxjYkRo/83Dw5uCXzn+vJ9CcvofFpec998OUXkzijgdCgbm2efOIxPz6K2Y6R/euvuZrqlSvQrElD32xmJKzXPOj7mSsSot63GBOXwbLSScW48cJ6tPvLJ7S8ayLRhAi9zj6Nd6Yuo+ntH9DyrokUTYpyVafTATjvzCrUqliKxre+zy2v/Mjwa87KU72pqancfutNTPz4c376+VfeHTeWRb/+6stnMtvH3/7AQVcx8ZNJvtg6lrBe86DvZ+6JOI/hOW1x8Bwel8ESIDEhgaJJUaIJEYomJbJ26x6+/OlI1q/ZSzdRpZyTXaxb8+qM/f53AGb9tpHSxZM4pYyHTuNjmDVzJrVq1ea0mjVJSkqid99+fPLxRF8+j9k+/vbbtmtP2bLBZFgL6zUP+n7mmkjkyKN4tpsFy0xZu3UPz328kEUje/P7K33ZsecAX/98JGVjYjRC/3a1+GqeEzwrlS1G8qbdh4+v2bybymWL/cluTqxZs5qqVasdfl+lSlVWr/YnLaPZjo39oAjrNY+76+2lVXm4dRlbAg2WInKBiKiILBWRv3g9r0zxJC5qUZ2GN02g9vXvUKxIIfq2q3n4+LPXnMUPi9YzbfEGIPPrmJdkSpllYIr4dJPMdmzsB0VYr3ncXW9PrUqPg0ABE5gHIhIFXgAuxEkG219E6ns5t2OjSqzYsJNNO/eTkprGRzNW0vr0CgDc26sxJ5cqwl/emHm4/JrNe6h6cvHD7yuXK87arXty7XOVKlVJTl51+P3q1clUrlw5mzPMdrzbD4qwXvO4u97WsgQc1cGlqrpMVQ/giE950r5etWk3LeuUp2iSMwLWoVEldPU2BnWqQ+fGVRg8/LujWo6fzl5F//a1AGhRpzw79hxg/bY/aVHlSPMWLVi69DdWLF/OgQMHePedcVzU7ZJc2zHb8WM/KMJ6zePueoeoZRnkPMsqOFm+00nGkSnIkdlLN/Hh9JX88PglpKQeYv6KLbz6vyVsePMK/ti4i68fuQiAj2as5LH35vPFT8mc37QKPz/Xk70HUrnhxbwtX01MTOTZEc9z8UXnk5qayqCrrqZ+gwZ5smW2Y2//yiv6M+W7b9m0aRO1alTl7/c/xFVXD/HFdlivedD3M9d4bTXGQcsysEzpItIbOF9Vr3HfDwRaquotWZSvASxfV+/GQJY7bnr7Kt9tGsaJwOrVyXQ9rzPAaa7kcL5J/3tfffLFpEZzFh+Npu6iyqaPffUhtwTZskwGqmV4X5W8qxAahlEQSYhC1MOE87TYT0oPMljOAuqIyGk4sqj9cMSlDMMwHGy5I6hqCo4q4RfAImC8qv4SVH2GYYSQEI2GB5pIQ1U/w9GVNgzD+DPpK3i8lIsxlnXIMIzYEaLRcAuWhmHEjhD1WVqwNAwjhnjtj7SWpWEYJzLWsjQMw/CAyUrknbkjegUiLnZSi5t9t5nO1lnPB2bbOP4EtaotnTBkVTpuWMvSMAzDA14lI+JAVsKCpWEYscNaloZhGB6wPkvDMAwveM1VGfuWZew9yAP5lfK8qX8HZr97H3Mm/JWbB3QA4K/Xd+X3Lx5m+ri/MH3cXzi/7ZGk7g3rVObb0XcyZ8JfmTX+Pgon5e03JqzypmGVwg3aNjhqia1bNKVnj4t9s7lq1SrO79KRJo3q0bRxA55/boRvtiHOpHBtbXhwpEt5fvr5V1SpWpW2rVvQrdsl1KvvSbGC+rUqMbjn2bQb+CQHDqby0QtD+Xyqk9/j3299w/A3Jx9VPhpN4NWHBzHk72+wYMlqypYuzsGU1OPud0G0HbT9oH0HeOHfI6hbtx47du7wzWZiYiKPPfE0ZzZtys6dOzm7VTM6dzk3NNckV4SozzL2HuSS/Ep51j2tIjMXrGDvvoOkph5iypyldO/YOMvyXc6qy8LfVrNgiaOAt2X7bg4dyv3UkrDKm4ZZCjdo35OTk5n0+We+ZV9Pp1KlSpzZtCkAJUuWpG7deqxZ448CY3xK4YajZRm6YJlfKc9ffl9D26a1KVu6OEWLFOKCtg2oWvEkAG7o156Z79zLSw9cTpmSju54neoVSEuDj164iWlv38OwQV1i4ndBtB20/aB9v/vOO3j4X4+TkBDcn9HKFSuYN+8nWrT0pMiSI/EmhRuJRDxvsSZIdcdXRWSDiCz0025+pTx1+Xqefv0rPhl5Mx+9cBM/L1lNSkoq/3l3CvUvfpBW/R5j3aYdPDasJwCJ0Shnn1mTwX99nc5XP8MlnRrToeXpx93vgmg7aPtB2v7s008oX6E8TZs288VeZuzatYv+fS7jyaeHU6pUKV9sxpsUrtNo9BIsY+biYYJsWb4OXOC3UT+kPEd/+CNnD3icc4cMZ+v23Sz9YyMbtuzk0KE00tLSePX9H2je8FTH/oZtTJmzlM3bdrN330EmTf2FM+tWy6GGYPwuaLaDth+k7enTfuDTTz6mbp3TuPKK/nz3zddcPWigL7YBDh48SP8+l9G3/+X0uLSnb3bjTQo3khDxvMWaIDOlfw9s8duuH1Ke5U9yBJKqVTyJ7p0aM37SbCqefOSXu3unxvz6+1oAvpr2Kw3rVKFokUJEowm0a1abRcvWxcTvgmY7aPtB2v7HI/9i6fJVLP5tOW+8NZZzOnbi1dFv+mI7LS2NG64dgtStx213DPPFZjrxJoUbweNjeBxMtAzdaLgfUp5jn7qGsmWcUe3bHxvPtp17GXV3b86QqqSlpbFy7RZueXgsANt27uW5t75m6lt3k5aWxhdTf2HS1NyrY4RV3jTMUrhxJ/vqkWk//MDbY96kYcNGtGrWBICHHn6UCy7smm/b8XZNvPZHeikjIncA1wBpwAJgMFAJGAeUBeYCA1X1gIgUBt4AmgGbgb45qUYGJoXrOl8D+ERVG3osu/yzLydbIg0jplgijaMJUgp3Y4ObSS2cs/R1dP82yv/yfJY+iEgVYCpQX1X3ish4HEmbrsD7qjpORF4C5qvqSBEZCpyhqjeISD/gUlXtm50PoRsNNwyjABHJxZYziUBREUkEigFrgU7ABPf4aKCH+7q7+x73eGcRybYWC5aGYcQOr9OGcmiNq+pq4CngD5wguR2YA2xzlWYBkoEq7usqwCr33BS3fLns6ghy6tBY4EfnpSSLiL8zdw3DCD1+zbMUkZNwWounAZWB4sCFmRRN72PJzGC2/S+BDfCoav+gbBuGUTDwcYCnC7BcVTcCiMj7wNlAGRFJdFuPVYE1bvlkoBqQ7D62lyaH2Tv2GG4YRszwcVL6H0BrESnm9j12Bn4FvgF6uWUGAelrOz9y3+Me/1pVs21ZWrA0DCO2+DC4o6ozcAZq5uJMG0oAXgHuAYaJyFKcPslR7imjgHLu/mHAX3KqI3TzLA3DKDgkJCSAh7X1Xtbfq+oDwAPH7F4GtMyk7D6gtzcvHSxYGoYRM/yclB40FiwNw4gdXudQxj5WnjjBMshVNmX7vRqYbYAt464O1L5xNPHQijlRsJalYRiGF7zmqrRgaRjGiYyX1TmHy8UYC5aGYcSMCB6DZRx0WlqwNAwjdoRogCeUk9LjXTr15m4NmP3spcx65lJev70DhQtFefW2c5g34jJmPXMpLw1tS2L0yN1v16Ai05/szuxnL+WLhzJbznp8/I6F7aDtB2U7aLna66+5muqVK9CsSY7ZDXNNPEnhmqxEgKRLeU78+HN++vlX3h03lkW//ho3tiuXLcbQC+vT9p6PaDHsA6IJEXq3OY13vv+dJre9R4thH1AkKZHBnQWA0sWSGH7NWfR6/H80v+MDrnj6m5j4HQvbQdsP0na6XO28BYv4bup0Xn7pBV+vy8BBVzHxk0m+2Usn6PuZW0ywLEDCIJ2aGI1QNClKNCFCscJR1m7dwxc/JR8+PnvpRqqUKw5A33Y1+WjGSpI37QZg4459MfP7eNsO2n6QtoOUqwVo2649ZcuW9c1eOvEmhWsaPAES79Kpa7bsYfhHC9GRfVn2n35s33OQyfPXHD6eGI0woH0tvpznBM/alUpTpkRhJj10IT88fgkDzqkdE79jYTto+8dL9tVvudogMSncvBPYAI+IVMPRuKgIHAJeUdV8d+zEu3RqmeJJdGtRnfo3vcu23fsZc2cn+rWrxbgpvwMw4tqzmfrreqYtWg84wfPMmuXo+tAkiiZF+ebRbsxcsoGla3ccV79jYTto+8dD9jUIudogiT8p3PBMHQqyZZkC3Kmq9YDWwE0iUj+/RuNdOrXjGZVZuWEXm3bsIyU1jYkzVtJaKgBwX+8mnFyqCPeMnnGkjs17+GreavbsT2Hzzv388Ot6GtXI3eNXvF+TWNkP2veg5GqDJN6kcPGo7hgPw+FBSuGuVdW57uudwCKOpHTPM/EunZq8aTctTi9P0aQoAB0aVWLx6m1c1fl0ujSpwqDh35Lxx/2TWSs5u94pRBOcfs7mdcqjyduOu9+xsB20/SBtBylXGyRxJ4Vrj+FH4yq5nQnMyKFojsS7dOqs3zby4Y8rmPZkd1JS05i/fDOvfqVsGnMlf2zcxbePdANg4oyV/GvCPHT1dr76KZmZT/fgUBq8Pln5dVXugmW8X5NY2Q/SdpBytQBXXtGfKd99y6ZNm6hVoyp/v/8hrro6/8os8SaFG6Z5loFK4QKISAngO+ARVX0/m3I1CFAKN0gskYZRkAlSCvdgx79DMQ/dTnu2UOibf/rqQ24JtGUpIoWA94Ax2QVKwzBOTJzuSC+JNAJ3JUeCHA2P4KRuX6SqzwRVj2EY4cXz2E1BDpZAG2AgsEBE5rn77lPVzwKs0zCMEJGQEAEvE87jYFJ6kFK4U4mL3wPDMOIVr1mH4iGUWNYhwzBih8dYmRb7WGnB0jCM2JHgcd13WkKEQ8fBn+ywYGkYRszwuNoxHp7CLVgahhE7PK/OOVFW8BiGYWSGtSwNwzA8YC3LE4yglyOedMlzgdne+tGtgdk2jJzxFizT4qBpacHSMIyY4fUxPA4alhYsDcOIHQkJEWcVT44FYx8tLVgahhEz0tUdvZSLNaHT4IFwSqf6ZfuWHk2YM/JyZr94OaPvPp/ChZwkww9eeRY//2cgP710BUMvaQzA6VVP4tune7Nt4k3c3vPMmPqdFUFKvkL838/MCFpmN/6kcL1tsSZ0wTKs0qm+yOyWK87QSxrT5rZxNB86hmg0gd7nnM7Ac+tRtXwJGl/3Jmfe8BbvfrcEgK0793HnS98x/L25MfU7O4KSfIX4v59ZEaTMrknh5p3QBcuwSqf6J7ObQNGkREeGonAiazfv5rqujXj07ZmH5So2bt97+P85v23gYGreF4oFLZ0alOQrhON+ZkaQMrtxJ4VrLcvgCKt0qi8yu5t3M/z9uSwZPZjlY65hx+79TP7pD06rVJpe7eswdURfPvzHJdSqXNoXn/3yO1bE+/30gt8yu/F3P8MjWBZk8t8iwPdAYbeeCar6QH7thlU61ReZ3RKF6da6JvUGj2bb7v28fd+F9OsoFC4UZf+BVNre9g7dz67Fy7d3ocvd78WN37Ei3u9nTgQhsxtv9zNMU4eCbFnuBzqpamOgCXCBiLTOr9GwSqf6YbtTk2qsWLeDTTv2kpJ6iA9/+J3W9SqxetMuPvhhKQATp/1Ow9NO9sVnv/yOFfF+P7MjKJndeLuf1mcJqGqaqu5y3xZyt3yro4VVOtUP26s27qRl3YoULew8EHRsUg1dtYWPf1xGh8bOo1W7RlVYujp36pBB+x0r4v1+ZkWQMrvxdj/D1GcZtGBZFJgD1AZeUNUCL4UbpO1Zup4Ppi7lx+f6OTK7yzYy6vNfKFo4ymv/dz63XNqE3XsPcuOIyQCcclIxfhjRj5LFkjh0KI2be5zJmde/xc69B46r39kRlOQrxP/9zIogZXbjTQrX66T0tDiYlB64FC6AiJQBPgBuUdWFWZSpQUilcIPG1oYbsSRIKdxy/R8nWjLnbqPUnZvYPPYeX33ILcdlNFxVtwHfAhccj/oMwwgHYeqzDHI0vDxwUFW3iUhRoAvweFD1GYYRTvyKg+4T7H+BhjjjI1cDCrwD1ABWAH1Udasr1T0C6ArsAa5S1WxXbwTZsqwEfCMiPwOzgK9U9ZMA6zMMI2T43LIcAUxS1bpAY2AR8BdgsqrWASa77wEuBOq423XAyJyMBymF+zOQ9wXJhmEUePyaZykipYD2wFUAqnoAOCAi3YEObrHRON2B9wDdgTdUNQ2YLiJlRKSSqq7Nqg7LOmQYRszwMetQTWAj8JqINMaZhXMbcEp6AFTVtSJSwS1fBViV4fxkd1+WwTJ0yx0Nwyg4+DjPMhFoCoxU1TOB3Rx55M606kz2ZTs1yIKlYRgxIyES8bzlQDKQnGEu9wSc4LleRCoBuP9vyFC+WobzqwJrsvU1l5/NMAzDN/xqWarqOmCViIi7qzPwK/ARMMjdNwhIT7H0EXCliETcZdjbs+uvhGz6LEXkuhyceyV79w3DMLInIRIh6mF1ziFvo+G3AGNEJAlYBgzGaRCOF5EhwB9Ab7fsZzjThpbiTB0anJPx7AZ42mVzLA2wYGkYRr7wOi3ISxlVnQc0z+RQ50zKpgE3eXDxMFkGS1UdmBtDRnAEuSTxpMteCsz21vduCMy2kTmHDvm/fDktAJvphClFW45Th9y8lPcANVV1kNsnIKr6UeDeGYZRoIm4/7yUizVeBnhGAiU50rxdAzwYlEOGYZw4JES8b7HGS7Bsoqp3AQcAVHUnEA3UK8MwTgy8LnWMg+dwLyt49md8IyKFiQdBDMMwQk+Y+iy9tCynisjdQGERaQuMAz4N1q3sCaMWdBhs33LJGcz5dx9mP9eH0Xd2PqxJDvDMtW3YOO5IUt4nhpzN9Gd7Mf3ZXvz8Yj/Wjslx5kWgvmeGaZJnzr9HPEvzJg1pfmYjBg0cwL59+3y1nxt8nJQevK8eytwHFAX2As8B84H7g3QqO8KqBR3vtiuXLc7Qbg1pc+d7NL91PNGEBHq3qw1A09rlKV288FHl7x41jdZ3TKD1HRMY+elCJk5fHjPfs8I0yf/MmtWrGfnCv5ny4yxm/7SAQ6mpvDt+nC+280KYZCVyDJaqekBVH1LVZqraVFUfVNWDx8O5zAirFnQYbP9Jk3zLbhISIjx6VWv+Onp6luf1aV+b8d8vjanvmWGa5JmTkprC3r17SUlJYc+ePVSqFEPBMo9SuKEYDReR4iLyqIhMF5EfReQRESl+PJzLjLBqQce77TVbdjP8g/ks+e8VLH/9SnbsOcDkecnc2LUhn85cybqtezI9r3r5EpxaoSTfLsjbZ4k/HWtvxPv9zIrKVapw2+13Urf2qdQ6tTKlSpemy7nn+WI7LyQkQDQhkuOWEAcLs7248CpO6qK7cbJ4VAJe81qBiERF5CcR8SXxb1i1oOPddpniSXRrVYN6142h5uA3KV44kQEdT6dnm5q8+MmCLM/r3a42H05blufJ0PGmY+2VeL+fWbF161Y++eQjftFlLF2xmj27dzP27bd8sZ0XIrnYYo2X0fCGqppR/u07EfklF3XchpOx2BeV+LBqQce77U6Nq7Ji/Q427XA6+z+cvpy/929OkaREfnlpAADFCiey8KX+NLxh7OHzerWrzR0vT4mp77Eg3u9nVnzz9f+oUaMG5cuXB+CSHpcy48dp9B9whS/2c4ufyx2DxkvLcqWIHO74cV8v82JcRKoCF+HoYvhCWLWg4932qk27aCmnUDTJ1SQ/owrPTfyZ0656g7rXjaHudWPYsz/lqEBZp0ppTipemOmL18fU91gQ7/czK6pVq86sGTPYs2cPaWlpfPvN10jder7YzgthmpSeXdahR92X24H5IpK+vPFi4H8e7Q/HeXwvmWcPjyGsWtDxbnvWkg18MG0ZPz57matJvolRX2Q/AtunXR3enZq3gZ10grwupkn+Z1q0bEWPnpfRplUzoomJNG5yJldfk22CsUAJU8syS91wEflndieq6t+zOy4i3YCuqjpURDoAd6lqt2zK18B0w487lkijYBFEIo01q5O56IIuEIBueONbn6dwmQo5FWf/tg3Mf+5mX33ILdllHco2GHqgDXCJiHQFigClROQtVY1N54hhGHFHmFqWngTLRKQT0AQn6AGgqo9mfQao6r3Ave75HXBalhYoDcM4TARv/ZGxD5XeUrQ9jJMIuC7wCU6f5eSA/TIM4wQgTC1LL6PhPYAuwDpVHQI0I0ML0wuq+m12/ZWGYZyYRCMRz1us8RIs96UvbxSRRFVdBVQP1i3DME4EwrQ23Euf5U4RKQr8iCNgvgY4FKxbhmGcCBS0x/DLcYLjncDvQGGOKKQZhmHkHa+tytjHypxblqqaLjy+H5OTMAzDR7zmqoyHfJbZreAZiyN5mymqOiAQjwzDOGEIU6b07FqWXpc0GiEmyFU2de/yJdFUpix+yiZXZEZCAIuoIwEuzI7grT8yDmJltit4Rh1PRwzDOPFIwNvASRyks/S2gscwDCMIwjQabsHSMIyYEfGYfi0OYqUFS8MwYke6bISXcrHGU1eAiJwjIje4ryuISK1g3coakzf9M6tWreL8Lh1p0qgeTRs34PnnRvhmG/Lvd80Kxfns/9od3hY8dj5Xn3Ma915Sj8n3duDzu9vz8tXNKVXU+e1ue/rJfHxnWybd3Z6P72zLWXXK5cnvffv20faslrRs2pimjRvwz4ceyJOdrAjyuxLk9zxIv3NLmJL/ehEsuwt4FGdSOjjrwl8P0KdsMXnTP5OYmMhjTzzNvAWL+G7qdF5+6YW48nvZht10fXIKXZ+cQrenprDvQCpf/LyOqbqR8x7/jguf+J7lG3cxtIsjvbt19wGG/GcWFzzxPXeOmc+zl5+ZJ98LFy7MpK++Zubc+cyYPY8vv5jEjOlZq1TmhiDvJwT3PQ/a79wSpuWOXlqWA4EOwC4AVf0DKBOgT9li8qZ/plKlSpzZtCkAJUuWpG7deqxZ448aoN9+tzn9ZFZu2sPqrXuZoptIdZPV/rRiGxVLFwXgl9WhKpZPAAAfZElEQVQ72LBjPwBL1u2kcKEEkqK5Hw+NRCKUKFECgIMHD5Jy8KBvAwVBy9UG9T0P2u/cEnEnpee0xcMAj5dv4N5MdMIL5NrwsMqbZmTlihXMm/cTLVq28sWe335f3LQyH81d86f9vVtV49tFG/60/8LGlfgleTsHUvP2lUtNTaVVsyZUr1yBTl3OpWWr+Lwux4t48zshF1us8TLAkywirYE0EYkA9+CoNeaIiKwAdgKpQIqqNs+jn8eFsMqbprNr1y7697mMJ58eTqlSvohp+up3oWiELg0q8sTHi4/af9O5tUk9lMaHc47+o61TsQR/ubguA0fOyFN9ANFolBlz5rFt2zb69rqUXxYupEHD/PcDmoSvPziT0r2VizVeguWtwFtAQ2APMB3ol4s6Oqrqpjz4dtwJq7wpOI+Z/ftcRt/+l9Pj0p6+2fXT7w71KrAweTubdh04vO+yFlXp3OAUBrzw41FlK5YuwstXN2fYmHn8sXlP3pzPQJkyZWh/Tge+/HKSL8HSJHz9IUxrw3Ns3arqGlXtBJQDKqpqR1XNu/ZpHBNWedO0tDRuuHYIUrcet90xzBeb6fjp9yVNK/Px3COtx3PqlueGzrW45j+z2HfwyGN2qaKJvHZdS574ZDFzlm/Ns+8bN25k27ZtAOzdu5evJ/8Pkbp5tpcRk/D1hzAN8HiRlTjvmPcAqOqXHuynAV+KSBrwsqq+khcnM2Lypn9m2g8/8PaYN2nYsBGtmjUB4KGHH+WCC7vm27ZffhcplEBbKc994xcc3vfQZQ1JSkzgraFOP+JPK7bx13cXcGXbGpx6cjFuPb8Ot55fB4CBI2ewOUOL1Avr1q7l2qsHkZqayqG0Q1zWqw9dL/JnTXmQ9xOC+54H7XduCdOk9CylcNMRkSkZ3hYBGgHzVLV1TsZFpLKqrhGRCsBXwC2q+n0WZWtgUrgFCkukUTBYvTqZrud1hgCkcHv841VKlDslx/K7Nq/nw/uv9tWH3OIln2W7jO9FpBFwixfj6bkwVXWDiHwAtAQyDZaGYZx4eJ1wHopJ6ceiqguAxjmVE5HiIlIy/TVwHrAw1x4ahlFgieTiX6zJbZ9lAtDCy3nAKcAHbh9nIvC2qgaz9MYwjFDid5+liESB2cBqVe0mIqcB44CywFxgoKoeEJHCwBs4arWbgb45Pd57CXp/z/A6BUeHp09OJ6nqMjy0QA3DOHFJwONjuHeTt+HMA0+faPw48KyqjhORl4AhwEj3/62qWltE+rnl+mZnONtgKSIJwCPWIjQMIwj8zGcpIlWBi4BHgGHuIppOQLoEzmgcHbGRQHeOaIpNAJ4XkYiqZjninW3AVtVDwP05emkYhpEHfM46NBy4myPLscsB21Q1xX2fDFRxX1cBVgG4x7e75bP21YMDc0WkmSdXDcMwcoFfk9JFpBuwQVXnZDSfSdE0D8cyxUufZWvgehFZhJt5CEBVz/ZwrmEYRpY4AzxeHsNzLNIGuEREuuLMBy+F09IsIyKJbuuxKpCexSUZqIaT+yIRKA1sya4CL8HyHg9lDMMwco1f8yxV9V7gXgAR6QDcpaqXi8i7QC+cEfFBQHo+uo/c9z+6x7/Orr8SstcNH6WqQ1R1cs4fxTD+TJCrbE7qE5z46Nbx/iyfNXImGokQ9dBs9FImC+4BxonIw8BPQPoXZxTwpogsxWlR5pgcKLuWZd7SUxuGYXjEa5KM3MRKVf0W+NZ9vQxn5eCxZfYBvb1bNcEywzBiSASPk9ID9yRnsguWjUTkz6mrHb/TVLVCQD4ZhnGCEKZ8ltkFyyVA/nN8GYZhZEEQj+FBkd08y/2qujKr7bh5eAwmhVuwbPt1P2/p1oA5w3sye3hPRt/RgcKFoowc2pYZz/Rg5jOX8vb/daJ4kaPbBpeeVYO97w+haa2T81RnUNclzBK+ucWLWJnX1mfgvmZzLHeZVo8TJoVbcGyDP/ezctliDL2oAW3unkjz298nmhChd9ua3P3aDFoN+5CWwz5g1cbd3Hhh/cPnlChSiKFdGzBzSWY9TTkT5HUJs4RvbglTpvQsg6WX5L6xwKRwC45t8O9+JkYjFE2KEk2IULRwImu37GHn3iOipEWSokctz3hgQFOe+fBn9h1IzVN9QV6XMEv45pYI3pQd4yBWxoXCZNwQVincsNr2izVb9jB84kKWvNyP5aP6s2PPASbPd3x8+eZ2rHh1AFKlNC9++gsAjU8rR9Vyxfl8zqrszGZfZ8DX5USR8E1PpOFlizWBBksRKSMiE0RksYgsEpGzgqwvv4RVCjestv2iTPEkurWsTr0bx1PzmrEUL1yIfu1rAXD981Ooec1YFq/eTq+2NYlE4InBrbjn9Zn5qjPo65Iu4bt0RTKzZ83kl4X+5M2Ot/sZycUWa4JuWY4AJqlqXZzclp70xmNFWKVww2rbLzqdUZkV63eyacc+UlLT+HDGClrXPaLrcuhQGhOmLqNH6xqULFqI+tVP4st/dmXxS31oeXp5JtzbJdeDPMfrumSU8PWDeLuf6St4vGyxJrBgKSKlgPa4y4tU9YCqbguqPj8IqxRuWG37xapNu2l5egWKJkUB6NioMpq8jZoVSx4uc1GL6ixZvZ0dew5S7aox1L1hPHVvGM/MJRvp9a//Mff33EnbB3ldTiQJ3zAN8AS5gqcmsBF4TUQaA3OA21R1d36MmhRuwbEN/tzPWb9t5IMfl/PjUz1IOZTG/GWbGfXlYib9oyslixYiEomwYMVmbn15mm9+B3ldwizhm3u89kfGPlrmKIWbV0SkOTAdaKOqM0RkBLBDVf+eRfkamBSu4RFLpHH8CFIK947n3uakChVzLL91wzqevXWArz7kliD7LJOBZFWd4b6fADQNsD7DMEKGjYYDqroOWCWuvCPQGYjd7FfDMOKOMI2GB5116BZgjIgkAcuAwQHXZxhGiHAGb3zJlB44gQZLVZ0HNA+yDsMwwkv6Ch0v5WKN5bM0DCN2eO2PjIOmpQVLwzBihl8aPMcDC5aGYcSMBCIkeBi+8VImaCxYGoYRM8KU/NeCpWEYMSPi/vNSLtZYsDRCSZCrbE666OnAbANs/fTOQO2HCWtZGoZheCDisc/SWpaGYZzQWMvSMAzDAxE8BsvAPckZC5aGYcSMMA3wxMMqolwTRtlXk/CNjX0/bN9yaVPmvDKI2S8PYvRfLqJwoSj/e7ov018cyPQXB7Ls7esZ/0B3APp1rMvMkVcyc+SVfPNsfxrVLB8zv2NhO7ekT0r3ssWa0AXLsMq+moTv8bfvh+3K5UowtEdT2tw8hubXjyYajdC7Q1263PkOrYe+SeuhbzJj0Ro+/OE3AFas38F5//cOLW98g3+N+ZEXbjs3Jn7HwnZeiHjUDC/QKdqCIqyyrybhe/zt+2U7MZpA0cKJR2R2N+86fKxE0UKc07g6H09bCsD0X9ewbdd+AGYuXkuVk0vEzO/jbTsvRHLxL9aELlie6LKvmRHmaxLvvq/ZvIvhE2ax5M1rWT72BnbsPsDkuSsPH7+kTR2+nfcHO/cc+NO5V13QiC9mrYiJ37GwnRfC9Bge2ACPm/T3nQy7agL3q+rw/Ng90WVfMyPM1yTefS9TojDdzqpNvUH/Zduu/bz9t4vp16ke4752hEr7dKjL65MW/Om89o2rMej8hnQeNi4mfsfCdl5wEvt6GeCJPUFmSldVbaKqTYBmwB7gg/zaPdFlXzMjzNck3n3vdOaprFi3nU3b95KSeogPf/iN1vUdG2VLFqG5VOTzGcuOOqfhaScz8vbz6P3gRLbs3BcTv2NhOy+ESd3xeD2GdwZ+V9WVOZbMgRNd9jUzwnxN4t33VRt20LJeJYoWdh7COjapjv6xBYCe7U/n8xnL2H8w9XD5auVLMu7+Sxjy5OcsXb01Zn7HwnZeMFmJP9MPGOuHobDKvpqE7/G374ftWbqOD6b8xo8vDCQl9RDzl25g1Oc/A9D7nLo8NX7mUeXvvfwsypYsyvCbOwOQknqItreMOe5+x8J2XkgfDfdSLtYEJoWbjqu/swZooKrrsylXA5PCNeIAS6RxNEFK4T716geUPyXnboCN69dw19WX+upDbjkeLcsLgbnZBUrDME5QvD5jx75heVyCZX98egQ3DKNgkeDxMdxLmaAJdIBHRIoB5wLvB1mPYRjhxAZ4XFR1D1AuyDoMwwg58RAJPWBZhwzDiBlhyjpkwdIwjJjhV/JfEakGvAFUBA4Br6jqCBEpi7OSsAawAuijqltFJAKMALriLJi5SlXnZldH6NaGG4ZRcPCxzzIFuFNV6wGtgZtEpD7wF2CyqtYBJrvvwZmlU8fdrgNG5lSBBUvDMGKHT9FSVdemtwxVdSewCKgCdAdGu8VGAz3c192BN1Q1TVWnA2VEpFJ2dViwNAwjhnhNz+a9z9Kd8H4mMAM4RVXXghNQgQpusSrAqgynJbv7ssSCpWEYMcPvRBoiUgJ4D7hdVXdkV3Um+7JdzmgDPIZxDEEvR6wyJLg1GqtH9Q/MdhD4uYBHRArhBMoxqpo+t3u9iFRS1bXuY/YGd38yUC3D6VVxlmVnibUsDcOIGRFXMsLLlh3u6PYoYJGqPpPh0EfAIPf1IGBihv1XikhERFoD29Mf17PCWpaGYcQMH3XD2wADgQUiMs/ddx/wGDBeRIYAfwC93WOf4UwbWoozdWhwThVYsDQMI2b49RiuqlOzKdY5k/JpwE0eqj5MKB/DwygTumrVKs7v0pEmjerRtHEDnn9uhG+2IZzXBE5sieDaFUvy7T8uOLyteKkX158nNKxehi/+fi7f/uMCJj94Hk1rOkJ3N19Y93DZqY9cyIbX+lKmeFKu6ty3bx9tz2pJy6aNadq4Af986IFc++0rIVocHrpgGVaZ0MTERB574mnmLVjEd1On8/JLL4TC76ClU09kieCl63bS4f5JdLh/Ep0e+II9+1P4dM4qHuzbhCcmLqTD/ZP41/sLeKBPEwCe/3zx4fL/fHc+0xZvZNvuPwulZUfhwoWZ9NXXzJw7nxmz5/HlF5OYMX16rmz4iak7BkhYZUIrVarEmU2bAlCyZEnq1q3HmjX+qOqF9ZqASQSn077BKazYuIvkzXtIS4OSRQoBUKpYEuu27f1T+Z6tT+W96blXaYlEIpQo4cjzHjx4kJSDB2MrWGYaPMFREGRCV65Ywbx5P9GiZStf7BWEaxIEYbouPVudyvtu8PvrmLk81K8JPz9zCf/o14R/vjv/qLJFk6J0blSJj2evysxUjqSmptKqWROqV65Apy7n0rKVP9/DvBKCJ3Ag+HyWd4jILyKyUETGikiR/NoMu0zorl276N/nMp58ejilSpXyxWbYr0lQhOW6FIomcMGZVZg40wl+gzvV5m9vz+WMYR/x17fn8tyQo4PZ+U2qMOO3Tbl+BE8nGo0yY848lq5IZvasmfyycGGe7PhGSKJlYMFSRKoAtwLNVbUhEMURLssXYZYJPXjwIP37XEbf/pfT49KevtkN8zUJkrBcly5nVOLnlVvYuMORze3X9jQ+np0MwMSZq2ha8+iUsD1bVz/cCs0PZcqUof05Hfjyy2D6jL1gfZZHSASKikgiUIwcZsh7IawyoWlpadxw7RCkbj1uu2OYLzbTCes1CZqwXJeerU89Kvit27aXNnWdJczt65/C7+t3Hj5WsmghzpYKfD43OU91bdy4kW3btgGwd+9evp78P0Tq5smWHyREvG+xJrB5lqq6WkSewpkIuhf4UlW/zK/dsMqETvvhB94e8yYNGzaiVTNndPOhhx/lggu75tt2WK8JmERw0aQoHRpWZNjrsw7vu/3VmTx6RTMSEyLsP5jKsNeOyO12a1aVbxauY8+B1MzM5ci6tWu59upBpKamcijtEJf16kPXi7rlyZYv+LneMWACk8IVkZNw1mn2BbYB7wITVPWtLMrXwKRwjROAsK0ND1IKd9Q7n3JKpWyT/QCwfu1qhvS9yFcfckuQj+FdgOWqulFVD+KIlp0dYH2GYYSMME0dCnK54x9Aa1fhcS/OkqPZAdZnGEbICNFTeHAtS1WdAUwA5gIL3LpeCao+wzBCSIiWOwYthfsAEOPFp4ZhxCum7mgYhuEFr/2RsY+VFiwNw4gdYeqztGBpGEbsCFG0tGBpGEbMSIhESPDwHO6lTNBYsDQMI2aEqGFpwdIwjNgRwaMGT+Ce5IwFS8M4zgQpV3tS31G+24we2E7OCxLzSnjalhYsDcOIGT6qOwaOBUvDMGJGeNqVFiwNw4glIZqUHjoNHohvedOCZjtoCV8I53UJg4TvLd0aMGd4T2Y/25PRd3SgcKEoI4e2ZcbTPZj5zKW8fVcnihdx2ktt6ldk2pPd2Tl+MJe2ruHjJ8key5QeIPEub1rQbAcp4QvhvS7xLuFbuWwxhnZtQJu7J9L8jveJJkTo3bYmd782g1Z3fkjLYR+watNubrywPgCrNu7iuue/550pvwfxkbImRIk0QhcswyRvWhBsBynhC+G9LmGQ8E2MRiiaFCWaEKFoUiJrt+xh596Dh48XSYqSnvv7j427WLhyK4cCSgaeFSGKleELlmGSNy0ItjPit4QvFIzr4jd++L1myx6Gf7SQJS/1Y/l/+7NjzwEmz3dsvHxTO1aMGoBUKc2Ln/3iq++5JX0Fj5ct1gQthXubK4P7i4jc7ofNsMibFhTb6QQh4Qvhvy5B4IffZYon0a1FdeoNHU/Na8dSvEgh+rWvBcD1L0yh5rVjWZy8nV5tavric54JUdMySCnchsC1QEugMdBNROrk125Y5E0Lim0ITsIXwn1dgsIPvzudUZkVG3ayacc+UlLT+HD6ClrLKYePHzqUxoQfltHjOA7mZEaIYmWgLct6wHRV3aOqKcB3wKX5NRoWedOCYjtICV8I73UJEj/8XrVpNy1Pr0DRpCgAHRtVRpO3UbNiycNlLmpenSWrt/vqe24xDR6HhcAjIlIOR4OnKz5o8IRB3rQg2Q5SwhfCe13iXcJ31m8b+eDH5fz4VA9SUtOYv3wzo75azKSHulKyaCEikQgLVmzm1lemAdCs1sm8c08XyhRPomvz6vytX1Oa3f6+L58nO8KUKT0wKVwAERkC3ATsAn4F9qrqHVmUrYFJ4RpGvghsbfiSlyEAKdz3P/2KypVzXnm+Zs1qel50rq8+5JagNXhGAaMARORRIDnI+gzDMIIi6NHwCu7/1YGeQHDq8oZhhI70FG05brF2lODXhr/n9lkeBG5S1a0B12cYRogIU59l0I/h7YK0bxhGuEmIOJuXcrHGsg4ZhhE7QpSjzYKlYRgxw4mVXh7DY48FS8MwYoZlSjcMw/CAn0/hInIBMAKIAv9VVV+To4Yu65BhGAUInxaHi0gUeAG4EKgP9BeR+n66Gk8tyyjA+nXrYu2HYYSW6AH/13pHD+48/NJv2xvWr8dLu9Eply0tgaWqugxARMYB3XFWDvpCPAXLSgCDr7w81n4YRmgJTrIWcP5G/UqlvgPYOvjKy0/KxTlb3fMyowqwKsP7ZMC/xKvEV7CcBbQD1gKpMfbFMIwjRHEC5Sy/DKrqFhGpDeQmOeoOVd2SxbHMmqe+Jr6Im2CpqvuBqbH2wzCMTPFdnMcNfFkFv9ySDFTL8L4qsMYn20AcBUvDMIx8MAuoIyKnAauBfsAAPyuw0XDDMEKPm2D8ZuALYBEwXlV9FRgKNJ+lYRhGQcFaloZhGB6wYGkYhuEBC5aGJ0QkDlbn5g4RKR6g7YphvCZG3glVn6WICFAWR/jskKr6Oh9TRKJ+23Tt1gbKAAvcKVJ+2m4AnAwsVNXNPttui6N58qb7PqKqvn1hRORioKaqjvDLZgbb3YFzgX+o6gafbZ8PPAj0VdU/fLbdGqgD/AbMVdUDPtquA5QGfgII4rtekAlNy1JEegITgYdxdH1uEpHcTGjNzvbp4Hx53DWmviEi3YD3gSeB19Pr8sn2hThSHXcAb4hIRZ/sJohICeBl4F4RuQFAVdNExJfvjIicB/wTH5ejZbB9DvA4MDGAQHmea7sScKfPti8BXgG6AHcBp/pouwcwAbgXeAa4PsiWd0EkFMFSRAoBfYEhqtoZJ2hWA+7Ob8B0g9k8EXkb/A2YInI28BQwSFU74izX+otPtjvgZFi5RlV7AAeAhn7YVtVDqroLGI3zw3S2iNyRfiy/9t3r8iZwnap+JSKlReRUESmWX9suzXCyznwlIpVF5FwRaSUipfNjVES6AC8Cl+O0/uqJSHsf/MWVX7kJGKCqg3CW9TURkQoiUsQH29cD/VX1MmA+MBi4Q0RKZnuycZhQBEuXUjhfUIAPgE+AJGBAXvuO3F/Wm4HbgQMi8hb43sJ8TFV/cl8/AJQVkcI+2F0PXK+qM90WZSvgZhF5WUR6+dSfloLzozQaaCkiz4jIv0Qkks8W5mYcXaZK7h/yh8BInJa3H76nZHg9Abga5z6/ICK5WYt8LFHgSnf+XnFAgQbgS59uClAUqOs2ADoAVwLDgb/lsxWYApQAKgKo6qvASqA80C0fdk8oQhEsVfUgzqNDTxFp57ZupgLzgLb5sLsb5w/pbZzHniIZA2a+HYcZOI/g6SmkCuM8WpVy95XLq2FVXaSq37hvhwAvui3M6UBvnH7M/DIRWKeqk3H6iW8ASqlqWn5amKqqwEXAszitnLdx/mgnAZcB+QloAF8D17qZZ/6jqv1xfqh24WSnyavfX6jqNBFJUNVtwKfAAyLSKL99uaq6HXgO5zH5S+A1Vb0Y+C/O0r3a+bQ9BhgsIgNF5BFgH04XyLn58ftEIhTB0mUKzpdooIi0V9VUVX0bqAw0zqtRVV2jqrtUdRPOo0rR9IApIk1FpG4+bKeqanqWlAiwDdiiqhtF5HLgYREpmlf7Gep5RFUfdl+/BpTk6HWyeWUvzrjatTiB8jGguohcn1/DqjofJ0D+S1X/4z76v4oTKKvn0/ZCnB+/VsBp7r5lOC3D8vlynCNdEao6CaePsZsPrW1UdQJOf+UUjgzCfI1zP/PbfzkW58eoE1BMVa9Q1ZeBCn71/Rd0QrM2XFX3icgYnEwi97pBbD9wCk6mIj/q2OwGgidFZDHOH1dHn2ynALtEZJWI/As4D7hKVffmx+6xI9QichnONcl3EgFVXSMiq4C/40gZfywiHYGl+bXt2v+VDAM8ru/l8ed+fo7TmnxQRFa6+87ECfh+Mh9ngO0JP55GVHWriHwN9BGRA0ARnID/cz7tbgfGiMjY9GAvIlfizC6xUXEPhGrqEICIJAFtcFqB+4ARGfoE/arjDuAe4FxVXeCTzQhQCGfdaiGgs6r+5odt135h4ApgGM6UloU+2a0GVFDVOe77BD8GeY6pI4Iz4HAX0NvPNb0i0hTohdMF8rpf9/OYOsYDd6vqCp/slcHpr7wM5zt+t9sS9w0RuRrnevcN4poUREIXLNNx+wDz1XeWhd2TgPHAnaqar1/zLOxfBczye5G/O2PgXOB3t0/QV/yeY3msbeAcnP7RxUHUEQRBXhPXfkkgkqErx0/bpwKFVNWXp4QTgdAGyyARkSKqui8g24H+gRmGEQwWLA3DMDwQptFwwzCMmGHB0jAMwwMWLA3DMDxgwdIwDMMDFixDioisEJHFIjJfRBaKSD8f7TZ0X38mIrVyKN9DRPK0hFBErhKRCTn5kYONNHEyJOWm3hoisik35xiGBctw00tVGwMDgddE5E/rwfOTEERVu6pqThKoPcjHemvDCAuhWe5oZI2q/iQiO4HT3JRz/YCNQH1giIisB/6Ns+a6KDBWVR8FEJF2OGnH9uIk4TicPUdEVgDdVHWhiFTBSfSQnvlpLDAXuAToIiLXAM+o6hsiMggYivP92g7cqKrqrr76N05GndWApwnoInKn+5kScVa03Kiq8zIUuUucPJPlgPtU9T33vFY4yxvT1z7fr6qfeqnTMI7FgmUBwF2vXQQnu3YDnExMjdNbhSLyFfBPVf3eDViTRWQW8D0wDrhcVb8VkT7ALVlU8xbwmZsPERE5WVU3ichHwGxVfd7d3w7oA7RX1f3iJCh+lSNLVE/DybtZyK1/hYeP+IaqPu3a7wK8BLTOcPyQqp4tIgJME5EpOPk9XwK6qupaEakEzPLyaG8YmWHBMtxMEJF9OIliL1PVbU68YGqGQFkcpyVX3j0GThabejg5Mfeo6rcAqjpeRF45thK3T/BsMqTzcrM0ZcbFOFmgZrj1RTiScq0jMNpNuXfQze7kJcVeMxG5DyfpwyHg2Gzzo1yfVETm4gTSFJzA/HmGz52Gk+rM+iuNXGPBMtz0yiJhxq4MrxNwgkQLN0gdRkTynNouGyLAq6p6fxbHcoXbEp6A01KdKyKVcR7hs6s/zf3/Z1X9UyZzEamRWz8MwwZ4CjiquhMnP+JhOQsRqSZOdvXFOPk727v7e+EIWh1rYxcwDScVWbqN9MGkHcec8zFwpYhUdctFRaSZe2wyTj7SRDeP5wAPH6EIzo/6Kvf90EzKDHbrqgM0wUm6PA2o43ZRpPvcQkyR0cgjFixPDC4H6ovIAhFZALwDlFFHabI/jtzCTKA5kJVa4RVAG3ea0nyc7OzgaOkMEJF5InKlqn4P/BX4yC23EOjuln3Ftf8LjizIdzk57mbcuR+nv/F7YHcmxfaLyA+uzetVdYOqbsUZfHrAnV61CEeR0YKlkScskYZhGIYHrGVpGIbhAQuWhmEYHrBgaRiG4QELloZhGB6wYGkYhuEBC5aGYRgesGBpGIbhgf8H1Ri4bR1R9PAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các giá trị trên đường chéo rất cao, chúng ta mô hình chúng ta có độ chính xác rất tốt.\n",
    "Nhìn vào confusion matrix ở trên, chúng ta có một số nhận xét như sau:\n",
    "* Số 4 hay nhầm lẫn với số 9, bởi vì khi viết tay đường nét của 2 số này tương tự nhau khá nhiều\n",
    "* số 3 và số 8, cũng hay bị tình trạng tương tự. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiển thị một số trường hợp bị sai\n",
    "Để có cái nhìn rõ hơn về một số mẫu bị sai, chúng ta quan sát top các mẫu có giá trị dự đoán khác nhất so với nhãn thật "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "    fig.tight_layout()\n",
    "    \n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với các mẫu ảnh sai, chúng ta có thể thấy rằng những mẫu này rất khó nhận dạng nhầm lẫn sáng các lớp khác. ví dụ số 9 và 4 hay là 3 và 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Kfold, Predict và submit kết quả\n",
    "Chúng ta huấn luyện lại mô hình sử dụng kfold, kết quả cuối dự đoán cuối cùng là trung bình cộng sự đoán của các mô hình huấn luyện trên mỗi fold.\n",
    "Chúng ta chọn nhãn là lớp được dự đoán có xác suất cao nhất mà mô hình nhận dạng được"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 41s - loss: 0.1605 - acc: 0.9510 - val_loss: 0.1090 - val_acc: 0.9704\n",
      "Epoch 2/30\n",
      " - 18s - loss: 0.0744 - acc: 0.9780 - val_loss: 0.0754 - val_acc: 0.9787\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0538 - acc: 0.9839 - val_loss: 0.0673 - val_acc: 0.9818\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.0577 - acc: 0.9837 - val_loss: 0.0437 - val_acc: 0.9864\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.0434 - acc: 0.9868 - val_loss: 0.0358 - val_acc: 0.9901\n",
      "Epoch 6/30\n",
      " - 17s - loss: 0.0433 - acc: 0.9873 - val_loss: 0.0448 - val_acc: 0.9877\n",
      "Epoch 7/30\n",
      " - 16s - loss: 0.0363 - acc: 0.9893 - val_loss: 0.0391 - val_acc: 0.9907\n",
      "Epoch 8/30\n",
      " - 17s - loss: 0.0214 - acc: 0.9934 - val_loss: 0.0252 - val_acc: 0.9926\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0169 - acc: 0.9946 - val_loss: 0.0249 - val_acc: 0.9927\n",
      "Epoch 10/30\n",
      " - 18s - loss: 0.0145 - acc: 0.9957 - val_loss: 0.0328 - val_acc: 0.9907\n",
      "Epoch 11/30\n",
      " - 17s - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0212 - val_acc: 0.9935\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0283 - val_acc: 0.9925\n",
      "Epoch 13/30\n",
      " - 17s - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0228 - val_acc: 0.9937\n",
      "Epoch 14/30\n",
      " - 18s - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0217 - val_acc: 0.9939\n",
      "Epoch 1/30\n",
      " - 43s - loss: 0.1577 - acc: 0.9516 - val_loss: 0.0594 - val_acc: 0.9850\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.0745 - acc: 0.9779 - val_loss: 0.0811 - val_acc: 0.9805\n",
      "Epoch 3/30\n",
      " - 18s - loss: 0.0598 - acc: 0.9817 - val_loss: 0.0641 - val_acc: 0.9839\n",
      "Epoch 4/30\n",
      " - 18s - loss: 0.0299 - acc: 0.9910 - val_loss: 0.0282 - val_acc: 0.9912\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.0229 - acc: 0.9932 - val_loss: 0.0210 - val_acc: 0.9944\n",
      "Epoch 6/30\n",
      " - 18s - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0273 - val_acc: 0.9924\n",
      "Epoch 7/30\n",
      " - 17s - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0249 - val_acc: 0.9929\n",
      "Epoch 8/30\n",
      " - 17s - loss: 0.0148 - acc: 0.9953 - val_loss: 0.0191 - val_acc: 0.9946\n",
      "Epoch 9/30\n",
      " - 18s - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0201 - val_acc: 0.9940\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0197 - val_acc: 0.9945\n",
      "Epoch 11/30\n",
      " - 17s - loss: 0.0113 - acc: 0.9963 - val_loss: 0.0190 - val_acc: 0.9951\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.0106 - acc: 0.9972 - val_loss: 0.0190 - val_acc: 0.9944\n",
      "Epoch 13/30\n",
      " - 17s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0185 - val_acc: 0.9949\n",
      "Epoch 14/30\n",
      " - 17s - loss: 0.0107 - acc: 0.9968 - val_loss: 0.0180 - val_acc: 0.9956\n",
      "Epoch 15/30\n",
      " - 18s - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0185 - val_acc: 0.9952\n",
      "Epoch 16/30\n",
      " - 18s - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0182 - val_acc: 0.9955\n",
      "Epoch 17/30\n",
      " - 18s - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0182 - val_acc: 0.9955\n",
      "Epoch 1/30\n",
      " - 47s - loss: 0.1586 - acc: 0.9507 - val_loss: 0.1703 - val_acc: 0.9568\n",
      "Epoch 2/30\n",
      " - 17s - loss: 0.0760 - acc: 0.9769 - val_loss: 0.0712 - val_acc: 0.9842\n",
      "Epoch 3/30\n",
      " - 18s - loss: 0.0575 - acc: 0.9832 - val_loss: 0.0607 - val_acc: 0.9860\n",
      "Epoch 4/30\n",
      " - 19s - loss: 0.0477 - acc: 0.9855 - val_loss: 0.0382 - val_acc: 0.9879\n",
      "Epoch 5/30\n",
      " - 18s - loss: 0.0472 - acc: 0.9859 - val_loss: 0.0358 - val_acc: 0.9902\n",
      "Epoch 6/30\n",
      " - 18s - loss: 0.0426 - acc: 0.9872 - val_loss: 0.0674 - val_acc: 0.9796\n",
      "Epoch 7/30\n",
      " - 18s - loss: 0.0361 - acc: 0.9892 - val_loss: 0.0361 - val_acc: 0.9914\n",
      "Epoch 8/30\n",
      " - 18s - loss: 0.0224 - acc: 0.9935 - val_loss: 0.0275 - val_acc: 0.9939\n",
      "Epoch 9/30\n",
      " - 18s - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0233 - val_acc: 0.9939\n",
      "Epoch 10/30\n",
      " - 17s - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0222 - val_acc: 0.9943\n",
      "Epoch 11/30\n",
      " - 17s - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0254 - val_acc: 0.9932\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0301 - val_acc: 0.9926\n",
      "Epoch 13/30\n",
      " - 18s - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0232 - val_acc: 0.9938\n",
      "Epoch 1/30\n",
      " - 46s - loss: 0.1574 - acc: 0.9497 - val_loss: 0.1697 - val_acc: 0.9568\n",
      "Epoch 2/30\n",
      " - 18s - loss: 0.0715 - acc: 0.9782 - val_loss: 0.0979 - val_acc: 0.9751\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0613 - acc: 0.9819 - val_loss: 0.0497 - val_acc: 0.9844\n",
      "Epoch 4/30\n",
      " - 18s - loss: 0.0509 - acc: 0.9849 - val_loss: 0.0696 - val_acc: 0.9800\n",
      "Epoch 5/30\n",
      " - 18s - loss: 0.0426 - acc: 0.9871 - val_loss: 0.0431 - val_acc: 0.9881\n",
      "Epoch 6/30\n",
      " - 18s - loss: 0.0387 - acc: 0.9874 - val_loss: 0.0418 - val_acc: 0.9905\n",
      "Epoch 7/30\n",
      " - 18s - loss: 0.0410 - acc: 0.9879 - val_loss: 0.0347 - val_acc: 0.9915\n",
      "Epoch 8/30\n",
      " - 18s - loss: 0.0382 - acc: 0.9882 - val_loss: 0.0553 - val_acc: 0.9883\n",
      "Epoch 9/30\n",
      " - 18s - loss: 0.0360 - acc: 0.9897 - val_loss: 0.0294 - val_acc: 0.9912\n",
      "Epoch 10/30\n",
      " - 18s - loss: 0.0340 - acc: 0.9899 - val_loss: 0.0279 - val_acc: 0.9920\n",
      "Epoch 11/30\n",
      " - 18s - loss: 0.0294 - acc: 0.9909 - val_loss: 0.0483 - val_acc: 0.9886\n",
      "Epoch 12/30\n",
      " - 18s - loss: 0.0308 - acc: 0.9903 - val_loss: 0.0374 - val_acc: 0.9924\n",
      "Epoch 13/30\n",
      " - 19s - loss: 0.0154 - acc: 0.9952 - val_loss: 0.0220 - val_acc: 0.9943\n",
      "Epoch 14/30\n",
      " - 19s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0219 - val_acc: 0.9952\n",
      "Epoch 15/30\n",
      " - 18s - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0211 - val_acc: 0.9942\n",
      "Epoch 16/30\n",
      " - 18s - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0230 - val_acc: 0.9945\n",
      "Epoch 17/30\n",
      " - 18s - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0209 - val_acc: 0.9943\n",
      "Epoch 18/30\n",
      " - 18s - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0286 - val_acc: 0.9933\n",
      "Epoch 19/30\n",
      " - 17s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0191 - val_acc: 0.9940\n",
      "Epoch 20/30\n",
      " - 18s - loss: 0.0115 - acc: 0.9965 - val_loss: 0.0244 - val_acc: 0.9942\n",
      "Epoch 21/30\n",
      " - 19s - loss: 0.0095 - acc: 0.9968 - val_loss: 0.0193 - val_acc: 0.9955\n",
      "Epoch 22/30\n",
      " - 18s - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0182 - val_acc: 0.9951\n",
      "Epoch 23/30\n",
      " - 18s - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0200 - val_acc: 0.9954\n",
      "Epoch 24/30\n",
      " - 18s - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0199 - val_acc: 0.9949\n",
      "Epoch 25/30\n",
      " - 18s - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0193 - val_acc: 0.9952\n",
      "Epoch 1/30\n",
      " - 47s - loss: 0.1594 - acc: 0.9504 - val_loss: 0.0880 - val_acc: 0.9733\n",
      "Epoch 2/30\n",
      " - 18s - loss: 0.0724 - acc: 0.9779 - val_loss: 0.0653 - val_acc: 0.9835\n",
      "Epoch 3/30\n",
      " - 17s - loss: 0.0589 - acc: 0.9827 - val_loss: 0.0463 - val_acc: 0.9896\n",
      "Epoch 4/30\n",
      " - 17s - loss: 0.0504 - acc: 0.9853 - val_loss: 0.0393 - val_acc: 0.9900\n",
      "Epoch 5/30\n",
      " - 17s - loss: 0.0556 - acc: 0.9836 - val_loss: 0.0496 - val_acc: 0.9874\n",
      "Epoch 6/30\n",
      " - 18s - loss: 0.0419 - acc: 0.9879 - val_loss: 0.0629 - val_acc: 0.9830\n",
      "Epoch 7/30\n",
      " - 19s - loss: 0.0230 - acc: 0.9926 - val_loss: 0.0227 - val_acc: 0.9949\n",
      "Epoch 8/30\n",
      " - 18s - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0201 - val_acc: 0.9955\n",
      "Epoch 9/30\n",
      " - 17s - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0234 - val_acc: 0.9944\n",
      "Epoch 10/30\n",
      " - 18s - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0230 - val_acc: 0.9938\n",
      "Epoch 11/30\n",
      " - 18s - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0216 - val_acc: 0.9952\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "preds = []\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    X_train, Y_train, X_val, Y_val = X[train_index], Y[train_index], X[valid_index], Y[valid_index]\n",
    "    train_gen = train_aug.flow(X_train, Y_train, batch_size=batch_size)\n",
    "    valid_gen = test_aug.flow(X_val, Y_val, batch_size=batch_size)\n",
    "    acc, model, history = train_model(train_gen, valid_gen, best_params)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = np.mean(preds, axis=0)\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lúc chạy thực tế, cần thay max_evals lúc search tham số thành 50 để có được accuracy trên tập test > 0.997. Kết quả dưới đây được submit trên kaggle mà không sử dụng kfold \n",
    "![](https://github.com/pbcquoc/pbcquoc.github.io/raw/master/images/kaggle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
