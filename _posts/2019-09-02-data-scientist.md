---
layout: post
title: Data Science là gì. Làm gì để trở thành Data Scientist?
---
# Giới Thiệu
Sau nhiều năm đi làm dưới danh nghĩa là một Data Scientist, mình nhận thấy rằng một bài viết chia sẻ của một người làm trong ngành này sẽ giúp ích cho một số bạn mới ban đầu theo đuổi công việc Data Scientist cho một công ty lớn như VNG, Tiki sẽ hình dung được một bức ảnh toàn cảnh về công việc khi các bạn bước vào làm. Những chia sẻ này làm những cảm nhận chủ quan nên có thể đúng với người này và cũng có thể sai với những người khác. <br/><br/> Cụ thể hơn trong bài viết này, mình sẽ chia sẻ về sự khác nhau giữ 3 công việc rất gần gũi với nhau như Data Engineer, Data Analytics và Data Scientist khác nhau chỗ nào? Các kiến thức cần có để trờ thành Data Scientist, và cuối cùng là các lưu ý và quy tắc khi các bạn bắt đầu một dự án data science cho công ty. 

# Sự khác biệt giữa Data Engineer, Data Analyst, Data Scientist
## Data Engineer là gì?
Data Engineer là những người đảm nhận nhiệm vụ xây dựng hệ thống để lưu trữ và truy xuất dữ liệu của việc kinh doanh của công ty. Là người được tuyển dụng sớm nhất trong 3 công việc trên. Bên cạnh việc chính là lưu trữ và truy xuất, Data Engineer còn phải tối ưu hoá việc lưu trữ để truy vấn nhanh nhất. Ngoài ra, tuỳ thuộc vào bài toán mà hệ thống này phải lưu trữ tính toán realtime. Hệ thống của Data Engineer xây dựng có thể đơn giản hay cực kì phức tạp để phục vụ lương lớn khách hàng, và tất nhiên tuỳ thuộc vào hệ thống phức tạp hay không mà yêu cầu về kinh nghiệm và trình độ của người Data Engineer cũng khác nhau. Thông thường, Data Scientist hay Data Analyst đều phải làm việc với Data Engineer để tìm hiểu về hệ thống hiện tại, nắm được bức tranh tổng quát về luồng dữ liệu trong hệ thống từ đó giúp cho các bạn hiểu được data sẽ có khi nào và nơi nào lưu trữ và ý nghĩa chung của những loại dữ liệu. 

Những tool mà mình biết các bạn Data Engineer thường xuyên làm việc là các tool liên quan đến lưu trữ dữ liệu như Mongo, SQL, Postgres, những công cụ như Spark giúp xây dựng một hệ thống phân tán. Ngôn ngữ mà Data Engineer thường dùng là Java. 
## Data Analytist là ai?
Sau khi dữ liệu được lưu trữ, lúc này các công cty sẽ có như cầu phân tích dữ liệu để biết được tình trạng hiện tại của việc kinh doanh. Lúc đó một Data Analytist sẽ được tuyển dụng và làm những công việc như đưa ra các số liệu thống kê, theo dõi các chỉ số về tình trạng hoạt động của công cty. Một Data Analytist như làm dâu trăm họ. Các team khác nhau của công ty đều cần tới  để lấy chỉ số, để yêu cầu các report, để hỗ trợ đo đếm số liệu cho một tính năng mới. Cuộc sống của một Data Analytist thường xoay quanh report.

Các Data Analytist cần có những kiến thức cơ bản về sác xuất và thống kê để tránh đưa ra những báo cáo bị [bias](https://en.wikipedia.org/wiki/Sampling_bias). Điều này là cực kì quan trọng vì Data Analytist cũng chính là người đưa ra những lời khuyên cho bên kinh doanh. Do đó các kết luận không chính xác đều gây ra những ảnh hưởng tiêu cực. 

Các ngôn ngữ lập trình mà Data Analytist hay sử dụng là Python, R, hay thâm chí là Excel. Do đó, nếu bạn mong muốn làm Data Analytist thì hãy thật vững 2 ngôn ngữ lập trình này. 

Hình dưới mình ghi lại những từ khoá quan trọng mà các bạn khi muốn trở thành Data Analytics thì cần phải biết và nắm thật vững nhé. Có khá nhiều bạn muốn trở thành Data Analytics và có chuyên môn bên kinh tế nên những điều này hy vọng sẽ vạch ra con đường rõ ràng hơn cho các bạn đi tiếp. 

<div class="img-div" markdown="0">
    <img src="/images/data_scientist/da_roadmap.png" />
</div>

# Các kiến thức cơ bản cần có để trở thành Data Scientist
Người ta hay bảo nhau rằng **Data Scientist: The Sexiest Job of the 21st Century**. Tuy nhiên, những năm vừa qua do việc tuyển dụng khá nhiều nên title Data Scientist đôi khi được đặt lên nhầm người. Bản thân mình cũng thấy cái tên gọi Data Scientist cũng là chưa thực sự phù hợp với khả năng hiện tại.

<div class="img-div" markdown="0">
    <img src="/images/data_scientist/meme.jpeg" />
</div>

Để trở thành Data Scientist các bạn phải có nhiều kiến thức cũng như là kinh nghiệm (những bài học từ những sai lầm) trong quá trình làm việc. Các kiến thức đó bao gồm: Ngôn ngữ lập trình, Cơ sở dữ liệu và tính toán phân tán, Software/Web Engineering, Data Visualization and story teller, Data Sense, Xác suất và thống kê, Máy học, Deep Learning, Giải tích và đại số tuyến tính. Những kiến thức trên hầu hết đều được mình sử dụng trong để giải quyết cho những bài toán hiện tại, cho nên kiến thức trên đều quan trọng chứ không phải chỉ là một đống lý thuyết chỉ liệt kê trên giấy.

Ngôn ngữ lập trình ở đây là các kiến thức vể lập trình như các cơ bản của một ngôn ngữ, cấu trúc dự liệu, lập trình hướng đối tượng. Những kiến thức này chính là nền tảng của mọi lập trình viên. Do đó sẽ giúp ích rất nhiều cho khi làm việc thực tế để hiểu,viết và tổ chức mã nguỗn cho hợp lý, gọn gàng và dễ phát triển về sau. 

Cơ sở dữ liệu và tính toán phân tán là kiến thức về các cơ sở dữ liệu phổ biến như mysql, mongo, redis, mapreduce concept, hadoop, spark, cách tổ chức và xây dựng hệ thống để hỗ trợ việc xây dựng mô hình máy học có thể  scale khi cần thiết và chạy được cả offline và online để 

Với những kiến thức cơ bản về web programming, các Data Scientist có thể tự tạo một dashboard cơ bản để theo dõi kết quả của mô hình, các chỉ số liên quan để đánh giá ảnh hưởng của dự án đến người dùng, hoặc là một giao diện đơn giản để a/b testing, hoặc là dùng để labeling hay đơn giản là để thể hiện kết quả ra bên ngoài cho nội bộ team sài và đánh giá. Việc tạo ra một giao diện có tương tác sẽ giúp ích và giảm thiểu thời gian đánh giá kết quả đi rất nhiều. Với những team nhỏ, không có đủ nhận lực thì kiến thức về lập trình web sẽ rất hữu ý cho một Data Scientist.

Data Visualization là kĩ năng dùng đồ thị để minh hoạ cho nhưng con số, các Data Scientist cần biết những đồ thị nào là phù hợp để minh hoạ cho những insight của dữ liệu, minh hoạ các con số được nói từ dữ liệu. Ngoài ra có thể tự tạo được những đồ thị phù hợp với ý muốn của mình. Song song bên cạnh Data Visualization là kỹ năng Story telling, kỹ năng này giúp Data Scientist truyền tải những con số , những insight từ mô hình máy học thành những lời nói dễ hiểu cho những bên liên quan, đặt biệt là bên kinh doanh, hoặc cấp trên. Kỹ năng này liên quan tới vấn đề giao tiếp nhiều hơn. 

Data Sense thực chất là những cảm nhận hay trực giác khi giải quyết bài toán. Khả năng này khá mơ hồ và cũng rất thú vị. Khả này này giúp chúng ta đạt ra những câu hỏi nghi ngờ hay tìm hướng đi đúng đắn cho bài toán. Vì mỗi mô hình kinh doanh lại có những vấn đề cụ thể khác nhau. Thông thường khi giải quyết bài toán, chúng ta không đơn giản chỉ là dùng một máy học phổ biến như XGBoost, hay là logistics regression là xong. Mà phải biết cách thiết kế luồng đi của của việc dự đoán phù hợp với nhu cầu của mọi người. 

Xác suất và thống kê là kiến thức **không thể thiếu** đối với một Data Scientist thực sự. Cũng giống như Data Analytics, các kiến này bao gồm: biến ngẫu nhiên, các hàm phân bố cơ bản, frequentist probability, bayesian probability, population, sampling, law of large numbers, center limit theorem, hypothesis testing, bayesian inference. Các kiến thức này cực kì hữu dụng cho các Data Scientist hiểu kĩ hơn về dữ liệu. Giúp mình xây dựng những mô hình thống kê để giải quyết bài toán. 

Machine learning (Máy học) thì không cần phải bàn nhiều vì nó chính là kiến thức trọng tâm của một Data Scientist, là công cụ để giải quyết hầu hết các bài toán. Hiểu được ưu nhược điểm của mô hình máy học giúp cho mình tự tin và lựa chọn được một mô hình phù hợp. Mô hình máy học thì mênh mông. Tuy nhiên, các mô hình được sài thường xuyên là logistic regression, Decistion tree, Gradient Boosted Machine. Các bạn hãy nắm thật vựng về nó nhé. 

Deep Learning là kiến thức cũng không thể thiếu được của một Data Scientist. Những mô hình này giải quyết tốt các bài toán liên quan đến hình ảnh và ngôn ngữ tự nhiên. Hiện tại, Deep Learning vẫn là một topic hot nhất và sôi động nhất trong giới học thuật và được ứng dụng khá nhiều trong đời sống. Các bạn ắt hẵn đã từng nghe về hệ thống nhận dạng khuôn mặt của [Trung Quốc](https://www.forbes.com/sites/zakdoffman/2019/10/08/trump-lands-crushing-new-blow-on-chinas-facial-recognition-unicorns/), tạo ra các bản nhạc, rồi tới chơi cờ vậy. Các mô hình chủ yếu là Convolution Neural Nets và Recurrent Neural Nets. Các biến dạng của 2 mô hình này thì có vô vàng. Các bạn hãy tận dụng thành xuân mà học cho hết nhé.

Giải tích và đại số tuyến tính là kiến thức toán nền toán của các mô hình máy học. Giúp các bạn nắm vững phần toán sau những mô hình đó, từ đó giúp các bạn khả năng đọc hiểu được các tài liệu học thuật để cập nhận các kiến thức, mô hình máy học mới nhất.   

# Chu trình của một project data science
## Tìm hiểu về business
Đây là bước đầu tiên trong một dự án data science bất kỳ. và do đó, cũng là bước quan trọng nhất của toàn bộ dự án. Hiểu được ngữ cảnh của vấn đề kinh doanh cần được trợ giúp từ góc nhìn của data science sẽ giúp các bạn xác định rõ ràng mục tiêu cần được tối ưu dưới góc nhìn của một mô hình máy học. Trong bước này, chúng ta cần có thật nhiều kiến thức và kinh nghiệm trong vấn đề của kinh doanh. Từ đó, giúp chúng ta có những ý tưởng tốt trong bước feature enineering. Tuy nhiên, thông thường với nền tảng là một lập trình viên, chúng ta thường thiếu các kiến thức này, do đó, mình gợi ý các bạn hãy làm việc trực tiếp với bên kinh doanh, cố gắng hiểu thật kĩ những vấn đề của họ trước ghi các bạn thực hiện các bước tiếp theo. 

Mình muốn nhấn mạnh một lần nữa, có cái nhìn cụ thể, rõ ràng về vấn đề kinh doanh là rất quan trọng cho toàn bộ dự án. Giúp các bạn định hướng rõ ràng mục tiêu của dự án,các KPI và đảm bảo những gì bạn làm ra đem lại giá trị cho các bộ phận liên quan. 

## Data collection
Giai đoạn này liên quan đến quá trình kiến thức của Data engineering. Data dùng cho một dự án data science có thể đến từ nhiều nguồn khác nhau, ví dụ như đến từ các file csv, json, hoặc là từ cơ sở dự liệu lớn. Do đó kiến thức về ETL đữ liệu và SQL sẽ giúp ích khá nhiều trong giai đoạn này. Trong một số trường hợp, dữ liệu có thể không có sẵn mà các bạn phải tự thu thập trên các website. Một ít kiến thức về html cũng như về web api sẽ rất là hữu ích để giúp các bạn giải quyết khó khăn này. Một thư viện python mà mình hay sài để thu thập dữ liệu từ các website là beautifulsoup, các bạn cũng có thể tìm hiểu nhé. 

## Data Cleaning
Dữ liệu mà các bạn thu thập ở bước trên thông thường chưa được sử dụng ngay để đưa vào các mô hình máy học do chưa nhiều nhiễu hay các biến kiểu categorical hay các giá trị bị rỗng. Do đó, các bạn cần phải xử lý các dữ liệu như vậy trước thực hiện những bước tiếp theo. Một số vấn đề phổ biến trong gia đoạn xử lý dữ liệu này là thay thế các giá trị rỗng bằng một giá trị mặc định như trung bình, hay bất kì giá trị nào có ý nghĩa theo trong ngữ cảnh của bài toán. Các biến kiểu categorical thường được mã hoá sang vector dạng one-hot hoặc những vector biểu diễn khác được học từ các mô hình deep learning. Các outlier cần được xem xét và nên được xoá khỏi dữ liệu. Xác định các outlier này thường phụ thuộc vào kiến thức của lĩnh vực kinh doanh thực tế. 

Các bạn hãy luôn nhớ rằng việc làm sạch dữ liệu là việc cực kì quan trọng. Để bảo đảm mô hình có thế hội tụ cũng như trách các kết quả bất thường khi dự đoán. 

## Exploration Data Analysis
Đã có dữ liệu rồi bước tiếp theo các bạn cần là tìm hiểu dữ liệu bằng một số chỉ số thống kê cơ bản, và các kĩ thuật visualization để nhìn tận mắt vào những đối tượng các bạn cần làm việc. Thông thường, các bạn cần xem xét phân bố các của biến, mối tương quan giữ các biến với nhau và với biến cần dự đoán. Kiểm tra xem các lớp cần dự đoán có cân bằng hay không hay thậm chí thực hiện một số hypothesis test. Hoặc dimemsion reduction để xem phân bố trên không gian 2 hay 3 chiều như thế nào, có tuyến tính hay không hay là ngẫu nhiên.  

Quá trình tìm hiểu ở trên giúp các bạn đưa ra các nhận định về dữ liệu từ đó có những ý tưởng về việc feature engineering ở bước tiếp theo. Hoặc chọn mô hình hợp lý cho dự liệu của mình. 

## Modelling
Trong giai đoạn có thể là phần thú vị nhất đối với hầu hết các bạn. Khi chúng ta cần lựa chọn mô hình để huấn luyện từ tập dự liệu ở trên, cũng như sử dụng một số kĩ thuật đơn giản như grid search để tunning các tham số của mô hình. Trong hầu hết các trường hợp các bạn có thể sử mô hình đơn giản như linear regression/logistic regression cho việc xây dựng mô hình dự đoán vì 2 mô hình này chạy nhanh cũng như dễ dàng giải thích được kết quả đầu ra. Ngoài ra các cũng nên thử với mô hình gradient boosted machine được cài đặt trong 2 thư việc xgb và lightgbm, 2 mô hình thường cho kết quả tốt nhất đối với các dữ liệu kiểu có cấu trúc. 

Khi xây dựng mô hình, các bạn cần lưu ý đến độ trễ của việc dự đoán, tính giải thích được của mô hình. Trong một số trường hợp cần mô hình có thể dự đoán nhanh chóng và cần hiểu được lý do tại sao mô hình lại cho kết quả như vậy, các bạn có thể xem xét sử dụng linear/logistic regression. Ngoài ra, các bạn cần lưu ý rằng, khi sử dụng mô hình linear/logistic regression để dự đoán có độ chính xác 90% thì các bạn không cần thiết phải sử dụng những mô hình phức tạp hơn như neural nets để để cải thiện kết quả lên 1% vì tốn kém về mặc thời gian cũng như 1% cải thiện trong bài toán thức tế có thể không thật sự cần thiết để đánh đổi với tính giải thích được của các mô hình đơn giản. 

## Performance Evaluation
Huấn luyện xong mô hình thì tất nhiên các bạn cần phải đánh giá và so sánh kết quả với các chỉ số về kinh doanh nếu được. hoặc đơn giản là xem xét các độ đô đơn giản như precision, recall, hoặc cụ thể hơn là confusion matrix, hay các chỉ số như mse. Từ đó, các bạn cần quyết định xem mình nên tiếp tục cải thiện, hay đã đủ tốt để đưa vào production. 

## Communicating to stackholders
Ở bước này các bạn cần nói chuyện với bên kinh doanh để trao đổi với họ về những insight của mô hình. Và bên kinh doanh sẽ để xuất các cách để đánh giá mô hình của các bạn bằng các chỉ số của họ. Các bạn cần thuyết phục họ tại sao có thể sử dụng mô hình này để cải thiện hiệu quả công việc mà phương pháp cũ không làm được.

Hãy thuyết phục và kiên trì.

## Deployment
Đến bước này các bạn cần làm việc trực tiếp với team data engineer, để triển khai kết quả lên môi trường production. Các bạn cũng có thể cần phải xây dựng một giao diện đơn giản để phục vụ cho các cá nhân sử dụng kết quả của bạn hiệu quả hơn. Ngoài ra, các bạn cũng có thể phải viết lại phần dự đoán bằng ngôn ngữ C/C++ để giảm thời gian dự đoán trong các bài toán cần xử lý lượng lớn dự liệu.

## Real world testing
Kết quả đưa lên production và đánh giá mức độ hiệu quả. Nếu mô hình bạn đem lại kết quả tốt thì xin chúc mừng bạn đã có một dự án thành công. Trong giai đoạn này, các bạn có thể sử dụng A/B test để đánh giá tính hiệu quả khi triển khai mô hình mới  mà giúp các bạn đạt được KPI của bên kinh doanh đạt ra.

## Operations & Optimization
Ở bước cuối này, khi mô hình đã đưa vào vận hành các bạn cần theo dõi kết quả dự đoán, cũng như tính hiệu quả của mô hình vì trong một số trường hợp thực chưa lường trước như thay đổi phân bố dữ liệu hoặc các yếu tố vận hành sẽ làm cho mô hình các bạn cho kết quả tệ.

# Các lưu ý khi bắt đầu một dự án Data Science
Khi bắt đầu các dự án data science, việc các bạn nhận thức được các vấn đề sau sẽ giúp ích rất lớn trong quá trình làm việc và triển khai một dự án thành công.
Phần này mình trình bày các rules mà mình thấy quan trọng trong quá trình làm việc. Các bạn nên xem tất cả 43 rules được khuyến nghị bởi [Martin Zinkevich](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf) tại google để có cái nhìn tổng quan hơn nhé.

Trong hầu hết các trường hợp trong thực tế để có một mô hình machine learning tốt, chúng ta cần phải tập trung vào việc tìm kiếm các features tốt, hơn là đi tìm một mô hình phức tạp như neural nets. Do đó, để xây dựng một mô hình machine learning thành công, các bạn trước hết cần phải xây dựng môt pipeline hoàn chỉnh để dễ dành theo dõi, đánh giá mô hình, dễ dành thêm features. Từ đó giúp các bạn có thể nhanh chóng thực hiện các thí nghiệm mới. và giúp đồng nghiệp cùng cộng tác với nhau dễ dàng.

Do đó các bạn cần ý thức được những điều sau đây.
- Cần tạo một pipeline hoàn chỉnh càng sớm càng tốt. tức là từ việc lấy data source, xử lý dữ liệu, feature engineering, train, test, prediction, lưu trữ kết quả dự đoán hằng ngày hoặc hằng tuần cần được hoàn thành và vận hành mượt mà ngay từ lúc đầu tiên. 


